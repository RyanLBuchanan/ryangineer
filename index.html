<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Ryangineer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
  <script src="scripts/jquery.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
  <!-- jQuery Content Delivery Network -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <!-- CDN React libraries-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/umd/react.profiling.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/cjs/react.development.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/cjs/react.production.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/babel-standalone/6.26.0/babel.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <!-- My Stylesheet -->
  <link rel="stylesheet" type="text/css" href="stylesheets/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
  <!-- Favicon -->
  <link rel="shortcut icon" href="assets/favicon.ico" type="image/x-icon">
  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a target="_blank" class="navbar-brand" href="#"></a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/">Home</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/ai_finance.html">AI Finance</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/data_cleaning.html">Data Cleaning</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/data_dashboard.html">Data Dashboard</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/data_science.html">Data Science Diction</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/exploratory_data_analysis.html">Exploratory Data Analysis</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/machine_learning.html">Machine Learning</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/mathematicians.html">Mathematicians</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/predictive_modeling.html">Predictive Modeling</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/virtual_reality.html">VR Dev Kids</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/about.html">About</a>
        </li>
      </ul>
    </div>
  </nav>



  <div id="bio_image" style="float: left;">
    <figure>
      <img src="assets/bio_image.png" alt="Ryan L Buchanan" class="img-bio_image">
      <figcaption>
        <a target="_blank" href="mailto:buchananryan22@gmail.com">
          <b>buchananryan22@gmail.com</b></a><br />
        <a target="_blank" href="https://goo.gl/maps/UnhTaBZieDZU5F5w6"><b>Ogden, Utah, USA</b></a>
      </figcaption>
    </figure>
  </div>

  <div id="img_pythagoras" style="float: right;">
    <img src="assets/pythagoras.png" alt="Pythagora" class="img-fluid">
  </div>

  <div>
    <h1 id="ryangineer"><b>Ryangineer</b></h1>
    <h2 id="ryangineer_sub" style="font-weight:bold;">Machine Learning Mathematics<br />&<br />Virtual Reality Aesthetics<br /><br /></h2>
  </div>

  <div id="Rodgers_Quotation" class="container">
    <div class="jumbotron">
      <p id="rodgers_quotation" style="border: 1px solid gray;"><b>"Mathematics requires a small dose, not of genius, but of an imaginative freedom which, in a larger dose, would be insanity."</b><br />Angus K. Rodgers</p>
    </div>
  </div>


  <br /><br />
  <div id="ML_Algorithms">
    <h3>Noteworthy Machine Learning Algorithms</h3>
    <h7><b>&nbsp; Machine Learning &nbsp; &#8658; &nbsp; software able to detect
        patterns, make decisions, predict outcomes, learn from mistakes & optimize
        own performance without being explicitly programmed to do so</b></h7>
    <a target="_blank" href="https://en.wikipedia.org/wiki/Supervised_learning">
      <h4>Supervised Learning</h4>
    </a>
    <h7><b>Learning a function that maps to an output based on the example of
        input-output pairs. In other words, training a model on data where the
        outcome is known, for subsequent application to data where the outcome
        is not known."</b>
      <br />"Present labeled examples to learn from. For instance, when we want
      to be able to predict the selling price of a house in advance in a real estate
      market, we can get the historical prices of houses and have a supervised
      learning algorithm successfully figure out how to associate the prices to the
      house characteristics.
      <br /><b>Using the uppercase letter X we intend to use matrix notation,
        since we can also treat the <i>y</i> as a response vector (technically a
        column vector) and the X as a matrix containing all values of the feature
        vectors, each arranged into a separate column of the matrix. . . . building
        a function that can answer the question about how <i>X</i> can imply <i>y</i>
        . . . [with] a functional mapping that can translate <i>X</i> values into
        <i>y</i> without error or with an acceptable margin of error. . . . to
        determinate a function of the following kind:"</b> <a target="_blank" href="https://www.amazon.com/Regression-Analysis-Python-Luca-Massaron/dp/1785286315">(Massaron, pg 24)</a></h7>
    <ul>
      <li>
        <h5>Active Learning</h5>
        <h7>Semi-supervised learning algorithm where the software picks examples
          of data that are most useful to its learning & ignoring the bulk of data
          in data warehouses or data lakes.</h7>
      </li>
      <li>
        <h5>Online Learning</h5>
        <h7>In a fast-paced environment, a learning algorithm may stream data as
          it becomes available, continuously adapting to any new associations
          between predictive variables & the response.</h7>
      </li>
      <li>
        <h5>Matrix Notation Function</h5>
        <h7>"When the function is specified, and we have in mind a certain algorithm
          with certain parameters & an X matrix made up of certain data, conventionally
          we can refer to it as a <b><i>hypothesis</i></b>." </h7>
        <h6>
          <math>
            <mi>y</mi>
            <mo>&nbsp; = &nbsp;</mo>
            <mi>h</mi>
            <mo>(</mo>
            <mi>X</mi>
            <mo>)</mo>
          </math>
          <br />&nbsp; &#8627; where:
          <br />&emsp; <i>X</i> = a matrix of size (<i>n</i>, <i>p</i>)
          <br />&emsp; <i>y</i> = a response vector of size <i>n</i>
          <br />&emsp; <i>n</i> = # of observations
          <br />&emsp; <i>p</i> = # of variables
        </h6>
        <h7>Store the predictive variables (features or attributes) in the <i>X</i> matrix, size <i>n</i> x <i>p</i>:</h7>
        <h6>
          <math>
            <mi>X</mi>
            <mo>&nbsp; = &nbsp;</mo>
            <mo stretchy=True>[</mo>
            <mtable>
              <mtr>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mn>1,1</mn>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mn>1,2</mn>
                  </msub>
                </mtd>
                <mtd>
                  <mn>-</mn>
                </mtd>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mn>1,</mn>
                  </msub>
                  <msub>
                    <mn></mn>
                    <mi>p</mi>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mn>2,2</mn>
                  </msub>
                </mtd>
                <mtd>
                  <mn>-</mn>
                </mtd>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mn>2,</mn>
                  </msub>
                  <msub>
                    <mn></mn>
                    <mi>p</mi>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>.</mn>
                </mtd>
                <mtd>
                  <mn>.</mn>
                </mtd>
                <mtd>
                  <mn>-</mn>
                </mtd>
                <mtd>
                  <mn>.</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>.</mn>
                </mtd>
                <mtd>
                  <mn>.</mn>
                </mtd>
                <mtd>
                  <mn>-</mn>
                </mtd>
                <mtd>
                  <mn>.</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>.</mn>
                </mtd>
                <mtd>
                  <mn>.</mn>
                </mtd>
                <mtd>
                  <mn>-</mn>
                </mtd>
                <mtd>
                  <mn>.</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mi>n</mi>
                  </msub>
                  <msub>
                    <mn></mn>
                    <mn>,1</mn>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mi>n</mi>
                  </msub>
                  <msub>
                    <mn></mn>
                    <mn>,2</mn>
                  </msub>
                </mtd>
                <mtd>
                  <mn>-</mn>
                </mtd>
                <mtd>
                  <msub>
                    <mi>x</mi>
                    <mi>n</mi>
                  </msub>
                  <msub>
                    <mn></mn>
                    <mn>,</mn>
                  </msub>
                  <msub>
                    <mn></mn>
                    <mi>p</mi>
                  </msub>
                </mtd>
              </mtr>
            </mtable>
            <mo stretchy=True>]</mo>
          </math>
        </h6>
      </li>
      <li>
        <h5>Linear Regression | Predict Real Values</h5>
        <h7>Estimate or predict real values based on continuous variables -> establish relationship between independent variables (matrix of features) & dependent variable (output) by fitting a best line</h7>
      </li>
      <ul>
        <li>
          <h5>Homoscedasticity</h5>
          <h7>"Homoskedastic . . . refers to a condition in which the variance
            of the residual, or error term, [that is, the “noise” or random disturbance
            in the relationship between the independent variables and the dependent
            variable], in a regression model is constant. That is, the error term
            does not vary much as the value of the predictor variable changes." <a target="_blank" href="https://www.investopedia.com/terms/h/homoskedastic.asp">Investopedia</a></h7>
        </li>
        <li>
          <h5>Multicollinearity</h5>
          <h7>"[R]efers to predictors that are correlated [, that is, highly linearly
            related,] with other predictors. Multicollinearity occurs when your
            model includes multiple factors that are correlated not just to your
            response variable, but also to each other. In other words, it results
            when you have factors that are a bit redundant." <a target="_blank" href="https://blog.minitab.com/en/understanding-statistics/handling-multicollinearity-in-regression-analysis">Minitab</a> </h7>
        </li>
        <li>
          <h5>No Free Lunch Theorems (NFL)</h5>
          <h7>"[S]tate that any one algorithm that searches for an optimal cost
            or fitness solution is not universally superior to any other algorithm.
            . . . 'If an algorithm performs better than random search on some class
            of problems then in must perform worse than random search on the
            remaining problems.'” <a target="_blank" href="https://medium.com/@LeonFedden/the-no-free-lunch-theorem-62ae2c3ed10c">Medium</a></h7>
        </li>
        <li>
          <h5>Parsimonious Model</h5>
          <h7>"Parsimonious models are simple models [with the least assumptions
            & variables but] with great explanatory predictive power. They explain
            data with a minimum number of parameters, or predictor variables. The
            idea behind parsimonious models stems from Occam's razor, or 'the law
            of briefness' (sometimes called lex parsimoniae in Latin)." <a target="_blank"
              href="https://www.statisticshowto.com/parsimonious-model/#:~:text=Parsimonious%20models%20are%20simple%20models,called%20lex%20parsimoniae%20in%20Latin).">Statistics How To</a></h7>
        </li>
        <li>
          <h5>Law of Large Numbers</h5>
          <h7>As the # of experiments grows, so increases the likelihood that the
            average of their results will reporesent the true value of the population.</h7>
        </li>
        <li>
          <h5>Linear Combination</h5>
          <h7>A sum where each addendum value is modified by a weight (the
            coefficients), and, therefore, a smarter form of summation.</h7>
        </li>
        <li>
          <h5>Family of Linear Models or Generalized Linear Model (GLM)</h5>
          <h7>Function that specifies the relationship between the <i>X</i>, the
            predictors, & the <i>y</i>, the target, is a linear combination of
            the <i>X</i> values. By means of special link functions proper
            transformation of the answer variable, proper constraints on the
            weights & different optimization procedures (the learning procedures),
            GLM can solve a very wide range of problems.</h7>
        </li>
        <li>
          <h5>Probability Density Function (PDF)</h5>
          <h7>A function describing the probability of values in the distribution.
            For a normal distribution:</h7>
          <h6>
            <math>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <mi>x</mi>
              <mo stretchy=False>|</mo>
              <mi>&mu;</mi>
              <mo>, </mo>
              <mi>&sigma;</mi>
              <mo stretchy=False>)</mo>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mn>1</mn>
                </mrow>
                <mrow>
                  <mi>&sigma;</mi>
                  <msqrt>
                    <mn>2</mn>
                    <mi>&pi;</mi>
                  </msqrt>
                </mrow>
              </mfrac>
              <msup>
                <mi>e</mi>
                <mo>-</mo>
              </msup>
              <msup>
                <mn></mn>
                <mfrac>
                  <mrow>
                    <mo>(</mo>
                    <mi>x</mi>
                    <mo>-</mo>
                    <mi>&mu;</mi>
                    <mo>)</mo>
                    <msup>
                      <mn></mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                  <mrow>
                    <mn>2</mn>
                    <msup>
                      <mi>&sigma;</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
              </msup>
            </math>
          </h6>
          <ul>
            <li>
              <h5>Moments of the PDF</h5>
              <ul>
                <li>
                  <h7><b>First moment</b>: <i>expected value</i> or a generalization
                    of the weighted average, the arithmetic mean</h7>
                </li>
                <li>
                  <h7><b>Second central moment</b>: <i>variance</i> or expectation
                    of the squared deviation of a random variable</h7>
                </li>
                <li>
                  <h7><b>Third standardized moment</b>: <i>skewness</i> or a measure
                    of the asymmetry of the probability distribution of a real-valued
                    random variable about its mean</h7>
                </li>
                <li>
                  <h7><b>Fourth standardized moment</b>: <i>kurtosis</i> or a measure
                    of the "tailedness" of the probability distribution of a
                    real-valued random variable</h7>
                </li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <h5>Covariation vs. Correlation</h5>
          <h7><b>Covariation</b> is a measure of association that is
            affected by the scale of the variables & is not <b>standardized</b>.
            When a variable is standardized, it returns a value
            between -1 to 1, -1 being negatively correlated (one grows, the other
            shrinks), 1 being positively correlated (one grows, so does the other)
            & 0 meaning there is no relationship, at all.
            <br /><b>Correlation</b> is a measure of the strength of linear
            association between two variables, of how close to a straight line your points are.</h7>
          <ul>
            <li>
              <h5>Covariance Expression</h5>
              <h6>
                <math>
                  <mi>c</mi>
                  <mi>o</mi>
                  <mi>v</mi>
                  <mo stretchy=False>(</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>i</mi>
                  </msub>
                  <mo>, </mo>
                  <mi>y</mi>
                  <mo stretchy=False>)</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mn>1</mn>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                  <mo>&nbsp; * &nbsp;</mo>
                  <mo stretchy=True>&Sigma;</mo>
                  <mo stretchy=False>(</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>i</mi>
                  </msub>
                  <mo>&nbsp; - &nbsp;</mo>
                  <msub>
                    <mi>x&#772;</mi>
                    <mi>i</mi>
                  </msub>
                  <mo stretchy=False>)</mo>
                  <mo>&nbsp; * &nbsp;</mo>
                  <mo stretchy=False>(</mo>
                  <mi>y</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>y</mi>
                  <mo>&#772;</mo>
                  <mo stretchy=False>)</mo>
                </math>
              </h6>
            </li>
            <li>
              <h5>Pearson's Correlation</h5>
              <h6>
                <math>
                  <mi>r</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mn>1</mn>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                  <mo>&nbsp; * &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mo stretchy=True>&Sigma;</mo>
                      <mo stretchy=False>(</mo>
                      <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                      </msub>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mi>x&#772;</mi>
                        <mi>i</mi>
                      </msub>
                      <mo stretchy=False>)</mo>
                      <mo>&nbsp; * &nbsp;</mo>
                      <mo stretchy=False>(</mo>
                      <mi>y</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <mi>y</mi>
                      <mo>&#772;</mo>
                      <mo stretchy=False>)</mo>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>&sigma;</mi>
                        <msub>
                          <mi>x</mi>
                          <mi>i</mi>
                        </msub>
                      </msub>
                      <mo>&nbsp; * &nbsp;</mo>
                      <msub>
                        <mi>&sigma;</mi>
                        <mi>y</mi>
                      </msub>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
          </ul>
        </li>
        <li>
          <h5>Ordinary Least Squares (OLS)</h5>
          <h7>Another way to refer to linear regression. "A type of linear least
            squares method for estimating the unknown parameters in a linear
            regression model. OLS chooses the parameters of a linear function of
            a set of explanatory variables by the principle of least squares:
            minimizing the sum of the squares of the differences between the
            observed dependent variable (values of the variable being observed)
            in the given dataset and those predicted by the linear function of
            the independent variable. Geometrically, this is seen as the sum of
            the squared distances, parallel to the axis of the dependent variable,
            between each data point in the set and the corresponding point on the
            regression surface—the smaller the differences, the better the model
            fits the data." <a target="_blank" href="https://en.wikipedia.org/wiki/Ordinary_least_squares">Wikipedia</a></h7>
        </li>
        <li>
          <h5>Bias</h5>
          <h7>The point at which a regression line crosses the y-axis; that is,
            the predicted value when X = 0.</h7>
          <h6>bias = y-intercept</h6>
        </li>
        <li>
          <h5>Derivation of Line of Best Fit | Residual Sum of Squares(RSS)</h5>
          <h7>Linear regression tries to fit a line through a given set of points,
            choosing the best fit. The best fit is the line that minimizes the
            summed squared difference between the value dictated by the line for
            a certain value of x and its corresponding y values. It is optimizing
            the squared error.</h7>
          <h6>RSS = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>(y - y&#770;)<sup>2</sup> &#8594; min</h6>
        </li>
        <li>
          <h5>Residuals or Errors</h5>
          <h7><b>The difference between the observed values of the dependent variable (y) & the predicted (fitted) values (y&#770;).</b>
            <br />"The deviations of the actual y from the predicted y. When forming
            a linear regression, the predicted Y follows a linear relationship.
            <b><i>Deviations from this line, are called residuals</i></b>; they measure the
            distance between the actual Y for each N and the line (predicted Y).
            For a good linear model, the residuals should be small and random.
            If they are really large it shows the model is not very accurate,
            and if there is a pattern then it would suggest a non-linear model
            would fit better for example." <a target="_blank" href="https://www.reddit.com/r/AskStatistics/comments/5f8v4r/residuals/">r/AskStatistics</a>
            <ul>
              <li>
                <b>Each data point has to residuals.</b>
              </li>
              <li>
                <b>Both the sum & the mean of the residuals are equal to zero.</b>
              </li>
              <li>
                <b>If the points in a residual plot are randomly dispersed arount
                  the horizontal axis, the linear regression model is appropriate.
                  Otherwise, a non-linear model is more appropriate.</b>
              </li>
            </ul>
          </h7>
        </li>
        <li>
          <h5>Fitted Values or Predicted Values</h5>
          <h7>The estimates <i>Y&#770;<sub>i</sub></i> obtained from a regression
            line, the predictions.</h7>
        </li>
        <li>
          <h5>Interpolation & Extrapolation</h5>
          <h7><b>Interpolation</b>: A linear regresssion model can always work within the range of values
            from which it learned.
            <b>Extrapolation</b>: But can provide correct values for its learning
            boundaries only in certain conditions.</h7>
        </li>
        <li>
          <h5>Kurtosis</h5>
          <h7>This is a measure of the shape of the distribution of the residuals.
            A bell-shaped distribution has a zero measure. A negative value points
            to a too flat distribution; a positive one has too great a peak.
            <br />"<b>A measure of the 'tailedness'</b> of the probability distribution
            of a real-valued random variable." <a target="_blank" href="https://en.wikipedia.org/wiki/Kurtosis">Wikipedia</a></h7>
          <h6>
            <math>
              <mn>Kurt</mn>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <msub>
                    <mi>&mu;</mi>
                    <mn>4</mn>
                  </msub>
                </mrow>
                <mrow>
                  <msup>
                    <mi>&sigma;</mi>
                    <mn>4</mn>
                  </msup>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </li>
        <li>
          <h5>Simple Linear Regression | The Equation of a Straight Line</h5>
          <h7>Combining one variable in an equation to predict a single outcome</h7>
          <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub>
            <br />&emsp;&ensp; <b style="color:Maroon">or</b>
            <br /><i>y</i> = <i>&beta;x</i> + <i>&beta;</i><sub>0</sub>
            <br />&emsp;&ensp; <b style="color:Maroon">or</b>
            <br />y = mx + b
            <br />&emsp;&ensp; <b style="color:Maroon">or</b>
            <br />y = <i>a</i> + <i>b</i>x
            <br />&emsp;&ensp; <b style="color:Maroon">or</b>
            <br /><i>Y<sub>i</sub></i> = <i>b</i><sub>0</sub> + <i>b</i><sub>1</sub><i>X<sub>i</sub></i> + <i>e<sub>i</sub></i>
            <br />&nbsp; &#8627; where:
            <br />&emsp; y = response, dependent, criterion, target, outcome, label
            <br />&emsp; <i>a</i>, b, b<sub>0</sub>, <i>&beta;</i><sub>0</sub> = constant, y-intercept, bias
            <br />&emsp; m, <i>b</i>, b<sub>1</sub>, <i>&beta;</i> = slope, coefficient, gradient,
            angular coefficient
            <br />&emsp; x, x<sub>1</sub>, <i>X<sub>i</sub></i> = independent,
            explanatory, predictor variable, matrix of predictors, feature vector,
            control variable
            <br />&emsp; <i>e<sub>i</sub></i> = explicit error term
            <br />&emsp;
            <br />
            <math>
              <mi>a</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>y</mi>
                  <mo>)</mo>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <msup>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msup>
                  <mo>)</mo>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>x</mi>
                  <mo>)</mo>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>x</mi>
                  <mi>y</mi>
                  <mo>)</mo>
                </mrow>
                <mrow>
                  <mi>n</mi>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <msup>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msup>
                  <mo>)</mo>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>x</mi>
                  <mo>)</mo>
                  <msup>
                    <mn></mn>
                    <mn>2</mn>
                  </msup>
                </mrow>
              </mfrac>
            </math>
            <br />
            <math>
              <mi>b</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>n</mi>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>x</mi>
                  <mi>y</mi>
                  <mo>)</mo>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>x</mi>
                  <mo>)</mo>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>y</mi>
                  <mo>)</mo>
                </mrow>
                <mrow>
                  <mi>n</mi>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <msup>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msup>
                  <mo>)</mo>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mo>(</mo>
                  <mn>&Sigma;</mn>
                  <mi>x</mi>
                  <mo>)</mo>
                  <msup>
                    <mn></mn>
                    <mn>2</mn>
                  </msup>
                </mrow>
              </mfrac>
            </math>
            <br />
            <math>
              <msub>
                <mn>b</mn>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mn>&Delta;Y</mn>
                </mrow>
                <mrow>
                  <mn>&Delta;X</mn>
                </mrow>
              </mfrac>
            </math>
            <br />
            <math>
              <msub>
                <mi>e&#770;</mi>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mi>Y</mi>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>Y&#770;</mi>
                <mi>i</mi>
              </msub>
            </math>
          </h6>
        </li>
        <li>
          <h5>Minimization of the Cost Function</h5>
          <h7>"The search for a line's equation that it is able to minimize the
            sum of the squared errors of the difference between the line's y
            values and the original ones." WGU MSDA
            <br />Methods of minimization include <b>Pseudoinverse</b>, <b>QR
              factorization</b>, & <b>gradient descent</b>.</h7>
          <ul>
            <li>
              <h5>Regression Function of <i>h</i>(X):</h5>
              <h6>
                <math>
                  <mi>y</mi>
                  <mo>&nbsp; &#8776; &nbsp;</mo>
                  <mi>h</mi>
                  <mo stretchy=False>(</mo>
                  <mi>X</mi>
                  <mo stretchy=False>)</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mi>&beta;</mi>
                  <mi>X</mi>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>&beta;</mi>
                    <mn>0</mn>
                  </msub>
                </math>
                <br /><b style="color:Maroon">Cost function minimized as follows:</b>
                <br />
                <math>
                  <mfrac>
                    <mrow>
                      <mn>1</mn>
                    </mrow>
                    <mrow>
                      <mn>2</mn>
                      <mi>N/mi>
                    </mrow>
                  </mfrac>
                  <mo>&nbsp; * &nbsp;</mo>
                  <mo>&Sigma;</mo>
                  <mo stretchy=False>(</mo>
                  <mi>h</mi>
                  <mo stretchy=False>(</mo>
                  <mi>X</mi>
                  <mo stretchy=False>)</mo>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>y</mi>
                  <mo stretchy=False>)</mo>
                  <msup>
                    <mn></mn>
                    <mn>2</mn>
                  </msup>
                </math>
              </h6>
            </li>
            <li>
              <h5>Pseudoinverse</h5>
              <h7>An analytical formula for solving a regression analysis and getting
                a vector of coefficients out of data, minimizing the cost function:</h7>
              <h6>
                <math>
                  <mi>w</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo stretchy=False>(</mo>
                  <msup>
                    <mi>X</mi>
                    <mi>T</mi>
                  </msup>
                  <mi>X</mi>
                  <mo stretchy=False>)</mo>
                  <msup>
                    <mn></mn>
                    <mn>-1</mn>
                  </msup>
                  <msup>
                    <mi>X</mi>
                    <mi>T</mi>
                  </msup>
                  <mi>y</mi>
                </math>
                <br /><b style="color:Maroon">Or solve for <i>w</i> in linear
                  equations called <b><i>normal equations</i></b>:</b>
                <br />
                <math>
                  <mo stretchy=False>(</mo>
                  <msup>
                    <mi>X</mi>
                    <mi>T</mi>
                  </msup>
                  <mi>X</mi>
                  <mo stretchy=False>)</mo>
                  <msup>
                    <mn></mn>
                    <mn>-1</mn>
                  </msup>
                  <mo>&nbsp; * &nbsp;</mo>
                  <mi>w</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <msup>
                    <mi>X</mi>
                    <mi>T</mi>
                  </msup>
                  <mi>y</mi>
                </math>
              </h6>
            </li>
          </ul>
        </li>
        <li>
          <h5>Gradient Descent</h5>
          <h7>"Explaining it simply, it resembles walking blind in the mountains.
            If you want to descend to the lowest valley, even if you don't know
            and can't see the path, you can proceed approximately by going downhill
            for a while, then stopping, then going downhill again and so on, always
            aiming at each stage for where the surface descends until you arrive
            at a point when you cannot descend anymore. Hopefully, at that point
            you will have reached your destination.
            <br />&emsp; . . . Though quite conceptually simple (it is based on
            an intuition that we have surely applied ourselves to move step-by-step,
            directing where we can optimize our result), gradient descent is very
            effective and indeed scalable when working with real data. Such interesting
            characteristics have elevated it to the core optimization algorithm
            in machine learning; it is not limited to just the linear model family,
            but it can also be extended, for instance, to neural networks for the
            process of back propagation, which updates all the weights of the neural
            net in order to minimize training errors. Surprisingly, gradient descent
            is also at the core of another complex machine learning algorithm,
            gradient boosting tree ensembles, where we have an iterative process
            minimizing the errors using a simpler learning algorithm (a so-called
            <b>weak learner</b> because it is limited by a high bias) to progress
            towards optimization." <a target="_blank" href="https://www.amazon.com/Regression-Analysis-Python-Luca-Massaron-ebook/dp/B01BFD2Z44">(Massaron, p. 62)</a>
            <br />&emsp; "A gradient is the slope of a function. It measures the
            degree of change of a variable in response to the changes of another
            variable. . . [It] is a convex function whose output is the partial
            derivative of a set of parameters of its inputs. The greater the
            gradient, the steeper the slope." <a target="_blank" href="https://www.geeksforgeeks.org/ml-stochastic-gradient-descent-sgd/">GeeksForGeeks</a>
          </h7>
          <ul>
            <li>
              <h5>Cost Function</h5>
              <h6>
                <math>
                  <mi>J</mi>
                  <mo stretchy=false>(</mo>
                  <mi>w</mi>
                  <mo stretchy=false>)</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mn>1</mn>
                    </mrow>
                    <mrow>
                      <mn>2</mn>
                      <mi>N</mi>
                    </mrow>
                  </mfrac>
                  <mo>&Sigma;</mo>
                  <mo stretchy=false>(</mo>
                  <mi>X</mi>
                  <mi>w</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>y</mi>
                  <mo stretchy=false>)</mo>
                  <msup>
                    <mn></mn>
                    <mn>2</mn>
                  </msup>
                </math>
              </h6>
            </li>
            <li>
              <h5>Final Resolution Form</h5>
              <h6>
                <math>
                  <msub>
                    <mi>w</mi>
                    <mi>j</mi>
                  </msub>
                  <mo>&nbsp; = &nbsp;</mo>
                  <msub>
                    <mi>w</mi>
                    <mi>j</mi>
                  </msub>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>&alpha;</mi>
                  <mo>&nbsp; * &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mn>1</mn>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                  <mo>&Sigma;</mo>
                  <mo stretchy=false>(</mo>
                  <mi>X</mi>
                  <mi>w</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>y</mi>
                  <mo stretchy=false>)</mo>
                  <mo>&nbsp; * &nbsp;</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>j</mi>
                  </msub>
                </math>
              </h6>
            </li>
            <li>
              <h5>Learning Rate (<i>&alpha;</i>)</h5>
              <h7>Very important in the process, because, if it is too large,
                it may cause the optimization to detour & fail.</h7>
            </li>
          </ul>
        </li>
        <li>
          <h5>Feature Scaling</h5>
          <h7>"[S]ome features in your data may be represented by measurements in
            units, some in decimals, & others in thousands, depending on what
            aspect of reality each feature represents. In our real estate example,
            one feature could be the number of rooms, another one could be the
            percentage of certain pollutants in the air, and finally, the average
            value of a house in the neighborhood. When it is the case that the
            features have a different scale, though the algorithm will be processing
            each of them separately, optimization will be dominated by the variables
            with the more extensive scale. Working in a space of dissimilar dimensions
            will require more iterations before convergence to a solution (&
            sometimes there might be no convergence at all).
            <br />&emps; The remedy is very easy; it is just necessary to put all
            the features on the same scale . . . <b>Feature scaling</b> can be
            achieved through <i>standardization</i> or <i>normalization</i>.
            <b>Normalization</b> rescales all the values in the interval between
            zero & one (usually, but different ranges are also possible), whereas
            <b>standardization</b> operates by removing the mean & dividing by
            standard deviation to obtain a unit variance."
            <a target="_blank" href="https://www.amazon.com/Regression-Analysis-Python-Luca-Massaron-ebook/dp/B01BFD2Z44">(Massaron, p. 76)</a>
          </h7>
        </li>
        <li>
          <h5>Multiple Linear Regression (MLR)</h5>
          <h7>Combining many variables in an equation to predict a single outcome</h7>
          <h6>
            <math>
              <msub>
                <mi>y</mi>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>0</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mn></mn>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mn></mn>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mn></mn>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&epsilon;</mi>
                <mi>i</mi>
              </msub>
            </math>
            <br />&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b style="color:Maroon">or</b>
            <br />
            <math>
              <mi>Y</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>E(Y)</mi>
              <mo>&nbsp; + &nbsp;</mo>
              <mi>&epsilon;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>0</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mi>X</mi>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mi>X</mi>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mi>X</mi>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <mi>&epsilon;</mi>
            </math>
            <br />&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b style="color:Maroon">or</b>
            <br />
            <math>
              <mn>Y&rsquo;</mn>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>a</mi>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>b</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>b</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
            </math>
            <br />&nbsp; &#8627; where:
            <br />&emsp; E(Y), <i>Y</i>, Y&rsquo;, Y&#770; = Expected value of Y or instance of Y
            <br />&emsp; <i>a</i>, &beta;<sub>0</sub> = constant, y-intercept
            <br />&emsp; &beta;<sub>0</sub>, &beta;<sub>1</sub>, &beta;<sub>2</sub>, &beta;<sub>3</sub> = population regression parameters, coefficients
            <br />&emsp; X<sub>1</sub>, X<sub>2</sub>, X<sub>3</sub> = independent,
            explanatory, predictor variables
            <br />&emsp; &epsilon; = regression error term, an adjustment term
          </h6>
          <ul>
            <li>
              <h5>Vector of Standardized Coefficients & Bias</h5>
              <h6>
                <math>
                  <mi>y</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <msub>
                    <mi>&beta;</mi>
                    <mn>0</mn>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <mo stretchy=True>&Sigma;</mo>
                  <msub>
                    <mi>&beta;</mi>
                    <mi>i</mi>
                  </msub>
                  <msub>
                    <mi>x</mi>
                    <mi>i</mi>
                  </msub>
                </math>
              </h6>
            </li>
            <li>
              <h5>Transformation of Predictors</h5>
              <h6>
                <math>
                  <mi>y</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>(</mo>
                  <msub>
                    <mi>&beta;&#770;</mi>
                    <mn>0</mn>
                  </msub>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mo stretchy=True>&Sigma;</mo>
                  <mfrac>
                    <mrow>
                      <msub>
                        <mi>&beta;&#770;</mi>
                        <mi>i</mi>
                      </msub>
                      <msub>
                        <mi>x&#772;</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>&delta;</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo>)</mo>
                  <mo>&nbsp; + &nbsp;</mo>
                  <mo>&Sigma;</mo>
                  <mo>(</mo>
                  <mfrac>
                    <mrow>
                      <msub>
                        <mi>&beta;&#770;</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>&delta;</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo>&nbsp; * &nbsp;</mo>
                  <msub>
                    <mi>x&#772;</mi>
                    <mi>i</mi>
                  </msub>
                  <mo>)</mo>
                </math>
                <br />&nbsp; &#8627; where:
                <br />&emsp; x&#772; = original mean
                <br />&emsp; &delta; = original variance
            </li>
            <li>
              <h5>Variable(s) Interactions</h5>
              <h7>"One of the first sources of non-linearity is due to possible
                interactions between predictors. Two predictors interact when the
                effect of one of them on the response variable varies in respect
                of the values of the other predictors. . . .[I]nteraction terms
                have to be multiplied by themselves for our linear model to catch
                the supplementary information of their relation as expressed in
                this example of a model with two interacting predictors."
                <a target="_blank" href="https://www.amazon.com/Regression-Analysis-Python-Luca-Massaron-ebook/dp/B01BFD2Z44">(Massaron, p. 87)</a></h7>
              <h6>
                <math>
                  <mi>y</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <msub>
                    <mi>&beta;</mi>
                    <mn>0</mn>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>&beta;</mi>
                    <mn>1</mn>
                  </msub>
                  <msub>
                    <mi>x</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>&beta;</mi>
                    <mn>2</mn>
                  </msub>
                  <msub>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>&beta;</mi>
                    <mn>12</mn>
                  </msub>
                  <msub>
                    <mi>x</mi>
                    <mn>1</mn>
                  </msub>
                  <msub>
                    <mi>x</mi>
                    <mi>2</mi>
                  </msub>
                  </msub>
                </math>
              </h6>
            </li>
          </ul>
        </li>
        <li>
          <h5>Polynomial Linear Regression</h5>
          <h7>"[G]enerally used when the points in the data are not captured by
            the Linear Regression Model and the Linear Regression fails in
            describing the best result clearly."
            <a target="_blank" href="https://medium.com/analytics-vidhya/understanding-polynomial-regression-5ac25b970e18">Anaylytics Vidhya</a>
            <br />"Although this model allows for a nonlinear relationship between
            Y and X, polynomial regression is still considered linear regression
            since it is linear in the regression coefficients."
            <a target="_blank" href="https://online.stat.psu.edu/stat462/node/158/">PSU</a>
            <br />"As an extension of interactions, polynomial expansion systematically
            provides an automatic means of creating both interactions and non-linear
            power transformations of the original variables. Power transformations
            are the bends that the line can take in fitting the response. The higher
            the degree of power, the more bends are available to fit the curve."
            <a target="_blank" href="https://www.amazon.com/Regression-Analysis-Python-Luca-Massaron-ebook/dp/B01BFD2Z44">(Massaron, p. 89)</a></h7>
          <h6><i>y</i> = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub> + b<sub>2</sub>x<sub>2</sub><sup>2</sup> + . . . + b<sub>n</sub>x<sub>n</sub><sup>n</sup></h6>
        </li>
        <li>
          <h5>Overfitting</h5>
          <h7>"[F]itting the data at hand so well that the result is far from being
            extraction of the form of the data to draw predictions from; the model
            won't learn general rules but it will just be memorizing the dataset
            itself in another form."
            <a target="_blank" href="https://www.amazon.com/Regression-Analysis-Python-Luca-Massaron-ebook/dp/B01BFD2Z44">(Massaron, p. 94)</a></h7>
        </li>
        <li>
          <h5>Coefficient of Determination | R Squared (<i>R</i><sup>2</sup>) | Goodness of Fit Parameter</h5>
          <h7>"[T]he <i>R</i><sup>2</sup> value basically depicts how correlated
            a certain trend is, which means how related two variables are. If you
            plot <i>x</i> & <i>y</i> on a scatterplot, & we note a correlation
            of <i>r</i>, the <i>R</i><sup>2</sup> is the amount of variation in <i>y</i>
            that can be predicted by <i>x</i>. So it is the percentage of variation
            that variable <i>x</i> can predict in variable <i>y</i>, which effectively
            means that if <i>y</i> changes by a percentage <i>p</i>, then <i>x</i>
            can still predict that change in <i>y</i>. It is usually expressed in
            percentage, so the closer your <i>R</i><sup>2</sup> value is to 100%
            [(expressed in decimal from 0 to 1)], the more accurately <i>x</i>
            predicts <i>y</i>, & therefore the more correlated your data is." <a target="_blank" href="https://www.reddit.com/r/explainlikeimfive/comments/wfhy2/eli5_what_is_a_coefficient_of_determination_or_r2/">ELI5</a>
            <ul>
              <li>
                <b>A metric to describe variation in outcome explained by the IVs.</b>
              </li>
              <li>
                <b>Mostly, <i>R</i><sup>2</sup> will increase as more predictors
                  are added to the model.</b>
              </li>
              <li>
                <b>By itself <i>R</i><sup>2</sup> cannot identity which Predictors
                  should be included in the model.</b>
              </li>
              <li>
                <b>If <i>R</i><sup>2</sup> is 0, none of the IVs predict outcome.
                  A value of 1 means that the outcome can be predicted without error.</b>
              </li>
            </ul>
          </h7>
          <h6>R<sup>2</sup> = 1 - SS<sub>res</sub>/SS<sub>tot</sub><br />
            &nbsp; &#8627; where: <br />
            <ul>&#8627; SS<sub>tot</sub> = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>(y - y<sub>avg</sub>)<sup>2</sup></ul>
          </h6>
        </li>
        <li>
          <h5>Adjusted R Squared</h5>
          <h6>Adj R<sup>2</sup> = 1 - (1 - r<sup>2</sup>) * [(n - 1)/(n - p - 1)] <br />
            &nbsp; &#8627; where: <br />
            <ul>
              &#8627; p = number of regressors <br />
              &#8627; n = sample size
            </ul>
          </h6>
        </li>
      </ul>
      <li><a target="_blank" title="" href="https://www.mathworks.com/help/stats/understanding-support-vector-machine-regression.html" />
        <h5>Support Vector Regression | Classification</h5></a>
        <h7>Use as a regression method, maintaining all the main features that characterize the algorithm (maximal margin). The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences.
        </h7>
        <ul>
          <li>
            <h5>Epsilon-Insensitive Tube</h5>
            <h6>
              <math div="epsilon_insnstvty_tuber">
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <mn>2</mn>
                  </mrow>
                </mfrac>
                <mo>&#8741;</mo>
                <mi>w</mi>
                <mo> &#8741;</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mn>C &nbsp;</mn>
                <span id="epsilon" style="font-size: 20px;">&Sigma;</span>(ξ<sub>i</sub> + ξ<sub>i</sub><sup>*</sup>) &#8594; min
              </math>
            </h6>
          </li>
          <li>
            <h5>The Gaussian RBF Kernel</h5>
            <h6>
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>K</mi>
                <mo stretchy="false">(</mo>
                <mi>x&#8407;, &nbsp;</mi>
                <msup>
                  <mi>l&#8407;</mi>
                  <mn>&nbsp;i</mn>
                </msup>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <mi>exp</mi>
                <mo stretchy="true">(</mo>
                <mo>-</mo>
                <mfrac>
                  <mrow>
                    <mi>&#8741; x&#8407;, &nbsp;</mi>
                    <msup>
                      <mi>l&#8407;</mi>
                      <mn>&nbsp;i</mn>
                    </msup>
                    <mo>&#8741;</mo>
                    <msup>
                      <mn></mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                  <mrow>
                    <mi>2</mi>
                    <msup>
                      <mi>&sigma;</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo stretchy="true">)</mo>
              </math><br />
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Logistic Regression</h5>
        <h7>Used to estimate discrete values, binary values (0/1, yes/no, true/false)
          based on given set of independent variables; predicts probability between
          0 & 1 as output values.
          <br /> &emsp; Logistic regression like its name is logarithmic. Its graph
          is curvilinear. If the dependent variable is binary, the graph is sigmoid.
          If not, the graph can be more pronounced, parabolic, etc.</h7>
        <ul>
          <li>
            <h5>Binary Classification</h5>
            <h7>An <i>n</i>-dimensional feature vector (<i>x<sub>i</sub></i>) paired
              with its label.</h7>
            <h6>
              <math>
                <mo>(</mo>
                <msub>
                  <mi>x</mi>
                  <mi>i</mi>
                </msub>
                <mn>,&nbsp;</mn>
                <msub>
                  <mi>y</mi>
                  <mi>i</mi>
                </msub>
                <mo>)</mo>
                <mo>&nbsp;:&nbsp;</mo>
                <msub>
                  <mi>x</mi>
                  <mi>i</mi>
                </msub>
                <mo>&nbsp; &#8712; &nbsp;</mo>
                <msup>
                  <mi>R</mi>
                  <mi>n</mi>
                </msup>
                <mo>, &nbsp;</mo>
                <msub>
                  <mi>y</mi>
                  <mi>i</mi>
                </msub>
                <mo>&nbsp; &#8712; &nbsp;</mo>
                <mo stretchy=False>{</mo>
                <mn>0,&nbsp;</mn>
                <mn>1</mn>
                <mo stretchy=False>}</mo>
              </math>
            </h6>
            <ul>
              <li>
                <h5>Classification Function</h5>
                <h7>The underlying model may be linearor non-linear.</h7>
                <h6>
                  <math>
                    <mi>f</mi>
                    <mo>&nbsp;:&nbsp;</mo>
                    <msup>
                      <mi>R</mi>
                      <mi>n</mi>
                    </msup>
                    <mo>&nbsp; &#8594; &nbsp;</mo>
                    <mo stretchy=False>{</mo>
                    <mn>0,&nbsp;</mn>
                    <mn>1</mn>
                    <mo stretchy=False>}</mo>
                  </math>
                </h6>
              </li>
            </ul>
          </li>
          <li>
            <h5>Sigmoid Function | Predicting Probability (p&#770;) </h5>
            <h6>
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>p</mi>
                <mo>=</mo>
                <mfrac>
                  <mrow>
                    <mi>1 &nbsp;</mi>
                  </mrow>
                  <mrow>
                    <mi>1 &nbsp; +</mi>
                    <msup>
                      <mi>&nbsp; e</mi>
                      <mn>-y</mn>
                    </msup>
                  </mrow>
                </mfrac>
              </math><br /><br />
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>ln</mi>
                <mo stetchy=false>(</mo>
                <mfrac>
                  <mrow>
                    <mi>p</mi>
                  </mrow>
                  <mrow>
                    <mn>1</mn>
                    <mo>&nbsp; - &nbsp;</mo>
                    <mi>p</mi>
                  </mrow>
                </mfrac>
                <mo stetchy=false>)</mo>
                <mo>=</mo>
                <msub>
                  <mi>b</mi>
                  <mn>0</mn>
                </msub>
                <mi>+</mi>
                <msub>
                  <mi>b</mi>
                  <mn>1</mn>
                </msub>
                <mi>x</mi>
              </math><br />
            </h6>
          </li>
          <li>
            <h5>Maximum Likelihood Estimation (MLE)</h5>
            <h7>"A method of estimating the parameters of a probability distribution
              by maximizing a likelihood function."
              <a target="_blank" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">Wikipedia</a></h7>
          </li>
          <li>
            <h5>Stochastic Gradient Descent (SGD)</h5>
            <h7>"<b>[S]tochastic</b> means a system or a process linked with a
              random probability. . . . [So], a few samples are selected randomly
              instead of the whole data set for each iteration. . . . [T]he term
              <b>batch</b> denotes the total number of samples from a dataset that
              is used for calculating the gradient for each iteration."
              <a target="_blank" href="https://www.geeksforgeeks.org/ml-stochastic-gradient-descent-sgd/">GeeksForGeeks</a></h7>
          </li>
          <li>
            <h5>ROC Curve</h5>
            <h7>"[The] receiver operating characteristic (ROC) curve is a graph
              showing the performance of a classification model at all classification
              thresholds. This curve plots two parameters." <a target="_blank"
                href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc#:~:text=An%20ROC%20curve%20(receiver%20operating,False%20Positive%20Rate">Google ML Crash Course</a>
              <ul>
                <li>
                  <b>True Positive Rate (TPR)</b>
                </li>
                <li>
                  <b>False Positive Rate (FPR)</b>
                </li>
              </ul>
            </h7>
          </li>
        </ul>
      </li>
      <li>
        <h5>Decision Tree Regression</h5>
        <h7>Supervised learning algorithm used for classification problems; works for categorical & continuous variables</h7>
        <ul>
          <li>
            <h5>Standard Deviation Reduction</h5>
          </li>
          <h6>F(T, X) = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>P(c)S(c)</h6>
        </ul>
      </li>
      <li>
        <h5>Support Vector Machines | Discriminative Classifier</h5>
        <h7>Discriminative classifier formally defined by a separating hyperplane</h7>
        <ul>
          <li><a target="_blank" title="" href="https://medium.com/@ankitnitjsr13/math-behind-support-vector-machine-svm-5e7376d0ee4d">
              <h5>Maximum Margin Hyperplane | Support Vectors</h5>
            </a></li>
          <h6>{x<sub><i>i</i></sub>, y<sub><i>i</i></sub>} where <i>i</i> = 1 . . . L, y<sub><i>i</i></sub> &#8712; {-1, 1}, x &#8712; &#8477;<sup>D</sup></h6>
        </ul>
      </li>
      <li><a target="_blank" title="Kernel Functions" href="https://towardsdatascience.com/kernel-function-6f1d2be6091" />
        <h5>Kernel SVM | Nonlinear</h5></a>
      </li>
      <h7>Mapping to a higher-dimensional space, applying the support vector algorithm & then projecting back to lower dimensional space resulting in a nonlinear separator</h7>
      <ul>
        <li><a target="_blank" title="The Math Behind SVM" href="https://medium.com/@ankitnitjsr13/math-behind-support-vector-machine-svm-5e7376d0ee4d">
            <h5>Linearly Separable with Hyperplane in 3D</h5>
          </a></li>
        <h6>&phi;(x<sub>1</sub>, x<sub>2</sub>) &#8658; (x<sub>1</sub>, x<sub>2</sub>, z) </h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">
            <h5>The Gaussian or Radial Basis Function (RBF) Kernel</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>K</mi>
              <mo stretchy="false">(</mo>
              <mi>x&#8407;, &nbsp;</mi>
              <msup>
                <mi>l&#8407;</mi>
                <mn>&nbsp;i</mn>
              </msup>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mi>exp</mi>
              <mo stretchy="true">(</mo>
              <mo>-</mo>
              <mfrac>
                <mrow>
                  <mi>|| x&#8407;, &nbsp;</mi>
                  <msup>
                    <mi>l&#8407;</mi>
                    <mn>&nbsp;i</mn>
                  </msup>
                  <msup>
                    <mi>||</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
                <mrow>
                  <mi>2</mi>
                  <msup>
                    <mi>&sigma;</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
              </mfrac>
              <mo stretchy="true">)</mo>
            </math><br />
          </h6>
        </div>
        <h6>&#8627; where:<br />
          <ul>
            &#8627; K = function applied to two vectors<br />
            &#8627; x = point in datasets<br />
            &#8627; <i>l</i> = landmark
          </ul>
        </h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="http://www.cs.toronto.edu/~duvenaud/cookbook/index.html">
            <h5>Sigmoid Kernel</h5>
          </a></li>
        <h6><i>K(X, Y)</i> = tanh(<i>&gamma; <b>&dot;</b> X<sup>T</sup>Y + r</i>)</h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="http://www.cs.toronto.edu/~duvenaud/cookbook/index.html">
            <h5>Polynomial Kernel</h5>
          </a></li>
        <h6><i>K(X, Y)</i> = tanh(<i>&gamma; <b>&dot;</b> X<sup>T</sup>Y + r</i>)<sup><i>d</i></sup>, <i>&gamma;</i> &#62; 0</h6>
      </ul>
      <li>
        <h5>Naive Bayes Classification</h5>
        <h7>Probabilistic classifier based on Bayes Theorem with an assumption of independence between predictors (aka, features or independent variables)</h7>
        <ul>
          <li>
            <h5>Bayes Theorem &#8658; The probability of an event given prior knowledge of related events that occurred earlier</h5>
            <div style="text-align: left;">
              <math id="bayes_theorem" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>P</mi>
                <mo stretchy="false">(</mo>
                <mi>y</mi>
                <mo>&#x2223;</mo>
                <msub>
                  <mi>x</mi>
                  <mn>1</mn>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;</mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mi>n</mi>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <mfrac>
                  <mrow>
                    <mi>P</mi>
                    <mo stretchy="false">(</mo>
                    <mi>y</mi>
                    <mo stretchy="false">)</mo>
                    <mi>P</mi>
                    <mo stretchy="false">(</mo>
                    <msub>
                      <mi>x</mi>
                      <mn>1</mn>
                    </msub>
                    <mo>,</mo>
                    <mo>&#x2026;</mo>
                    <mo>,</mo>
                    <msub>
                      <mi>x</mi>
                      <mi>n</mi>
                    </msub>
                    <mo>&#x2223;</mo>
                    <mi>y</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                  <mrow>
                    <mi>P</mi>
                    <mo stretchy="false">(</mo>
                    <msub>
                      <mi>x</mi>
                      <mn>1</mn>
                    </msub>
                    <mo>,</mo>
                    <mo>&#x2026;</mo>
                    <mo>,</mo>
                    <msub>
                      <mi>x</mi>
                      <mi>n</mi>
                    </msub>
                    <mo stretchy="false">)</mo>
                  </mrow>
                </mfrac>
              </math>
            </div>
          </li>
        </ul>
      </li>
      <li>
        <h5>K-Nearest Neighbors</h5>
        <h7>Used for classification & regression; a simple algorithm that stores all available cases & classifies new cases by a "majority vote" of its K-nearest neighbors</h7>
        <ul>
          <li>
            <h5>Euclidean Distance</h5>
            <div style="text-align: left;">
              <math id="euclidean" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>Between</mi>
                <msub>
                  <mi>P</mi>
                  <mn>1</mn>
                </msub>
                <mo stretchy="false"> & </mo>
                <msub>
                  <mi>P</mi>
                  <mn>2</mn>
                </msub>
                <mo>=</mo>
                <msqrt>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>1</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                  <msup>
                    <mi>2</mi>
                  </msup>
                  <mo stretchy="false">+</mo>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>y</mi>
                    <mn>2</mn>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>y</mi>
                    <mi>1</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                  <msup>
                    <mi>2</mi>
                  </msup>
                </msqrt>
              </math>
            </div>
          </li>
        </ul>
      </li>
    </ul>
    <a target="_blank" title="" href="https://en.wikipedia.org/wiki/Unsupervised_learning#:~:text=Unsupervised%20learning%20is%20a%20type,a%20minimum%20of%20human%20supervision" />
    <h4>Unsupervised Learning</h4></a>
    <h7><b>"Looks for previously undetected patterns in a data set with no
        pre-existing labels and with a minimum of human supervision"</b>
      <br />"[P]resent examples without any hint, leaving it to the algorithm to
      create a label. For instance, when we need to figure out how the groups inside
      a customer database can be partitioned into similar segments based on their
      characteristics and behaviors." <a target="_blank" href="https://www.wgu.edu/online-it-degrees/data-analytics-masters-program.html">WGU MSDA</a></h7>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>K-Means Clustering</h5></a>
      </li>
      <h7>Unsupervised algorithm which solves clustering problems; follows simple/easy way to classify a dataset through a certain number of clusters</h7>
      <ul>
        <li><a target="_blank" title="" href="https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce#:~:text=Within%20Cluster%20Sum%20of%20Squares&text=To%20calculate%20WCSS%2C%20you%20first,by%20the%20number%20of%20points.">
            <h5>Within Cluster Sum of Squares (WCSS)| Quantifiable metric to evaluate how certain number of clusters performs compared to different number of clusters</h5>
          </a></li>
        <h6>WCSS = <span id="wcss1" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>1</sub>)<sup>2</sup> + <span id="wcss2" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>2</sub>)<sup>2</sup>
          +<span id="wcss3" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>3</sub>)<sup>2</sup></h6>
        <h6>&#8627; where:<br />
          <ul>
            &#8627; distance = distance between each point inside cluster<br />
            &#8627; C = centroids, respectively<br />
          </ul>
        </h6>
      </ul>
      <li><a target="_blank" title="" href="https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html" />
        <h5>Apriori Association</h5></a>
      </li>
      <h7>Analyzes the association of specific preferences in customer transactions (movies watched, items purchased in convenience store - beer & pampers urban myth) to discover relationships and how items are associated with each other</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Support</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>Movie recommendation example: <br />
            &nbsp; &#8627; where M = specific <u>M</u>ovie<br />
            <br />
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Support(M)</mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi># of user watchlists containing M</mi>
                </mrow>
                <mrow>
                  <mi># of user watchlists</mi>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </div>
        <li><a target="_blank" title="" href="">
            <h5>Confidence</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Confidence</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>M</mi>
                <mn>1</mn>
              </msub>
              <mo>&#x2192;</mo>
              <msub>
                <mi>M</mi>
                <mi>2</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi># of user watchlists containing</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>&#x2192;</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi># of user watchlists containing</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>1</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </div>
        <li><a target="_blank" title="" href="">
            <h5>Lift &#8594; measuring the relevance of an associated rule & the improvement prediction</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Lift</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>M</mi>
                <mn>1</mn>
              </msub>
              <mo>&#x2192;</mo>
              <msub>
                <mi>M</mi>
                <mi>2</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>Confidence</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>&#x2192;</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>Support</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </div>
      </ul>
    </ul>
    <a target="_blank" href="https://en.wikipedia.org/wiki/Reinforcement_learning">
      <h4>Reinforcement Learning</h4>
    </a>
    <h7><b>"how software agents ought to take actions in an environment in order
        to maximize the notion of cumulative reward"</b>
      <br />"[P]resent examples without labels, as in unsupervised learning, but get
      feedback from the environment as to whether label guessing is correct or not.
      For instance, when we need software to act successfully in a competitive setting,
      such as a videogame or the stock market, we can use reinforcement learning.
      In this case, the software will then start acting in the setting and it will
      learn directly from its errors until it finds a set of rules that ensure its
      success." <a target="_blank" href="https://www.wgu.edu/online-it-degrees/data-analytics-masters-program.html">WGU MSDA</a></h7>
    <ul>
      <li>
        <h5>Upper Confidence Bound Algorithm | Deterministic Model</h5>
      </li>
      <a target="_blank" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">
        <h7>Modern application of Multi-Armed Bandit Problem (reference slot machine distributions)</h7>
      </a>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Advertising Model (requires update at every round)</h5>
          </a></li>
        <h6><u>Step 1</u>: Each round <i>n</i> considers two numbers for each ad <i>i</i>:<br />
          <ul>
            &nbsp; &#8627; <i>N<sub>i</sub></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> selected up to round <i>n</i><br />
            &nbsp; &#8627; <i>R<sub>i</sub></i>(<i>n</i>) &#x2192; &Sigma; of rewards of ad <i>i</i> up to round <i>n</i><br />
          </ul><br />
          <u>Step 2</u>: From these two numbers we compute:<br />
          <ul>
            &nbsp; &#8627; Average reward of ad <i>i</i> up to round <i>n</i> with:
        </h6>
        <div style="text-align: left;">
          <ul>
            <h6>&nbsp; &nbsp; &nbsp; &nbsp;
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>r&#772;</mi>
                <mo stretchy="false">(</mo>
                <mi>n</mi>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <mfrac>
                  <mrow>
                    <msub>
                      <mi>R</mi>
                      <mn>i</mn>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                  <mrow>
                    <msub>
                      <mi>N</mi>
                      <mn>i</mn>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                </mfrac>
              </math><br />
            </h6>
          </ul>
        </div>
        <ul>
          <h6>&nbsp; &#8627; Confidence interval [<i>r&#772;<sub>i</sub></i>(<i>n</i>) - &#x25B3;<sub><i>i</i></sub>(<i>n</i>), <i>r&#772;<sub>i</sub></i>(<i>n</i>) +
            &#x25B3;<sub><i>i</i></sub>(<i>n</i>)] at round <i>n</i> with:</h6>
        </ul>
        <div>
          <ul>
            <h6>&nbsp; &nbsp; &nbsp; &nbsp;
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <msub>
                  <mi>&#x25B3;</mi>
                  <mn>i</mn>
                </msub>
                <mo stretchy="false">(</mo>
                <mi>n</mi>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <msqrt>
                  <mfrac>
                    <mrow>
                      <mi>3</mi>
                    </mrow>
                    <mrow>
                      <mi>2</mi>
                    </mrow>
                  </mfrac>
                  <mo>*</mo>
                  <mfrac>
                    <mrow>
                      <mi>log</mi>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>N</mi>
                        <mn>i</mn>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                  </mfrac>
                </msqrt>
              </math><br />
            </h6>
          </ul>
        </div>
        <h6><u>Step 3</u>: Select the ad <i>i</i> that has the maximum UCB <i>r&#772;<sub>i</sub></i>(<i>n</i>) +
          &#x25B3;<sub><i>i</i></sub>(<i>n</i>)<br />
      </ul>
    </ul>
    </ul>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Thompson Sampling Algorithm | Probabilistic Model</h5>
        </a>
      </li>
      <a target="_blank" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">
        <h7>Constructs distributions of where we think the actual expected value might lie; an auxiliary mechanism to solve the problem</h7>
      </a>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Advertising Model (can accomodate delayed feedback & has better empirical evidence than UCB)</h5>
          </a></li>
        <h6><u>Step 1</u>: Each round <i>n</i> considers two numbers for each ad <i>i</i>:<br />
          <ul>
            &nbsp; &#8627; <i>N<sub>i</sub><sup>1</sup></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> rewarded 1 up to round <i>n</i><br />
            &nbsp; &#8627; <i>N<sub>i</sub><sup>0</sup></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> rewarded 0 up to round <i>n</i><br />
          </ul><br />
          <u>Step 2</u>: For each ad <i>i</i>, we take a random draw from the distribution below:<br />
          <ul>
            <br />
            <i>&theta;</i><sub>i</sub>(<i>n</i>) = <i>&beta;</i>(<i>N<sub>i</i></sub><sup>1</sup>(<i>n</i>) + 1, <i>N<sub>i</sub></i><sup>0</sup>(<i>n</i> + 1))
          </ul>
          <br />
        </h6>
        <h6><u>Step 3</u>: Select the ad <i>i</i> that has highest <i>&theta;</i><sub>i</sub>(<i>n</i>)<br />
      </ul>
    </ul>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Random Forest Regression</h5></a>
      </li>
      <h7>Ensemble decision trees; a collection of decision trees (aka forest) to classify a new object based on attributes; each tree gives a classification & we say the tree "votes" for the class </h7>
      <li><a target="_blank" title="" href="" />
        <h5>Dimensionality Reduction</h5></a>
      </li>
      <h7>Identifies highly significant variables when you have thousands</h7>
      <li><a target="_blank" title="" href="" />
        <h5>Gradient Boosting</h5></a>
      </li>
      <h7>Ensemble of machine learning algorithms</h7>
      <!-- <ul>
        <li><a target="_blank" title="" href="">
            <h5>Type</h5>
          </a></li>
        <h6>Equation</h6>
      </ul> -->
    </ul>
  </div>


  <br /><br />
  <div id="Deep_Learning">
    <h3>Lovely Deep Learning</h3>
    <div id="ANNs">
      <a id="definition" target="_blank" href="https://towardsdatascience.com/understanding-neural-networks-what-how-and-why-18ec703ebd31">
        <h4>Artificial Neural Networks</h4>
      </a>
      <h7><b>&nbsp; &#8627; A computing system that consist of a number of simple but highly interconnected elements or nodes, called ‘neurons’, which are organized in layers which process information using dynamic state responses to external inputs,
          an extremely useful algorithm for finding patterns too complex to be manually extracted</b></h7>
      <ul>
        <li><a target="_blank" title="Understanding neural networks 1: The concept of neurons" href="https://becominghuman.ai/understanding-neural-networks-1-the-concept-of-neurons-287be36d40f" />
          <h5>Neuron Definition</h5></a>
        </li>
        <h7>A mathematical operation that takes its input, multiplies it by its weight & then passes the sum through an activation function</h7>
        <ul>
          <li><a target="_blank" title="Understanding neural networks 2: The math of neural networks in 3 equations" href="https://becominghuman.ai/understanding-neural-networks-2-the-math-of-neural-networks-in-3-equations-6085fd3f09df">
              <h5>Neuron Formula</h5>
            </a></li>
          <h6>Y<sub>1</sub> = activation(w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub> + . . . + w<sub>m</sub>x<sub>m</sub>)</h6>
          <li><a target="_blank" title="Understanding neural networks 2: The math of neural networks in 3 equations" href="https://becominghuman.ai/understanding-neural-networks-1-the-concept-of-neurons-287be36d40f">
              <h5>Sigmoid Activation Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>1 &nbsp;</mi>
                </mrow>
                <mrow>
                  <mi>1 &nbsp; +</mi>
                  <msup>
                    <mi>&nbsp; e</mi>
                    <mn>-z</mn>
                  </msup>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Threshold Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mo stretchy="true">{</mo>
              <mrow>
                <mi>1 if x &#x2265; 0</mi>
              </mrow>
              <mrow>
                <mi>&nbsp;,&nbsp;0 if x < 0</mi>
              </mrow>
              <mo stretchy="true">}</mo>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Rectifier Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mo stretchy="false">(</mo>
              <mi>x, 0</mi>
              <mo stretchy="false">)</mo>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Hyperbolic Tangent Function (tanh)</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>1&nbsp; - &nbsp;</mi>
                  <msup>
                    <mi>e</mi>
                    <mn>-2x</mn>
                  </msup>
                </mrow>
                <mrow>
                  <mi>1&nbsp; + &nbsp;</mi>
                  <msup>
                    <mi>e</mi>
                    <mn>-2x</mn>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </ul>
      </ul>
    </div>
    <div id="CNNs">
      <a id="definition" target="_blank" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">
        <h4>Convolutional Neural Networks</h4>
      </a>
      <h7><b>&nbsp; &#8627; A class of deep neural networks, most commonly applied to analyzing visual imagery. CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each
          neuron in one layer is connected to all neurons in the next layer.</b></h7>
      <ul>
        <li><a target="_blank" title="" href="" />
          <h5>Convolution | Visual Imagery Analysis</h5></a>
        </li>
        <h7>A special kind of mathematical linear operation to give a network a degree of translation invariance; eg, a typical image convolution is a form of blurring</h7>
      </ul>
    </div>
    <div id="NLPs">
      <a id="definition" target="_blank"
        href="https://classroom.udacity.com/nanodegrees/nd009t/parts/c4bacd6f-3766-4b62-994f-23e44e4c1f68/modules/52fce89d-5551-4d94-8bdc-48089274b27b/lessons/ab4cc389-336f-401c-937a-54f8c2aea24c/concepts/f5efb207-200c-4194-9ada-1189f4d66312">
        <h4>Natural Language Processing</h4>
      </a>
      <h7><b>&nbsp; &#8627; Starts with raw text in whatever format available, processes it, extracts relevant features and builds models to accomplish various NLP tasks</b></h7>
      <ul>
        <li><a target="_blank" title="" href="" />
          <h5>NLP Pipeline</h5></a>
        </li>
        <h6>Text Processing &nbsp; &#8658; &nbsp; Feature Extraction &nbsp; &#8658; &nbsp; Modeling</h6>
        <ul>
          <li>
            <h5>Document-Term Matrix</h5>
            <h7>Compute dot product (sum of the products of corresponding elements) to find similarities</h7>
            <h6>a * b = &Sigma; (a<sub>1</sub>b<sub>1</sub> + a<sub>2</sub>b<sub>2</sub> + a<sub>3</sub>b<sub>3</sub> + . . . + a<sub>n</sub>b<sub>n</sub>)</h6>
          </li>
          <li>
            <h5>Cosine Similarity</h5>
            <h7>Divide the product of two vectors by their magnitudes or Euclidean norms</h7>
            <h6>
              <math>
                <mi>cos(&theta;) = </mi>
                <mfrac>
                  <mrow>
                    <mi>a*b</mi>
                  </mrow>
                  <mrow>
                    <mi>||a||*||b||</mi>
                  </mrow>
                </mfrac>
                <br />&nbsp; &#8627; where:
                <br />&nbsp; &nbsp; &nbsp; Identical vectors &#x2192; cos(&theta;) = 1
                <br />&nbsp; &nbsp; &nbsp; Orthogonal vectors &#x2192; cos(&theta;) = 0
                <br />&nbsp; &nbsp; &nbsp; Exact opposite vectors &#x2192; cos(&theta;) = -1
              </math>
            </h6>
          </li>
          <li>
            <h5>TF-IDF Transform</h5>
            <h7>Term frequency-inverse document frequency</h7>
            <br />
            <h6>
              <mi>tfidf(t, d, D) = tf(t, d) * idf(t, D)</mi>
              <br />&nbsp; &#8627; where:
              <br />&nbsp; &nbsp; &nbsp;
              <mi>tf(t, d) = </mi>
              <math>
                <mi></mi>
                <mfrac>
                  <mrow>
                    <mi>count(t, d)</mi>
                  </mrow>
                  <mrow>
                    <mi>|d|</mi>
                  </mrow>
                </mfrac>
              </math>
              <br />&nbsp; &nbsp; &nbsp;
              <mi>idf(t, D) = </mi>
              <math>
                <mi>Log</mi>
                <mo stretchy=True>(</mo>
                <mfrac>
                  <mrow>
                    <mi>|D|</mi>
                  </mrow>
                  <mrow>
                    <mi>|{d &#8712; D : t &#8712; d}|</mi>
                  </mrow>
                </mfrac>
                <mo stretchy=True>)</mo>
              </math>
            </h6>
          </li>
        </ul>
        <li>
          <h5>Stemming</h5>
          <h7>Takes the root of a word removing conjugation to simplify & understand gist meaning (reducing final dimension )</h7>
        <li><a target="_blank" title="" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html#:~:text=Lemmatization%20usually%20refers%20to%20doing,is%20known%20as%20the%20lemma%20." />
        </li>
        <h5>Lemmatization</h5></a>
        </li>
        <h7>Refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.</>
      </ul>
    </div>
  </div>

  <br /><br />
  <div id="Mathematics">
    <h3 style="color: #F4B400;"><b>Mathematics</b></h3>
    <h7><b>Etymology</b>: <a target="_blank" href="https://en.wikipedia.org/wiki/Mathematics">The word mathematics comes from Ancient Greek máthēma (μάθημα), meaning "that which is learnt," "what one gets to know," hence also "study" and
        "science".</a></h7>
  </div>

  <br /><br />
  <div id="Linear_Algebra">
    <h3>Intimate Linear Algebra</h3>
    <h7>The study of linear equations & geometric transformations using matrices,
      vectors spaces & determinants</h7>
    <h4>Fundamental Data Science</h4>
    <ul>
      <li>
        <h5>Linear Regression</h5>
        <ul>
          <li>
            <h5>Matrix-Vector Multiplication Function</h5>
            <h6>
              <math>
                <mrow>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>y</mi>
                          <mn>1</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>y</mi>
                          <mn>2</mn>
                        </msub>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <mn>1</mn>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>11</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>12</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>13</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <mn>1</mn>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>21</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>22</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>23</mn>
                        </msub>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                </mrow>
                <mrow>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>0</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>1</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>2</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>3</mn>
                        </msub>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                </mrow>
                <mo>&nbsp; + &nbsp;</mo>
                <mrow>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&epsilon;</mi>
                          <mn>1</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&epsilon;</mi>
                          <mn>2</mn>
                        </msub>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                </mrow>
              </math>
              <br />&nbsp; &#8627; where:
              <br />&nbsp; &nbsp; &nbsp;
              <math>
                <mi>Vector of Outcomes for Each Case</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mo>[</mo>
                <mtable>
                  <mtr>
                    <mtd>
                      <msub>
                        <mi>y</mi>
                        <mn>1</mn>
                      </msub>
                    </mtd>
                  </mtr>
                  <mtr>
                    <mtd>
                      <msub>
                        <mi>y</mi>
                        <mn>2</mn>
                      </msub>
                    </mtd>
                  </mtr>
                </mtable>
                <mo>]</mo>
                <br />&nbsp; &nbsp; &nbsp;
                <math>
                  <mi>Matrix of Scores for Each Case</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <mn>1</mn>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>11</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>12</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>13</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <mn>1</mn>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>21</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>22</mn>
                        </msub>
                      </mtd>
                      <mtd>
                        <msub>
                          <mi>x</mi>
                          <mn>23</mn>
                        </msub>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                </math>
                <br />&nbsp; &nbsp; &nbsp;
                <math>
                  <mi>Vector of Regression Coefficients (y-intercept & slopes)</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>0</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>1</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>2</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&beta;</mi>
                          <mn>3</mn>
                        </msub>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                </math>
                <br />&nbsp; &nbsp; &nbsp;
                <math>
                  <mi>Vector of Error Terms</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&epsilon;</mi>
                          <mn>1</mn>
                        </msub>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <msub>
                          <mi>&epsilon;</mi>
                          <mn>2</mn>
                        </msub>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                </math>
            </h6>
          </li>
      </li>
      <li>
        <h5>Matrix Notation</h5>
        <h6>
          <math>
            <mn>Y</mn>
            <mo>&nbsp; = &nbsp;</mo>
            <mn>X</mn>
            <mn>&beta;</mn>
            <mo>&nbsp; + &nbsp;</mo>
            <mn>&epsilon;</mn>
          </math>
        </h6>
      </li>
      <li>
        <h5>Sparse Matrix</h5>
        <h7>In numerical analysis and scientific computing, a sparse matrix or sparse array is a matrix in which most of the elements are zero.</h7>
      </li>
    </ul>
    </ul>
    <h4>Determinants</h4>
    <a target="_blank" href="https://en.wikipedia.org/wiki/Determinant">
      <h7><b>&nbsp; &#8627; The volume scaling factor of the linear transformation described by the matrix</b></h7>
    </a>
    <ul>
      <li>
        <h5>Square Matrices</h5>
        <ul>
          <li>
            <h5>Determinant Equation 2x2 Matrix</h5>
            <h6>
              <math>
                <mrow>
                  <mo>|</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <mn>a</mn>
                      </mtd>
                      <mtd>
                        <mn>b</mn>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <mn>c</mn>
                      </mtd>
                      <mtd>
                        <mn>d</mn>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>|</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mn>ad</mn>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mn>bc</mn>
                </mrow>
              </math>
            </h6>
          </li>
          <li>
            <h5>Trace of Matrix</h5>
            <h7>Equal to the sum of the values along the main diagonal</h7>
            <h6>
              <math>
                <mrow>
                  <mi>Trace </mi>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <mn>a</mn>
                      </mtd>
                      <mtd>
                        <mn>b</mn>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <mn>c</mn>
                      </mtd>
                      <mtd>
                        <mn>d</mn>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mn>a</mn>
                  <mo>&nbsp; + &nbsp;</mo>
                  <mn>d</mn>
                </mrow>
              </math>
            </h6>
          </li>
        </ul>
      </li>
    </ul>
    <a target="_blank" title="No BS Guide to Linear Algebra" href="https://github.com/minireference/noBSLAnotebooks#chapters-overview">
      <h4>Geometrical Aspects of Linear Algebra</h4>
    </a>
    <h7><b>&nbsp; &#8627; Mathematics to used see through to the governing dynamics of the physical universe</b></h7>
    <ul>
      <li><a target="_blank" title="Intuitive Math" href="https://intuitive-math.club/" />
        <h5>Orthogonality & Change of Basis</h5></a>
        <ul>
          <li><a target="_blank" title="" href="">
              <h5>Least Squares Solution</h5>
            </a>
            <h6>
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <msup>
                  <mi>A</mi>
                  <mn>T</mn>
                </msup>
                <mi>A</mi>
                <msup>
                  <mi>x&#8407;</mi>
                  <mn>*</mn>
                </msup>
                <mo>=</mo>
                <msup>
                  <mi>A</mi>
                  <mn>T</mn>
                </msup>
                <mi> b&#8407; </mi>
              </math>
            </h6>
          </li>
      </li>
    </ul>
    <li>
      <h5>Orthonormal Bases</h5>
      <ul>
        <li>
          <h5>Orthogonality</h5>
          <h7>Every vector in set is orthogonal to every other vector in set; as perpendicular is to two-dimensional space (vectors at 90&#176; angle), orthogonal is to three- or n-dimensional space.</h7>
          <h6>
            <math>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&#8901;</mo>
              <msub>
                <mi>v&#8407;</mi>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>0</mo>
            </math>
          </h6>
        </li>
        <li>
          <h5>Normality</h5>
          <h7>Every vector has been normalized; every vector has a length of 1.</h7>
          <h6>
            <math>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&#8901;</mo>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>&#8741;</mo>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&#8741;</mo>
              <msup>
                <mi></mi>
                <mn>2</mn>
              </msup>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>1</mo>
            </math>
          </h6>
        </li>
        <li>
          <h5>Projection onto an Orthonormal Basis</h5>
          <h7>Using an orthonormal subspace drastically simplifies projection equation from:</h7>
          <h6>
            <math>
              <msub>
                <mi>Proj</mi>
                <mn>v</mn>
              </msub>
              <mi>x&#8407;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>A</mo>
              <mo>(</mo>
              <msup>
                <mn>A</mn>
                <mn>T</mn>
              </msup>
              <mn>A</mn>
              <mo>)</mo>
              <msup>
                <mn></mn>
                <mn>-1</mn>
              </msup>
              <msup>
                <mn>A</mn>
                <mn>T</mn>
              </msup>
              <mi>x&#8407;</mi>
            </math>
            <br />
            <mn>&emsp;&emsp;&emsp;&nbsp; &#8595;</mn>
            <br />
            <math>
              <msub>
                <mi>Proj</mi>
                <mn>v</mn>
              </msub>
              <mi>x&#8407;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mn>A</mn>
              <msup>
                <mn>A</mn>
                <mn>T</mn>
              </msup>
              <mi>x&#8407;</mi>
            </math>
          </h6>
        </li>
        <li>
          <h5>Gram-Schmidt Process</h5>
          <h7>Converts non-orthonormal set into an orthonormal set</h7>
          <h6>
            <math>
              <mi>Subspace v</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
              <mi>&emsp;&emsp;&emsp;&emsp;Step 1: &emsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <msub>
                    <mn>v&#8407;</mn>
                    <mn>1</mn>
                  </msub>
                </mrow>
                <mrow>
                  <mn>&#8741;</mn>
                  <msub>
                    <mn>v&#8407;</mn>
                    <mn>1</mn>
                  </msub>
                  <mn>&#8741;</mn>
                </mrow>
              </mfrac>
            </math>
            <br />
            <mi>&emsp;&emsp;&emsp;&emsp;&ensp;</mi>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
              <mi>&emsp;&emsp;&emsp;&emsp; Step 2: &emsp;</mi>
              <msub>
                <mn>w&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; - &nbsp;</mo>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; &#8901; &nbsp;</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>)</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
            </math>
            <br />
            <mi>&emsp;&emsp;&emsp;&emsp;&ensp;</mi>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
              <mi>&emsp;&emsp;&emsp;&emsp; Step 3: &emsp;</mi>
              <msub>
                <mn>w&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; - &nbsp;</mo>
              <mo>[</mo>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; &#8901; &nbsp;</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>)</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; &#8901; &nbsp;</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>)</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>]</mo>
            </math>
            <br />
            <mi>&emsp;&emsp;&emsp;&emsp;&ensp;</mi>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
            </math>
          </h6>
        </li>
      </ul>
    <li>
      <h5>Eigenvalues & Eigenvectors</h5>
      <a target="_blank" href="https://www.reddit.com/r/explainlikeimfive/comments/1avwm7/eli5_eigenvalues_and_eigenvectors_and_why_are/">
        <h7>Literally "special" or "self" values/vectors that correspond to a matrix or linear transformation; a way to diagonalize a problem, adjusting specific parts without disturbing others</h7>
      </a>
      <ul>
        <li>
          <h5>Eigenvector Transformation <a target="_blank" href="https://www.youtube.com/watch?v=PFDu9oVAE-g">( Brilliant 3Blue1Brown visualization)</a></h5>
          <h6>
            <math>
              <mi>T(v&#8407;)</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>Av&#8407;</mi>
            </math>
            <br />
            <math>
              <mi>T(v&#8407;)</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>&lambda;v&#8407;</mi>
              <br />&nbsp; &#8627; where:
              <br />&nbsp; &nbsp; &nbsp;
            </math>
            <math>
              <mi>&lambda;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>eigenvalue; a scalar</mi>
            </math>
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <mn>v&#8407; </mn>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>eigenvector</mi>
            </math>
            <br />
            <math>
              <mo>&#8756; &nbsp; </mo>
              <mi>Av&#8407;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>&lambda;v&#8407;</mi>
            </math>
            <br />&nbsp; &#8627; algebraically:
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <mo>0&#8407;</mo>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>(</mo>
              <mo>&lambda;</mo>
              <msub>
                <mn>I</mn>
                <mn>n</mn>
              </msub>
              <mo>&nbsp; - &nbsp;</mo>
              <mo>A</mo>
              <mo>)</mo>
              <mn>v&#8407;</mn>
            </math>
          </h6>
        </li>
        <li>
          <h5>Eigenspace (E<sub>&lambda;</sub>)</h5>
          <h6>
            <math>
              <mrow>
                <msub>
                  <mn>E</mn>
                  <mn>&lambda;</mn>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <mn>N</mn>
                <mo>(</mo>
                <mn>&lambda;</mn>
                <msub>
                  <mn>I</mn>
                  <mn>n</mn>
                </msub>
                <mo>&nbsp; - &nbsp;</mo>
                <mn>A</mn>
                <mo>)</mo>
              </mrow>
            </math>
            <br />&nbsp; &#8627; where:
            <br />&emsp;
            <math>
              <mrow>
                <mn>N</mn>
                <mo>&nbsp; = &nbsp;</mo>
                <mn>Null Space</mn>
              </mrow>
            </math>
            <br />&emsp;
            <math>
              <mrow>
                <msub>
                  <mn>I</mn>
                  <mn>n</mn>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>Identity Matrix</mi>
              </mrow>
            </math>
          </h6>
        </li>
      </ul>
    </li>
    <li>
      <h5>Fast Fourier Transformation</h5>
      <h7>"A fast Fourier transform is an algorithm that computes the discrete
        Fourier transform of a sequence, or its inverse. Fourier analysis converts
        a signal from its original domain to a representation in the frequency
        domain and vice versa." <a target="_blank" href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">Wikipedia</a></h7>
    </li>
    </li>
    </ul>
  </div>

  <br /><br />
  <div id="Statistics_Probabilities">
    <h3>Salient Statistics & Probabilities</h3>
    <h7><b>Statistics is the art of making numerical conjectures about puzzling questions.<br />
        &#8627; Is statistics a field of mathematics? Some say it is not mathematics but the science of data. Whatever you decide, you must embrace it, my Dear Friends.</b></h7>
    <h4>Terminology</h4>
    <ul>
      <li>
        <h5><u><b>Index</b></u>: a descriptive statistic made up of other descriptive statistics that consolidates lots of information into a single number</h5>
      </li>
    </ul>
    <h4>Probability</h4>
    <h7><b>Generalizing logic to situations with uncertain outcomes & measurements,
        & incomplete theories; the possible outcomes of events.</b>
      <br />"The formalization of probability, combined with the availability of data,
      led to the emergence of statistics as a field."
      <a target="_blank" href="https://www.amazon.com/Artificial-Intelligence-A-Modern-Approach-dp-0134610997/dp/0134610997/ref=dp_ob_image_bk">Artificial Intelligence: A Modern Approach, pg 8</a></h7>
    <ul>
      <li>
        <h5>Basic Formulae</h5>
      </li>
      <ul>
        <li>
          <h5>Probability of an Event</h5>
        </li>
        <h6>
          <math>
            <mi>P(A)</mi>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>Outcome(s) You Are Looking For</mi>
              </mrow>
              <mrow>
                <mi>Total Possible Outcomes</mi>
              </mrow>
            </mfrac>
            <mo>&#8658;</mo>
            <mfrac>
              <mrow>
                <mi>Event</mi>
              </mrow>
              <mrow>
                <mi>Sample space</mi>
              </mrow>
            </mfrac>
            <mo>&#8658;</mo>
            <mfrac>
              <mrow>
                <mi>A, B, etc.</mi>
              </mrow>
              <mrow>
                <mo>S</mo>
              </mrow>
            </mfrac>
          </math>
        </h6>
        <li>
          <h5>Complement of an Event</h5>
        </li>
        <h6>
          <math>
            <mi>P(A&#772;)</mi>
            <mo>=</mo>
            <mi> 1 - P(A)</mi>
          </math>
        </h6>
        <li>
          <h5>Union(&#8746;, Or) & Intersection(&#8745;, And)</h5>
        </li>
        <h6>P(A &#8746; B) = P(A) + P(B) - P(A &#8745; B)</h6>
      </ul>
      <li>
        <h5>Permutations & Combinations</h5>
        <ul>
          <li>
            <h5>The Combinatorial Explosion</h5>
            <h6>
              <math>
                <mo>P</mo>
                <mo stretchy=False>(</mo>
                <mi>n</mi>
                <mo>, </mo>
                <mi>r</mi>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mi>n</mi>
                    <mo>!</mo>
                  </mrow>
                  <mrow>
                    <mo>(</mo>
                    <mi>n</mi>
                    <mo>&nbsp; - &nbsp;</mo>
                    <mi>r</mi>
                    <mo>)</mo>
                    <mo>!</mo>
                  </mrow>
                </mfrac>
              </math>
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Bayes' Theorem</h5>
        <h7>Tells the probability of an event given prior knowledge of related events that occurred earlier</h7>
        <ul>
          <li>
            <h5>Bayesian Analysis: Probability of B given A</h5>
            <h6>
              <math>
                <mn>Posterior</mn>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>likelihood * prior</mn>
                  </mrow>
                  <mrow>
                    <mn>marginal</mn>
                  </mrow>
                </mfrac>
              </math>
              <br /><br />
              <math>
                <mn>P</mn>
                <mo stretchy=False>(</mo>
                <mn>A | B</mn>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>P</mn>
                    <mo stretchy=False>(</mo>
                    <mn>B | A</mn>
                    <mo stretchy=False>)</mo>
                    <mo>&nbsp; * &nbsp;</mo>
                    <mn>P</mn>
                    <mo stretchy=False>(</mo>
                    <mn>A</mn>
                    <mo stretchy=False>)</mo>
                  </mrow>
                  <mrow>
                    <mn>P</mn>
                    <mo stretchy=False>(</mo>
                    <mn>B</mn>
                    <mo stretchy=False>)</mo>
                  </mrow>
                </mfrac>
              </math>
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <a target="_blank" href="https://www.britannica.com/science/random-walk#ref77569">
          <h5>Random Walk</h5>
        </a>
        <h7>"A process for determining the probable location of a point subject to random motions, given the probabilities (the same at each step) of moving some distance in some direction. Random walks are an
          example of Markov processes, in which future behaviour is independent of past history."</h7>
      </li>
      <li>
        <a target="_blank" href="https://www.britannica.com/science/random-walk#ref77569">
          <h5>Drunkard's Walk</h5>
        </a>
        <h7>"A typical example is the drunkard’s walk, in which a point beginning at the origin of the Euclidean plane moves a distance of one unit for each unit of time, the direction of motion, however, being random at each step. The problem is to
          find, after some fixed time, the probability distribution function of the distance of the point from the origin. Many economists believe that stock market fluctuations, at least over the short run, are random walks." This is observed in
          Brownian Motion.</h7>
      </li>
    </ul>

    <div id="Descriptive_Statistics">
      <h4>Descriptive Statistics</h4>
      <h7><b>"Descriptive statistics are brief descriptive coefficients that summarize
          a given data set, which can be either a representation of the entire or a sample
          of a population. Descriptive statistics are broken down into measures of central
          tendency and measures of variability (spread)." <a href="https://www.investopedia.com/terms/d/descriptive_statistics.asp"><i>Investopedia</i></a></b></h7>
      <br />
      <h7>Used to describe data; <b>univariate analysis</b> on a single variable or <b>multivariate analysis</b> when looking at two or more variables in the dataset</h7>
      <ul>
        <li>
          <h5>Moments of Statistics</h5>
          <ol>
            <li>
              <h6>Location</h6>
            </li>
            <li>
              <h6>Variability</h6>
            </li>
            <li>
              <h6>Skewness</h6>
            </li>
            <li>
              <h6>Kurtosis</h6>
            </li>
          </ol>
        </li>
        <li>
          <h5>Estimates of Location (Measures of Central Tendency)</h5>
          <ul>
            <li>
              <h5>Mean</h5>
              <h6>
                <math>
                  <mn>x&#772;</mn>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <msup>
                        <mo>&Sigma;</mo>
                        <mi>n</mi>
                        <mi>i=1</mi>
                      </msup>
                      <msub>
                        <mi>&nbsp;x</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                    <mrow>
                      <mn>n</mn>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Trimmed Mean</h5>
              <h6>
                <math>
                  <mn>x&#772;</mn>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <msup>
                        <mo>&Sigma;</mo>
                        <mi>n - p</mi>
                        <mi>i = p + 1</mi>
                      </msup>
                      <msub>
                        <mi>&nbsp;x</mi>
                        <mi>(i)</mi>
                      </msub>
                    </mrow>
                    <mrow>
                      <mn>n</mn>
                      <mo>&nbsp;-&nbsp;</mo>
                      <mn>2</mn>
                      <mi>p</mi>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Weighted Mean</h5>
              <h6>
                <math>
                  <msub>
                    <mn>x&#772;</mn>
                    <mi>w</mi>
                  </msub>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <msup>
                        <mo>&Sigma;</mo>
                        <mi>n</mi>
                        <mi>i=1</mi>
                      </msup>
                      <mo>&nbsp;</mo>
                      <msub>
                        <mi>w</mi>
                        <mi>i</mi>
                      </msub>
                      <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                    <mrow>
                      <msup>
                        <mo>&Sigma;</mo>
                        <mi>n</mi>
                        <mi>i=1</mi>
                      </msup>
                      <mo>&nbsp;</mo>
                      <msub>
                        <mi>w</mi>
                        <mi>i</mi>
                      </msub>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
          </ul>
        </li>
        <li>
          <h5>Estimates of Variability</h5>
          <h7>Second dimension (after estimate of location) in summarizing a feature,
            aka <i>dispersion,</i> measures whether data are tightly packed or spread out.</h7>
          <ul>
            <li>
              <h5>Mean Absolute Deviation</h5>
              <h6>
                <math>
                  <mi>mean absolute deviation</mi>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <msup>
                        <mo>&Sigma;</mo>
                        <mi>n</mi>
                        <mi>i=1</mi>
                      </msup>
                      <mo>&nbsp;</mo>
                      <mo>|</mo>
                      <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                      </msub>
                      <mo>-</mo>
                      <mi>x&#772;</mi>
                      <mo>|</mo>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Variance</h5>
              <h6>
                <math>
                  <msup>
                    <mi>s</mi>
                    <mn>2</mn>
                  </msup>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <msup>
                        <mo>&Sigma;</mo>
                        <mi>n</mi>
                        <mi>i=1</mi>
                      </msup>
                      <mo>&nbsp;</mo>
                      <mo>(</mo>
                      <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                      </msub>
                      <mo>-</mo>
                      <mi>x&#772;</mi>
                      <mo>)</mo>
                      <msup>
                        <mn></mn>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                      <mo>-</mo>
                      <mn>1</mn>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Standard Deviation</h5>
              <h7>"Sort of" the average distance from the mean.</h7>
              <h6>
                <math>
                  <mi>s</mi>
                  <mo>=</mo>
                  <msqrt stretchy=True>
                    <mfrac>
                      <mrow>
                        <msup>
                          <mo>&Sigma;</mo>
                          <mi>n</mi>
                          <mi>i=1</mi>
                        </msup>
                        <mo>&nbsp;</mo>
                        <mo>(</mo>
                        <msub>
                          <mi>x</mi>
                          <mi>i</mi>
                        </msub>
                        <mo>-</mo>
                        <mi>x&#772;</mi>
                        <mo>)</mo>
                        <msup>
                          <mn></mn>
                          <mn>2</mn>
                        </msup>
                      </mrow>
                      <mrow>
                        <mi>n</mi>
                        <mo>-</mo>
                        <mn>1</mn>
                      </mrow>
                    </mfrac>
                  </msqrt>
                </math>
              </h6>
            </li>
            <li>
              <h5>Median Absolute Deviation (MAD)</h5>
              <h6>* A robust estimate of variability as opposed to variance & standard deviation.
                <br />
                <br />
                <math>
                  <mi>MAD</mi>
                  <mo>=</mo>
                  <mi>Median</mi>
                  <mo stretchy=True>(</mo>
                  <mo>|</mo>
                  <msub>
                    <mi>x</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>-</mo>
                  <mi>m</mi>
                  <mo>|</mo>
                  <mo>,&nbsp;</mo>
                  <mo>|</mo>
                  <msub>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msub>
                  <mo>-</mo>
                  <mi>m</mi>
                  <mo>|</mo>
                  <mo>,&nbsp;...,</mo>
                  <mo>|</mo>
                  <msub>
                    <mi>x</mi>
                    <mn>n</mn>
                  </msub>
                  <mo>-</mo>
                  <mi>m</mi>
                  <mo>|</mo>
                  <mo stretchy=True>)</mo>
                </math>
              </h6>
            </li>
          </ul>
        </li>
        <li>
          <h5>Data Distribution</h5>
          <ul>
            <li>
              <h5>Empirical Rule or Three Sigma Rule</h5>
              <h7>Symmetrically distributed data follows a pattern whereby most
                data points fall within three standard deviations of the mean.</h7>
            </li>
            <li>
              <h5>Relative Frequency</h5>
              <h7>The proportion of times a value occurs in a dataset.</h7>
            </li>
            <li>
              <h5>Z-Scores</h5>
              <h7>A measure of the number of standard deviations a particular data point is from the mean.</h7>
              <h6>
                <math>
                  <mi>z</mi>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>Observed</mi>
                      <mo>&nbsp;-&nbsp;</mo>
                      <mi>x&#772;</mi>
                    </mrow>
                    <mrow>
                      <mi>s</mi>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Percentile Rank</h5>
              <h6>
                <math>
                  <mi>percentile rank</mi>
                  <mo>=</mo>
                  <mo stretchy=True>[</mo>
                  <mfrac>
                    <mrow>
                      <mo>(</mo>
                      <mi># of values below x</mi>
                      <mo>)</mo>
                      <mo>+</mo>
                      <mn>0.5</mn>
                    </mrow>
                    <mrow>
                      <mi>total # of values</mi>
                    </mrow>
                  </mfrac>
                  <mo stretchy=True>]</mo>
                  <mn>100</mn>
                </math>
              </h6>
            </li>
            <li>
              <h5>Percentile: Precise Definition</h5>
              <h7>Take any value between the <i>order statistics</i> (sorted or
                ranked data) <i>x</i><sub>(<i>j</i>)</sub> & <i>x</i><sub>(<i>j</i>
                  + 1)</sub> where <i>j</i> satisfies:</h7>
              <h6>
                <math>
                  <mn>100</mn>
                  <mo>*</mo>
                  <mfrac>
                    <mrow>
                      <mi>j</mi>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                  <mo>&#8804;</mo>
                  <mi>P</mi>
                  <mo>&#60;</mo>
                  <mn>100</mn>
                  <mo>*</mo>
                  <mfrac>
                    <mrow>
                      <mi>j</mi>
                      <mo>+</mo>
                      <mn>1</mn>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
              <h7>The percentile is the weighted average:</h7>
              <h6>
                <math>
                  <mn>Percentile</mn>
                  <mo>(</mo>
                  <mi>P</mi>
                  <mo>)</mo>
                  <mo>=</mo>
                  <mo stretchy=True>(</mo>
                  <mn>1</mn>
                  <mo>-</mo>
                  <mi>w</mi>
                  <mo stretchy=True>)</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>(j)</mi>
                  </msub>
                  <mo>+</mo>
                  <mi>w</mi>
                  <msub>
                    <mi>x</mi>
                    <mi>(j + 1)</mi>
                  </msub>
                </math>
              </h6>
              <h7>for some weight between 0 & 1.</h7>
            </li>
            <li>
              <h5>N-Quantiles</h5>
              <ul>
                <li>
                  <h5>Index <i>i</i> for <i>k-th</i> cut point</h5>
                  <div id="index-kth-cut-point">
                    <h6>
                      <math>
                        <mi>i</mi>
                        <mo>&nbsp; = &nbsp;</mo>
                        <mo>[</mo>
                        <mfrac>
                          <mrow>
                            <mi>k</mi>
                          </mrow>
                          <mrow>
                            <mi>n</mi>
                          </mrow>
                        </mfrac>
                        <mo stretchy=False>(</mo>
                        <mi>d</mi>
                        <mo>&nbsp; - &nbsp;</mo>
                        <mn>1</mn>
                        <mo stretchy=False>)</mo>
                        <mo>]</mo>
                        <mo>&nbsp; + &nbsp;</mo>
                        <mn>1</mn>
                      </math>
                    </h6>
                  </div>
                </li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <h5>Binary & Categorical Data</h5>
          <h7>Simple proportions or percentages tell the story of the data</h7>
          <ul>
            <li>
              <h5>Expected Value (EV)</h5>
              <h7>When the categories can be associated with a numeric value, this
                gives an average value based on a category's probability of occurrence.
                A form of weighted mean in which the weigths are probabilities, the
                EV adds the ideas of future expectations & probability weights,
                often based on subjective judgements.</h7>
              <ol>
                <li>
                  <h6>Multiply each outcome by its probability of occurrence.</h6>
                </li>
                <li>
                  <h6>Sum theses values.</h6>
                </li>
              </ol>
              <h6>&emsp; &emsp; EV = (weight as %)(component value) + (weight as %)(component value) + (weight as %)(component value)</h6>
            </li>
            <li>
              <h5>Probability</h5>
              <h7><b>Probability is essentially a ratio. The ratio of a particular event or outcome versus all the possible outcomes.</b>
                <br />Total probability of sample space: the sum of probabilities of
                all possible outcomes must add up to 100%.</h7>
              <ul>
                <li>
                  <h5>Objective Probability</h5>
                  <h7>"Objective probability refers to the chances or the odds
                    that an event will occur based on the analysis of concrete
                    measures rather than hunches or guesswork. ... The probability
                    estimate is computed using mathematical equations that manipulate
                    the data to determine the likelihood of an independent event
                    occurring." <a target="_blank"
                      href="https://www.investopedia.com/terms/o/objective-probability.asp#:~:text=Objective%20probability%20refers%20to%20the,rather%20than%20hunches%20or%20guesswork.&text=The%20probability%20estimate%20is%20computed,of%20an%20independent%20event%20occurring."><i>Investopedia</i></a>
                  </h7>
                  <ul>
                    <li>
                      <h5>Classical</h5>
                      <h7>All possible outcomes are known & equally ikely; everything
                        is fair & equal, eg, a coin toss or roll of dice.</h7>
                    </li>
                    <li>
                      <h5>Empirical</h5>
                      <h7>AKA, <b><i>relative frequency</i></b> or <b><i>experimental
                            probability</i></b> is the ratio of the # of outcomes for
                        a specific event to the total number of subsequent trials.
                        Based on observed data from past events, eg, odds of favorite
                        ball team winning.</h7>
                    </li>
                  </ul>
                </li>
                <li>
                  <h5>Subjective Probability</h5>
                  <h7>"a type of probability derived from an individual's personal
                    judgment or own experience about whether a specific outcome
                    is likely to occur. It contains no formal calculations and only
                    reflects the subject's opinions and past experience." <a target="_blank" href="https://www.investopedia.com/terms/s/subjective_probability.asp#:~:text=Subjective%20probability%20is%20a%20type,subject"><i>Investopedia</i></a></h7>
                </li>
              </ul>
            </li>
            <li>
              <h5>Correlation</h5>
              <h7>A measurement of the extent to which numeric variables are associated
                with one another.</h7>
              <ul>
                <li>
                  <h5>Pearson's Correlation Coefficient (r)</h5>
                  <h7>A measure of linear correlation between two sets of data;
                    will always lie between +1 (perfect positive correlation) & -1 (perfect negative correlation).</h7>
                  <h6>
                    <math>
                      <mi>r</mi>
                      <mo>&nbsp;=&nbsp;</mo>
                      <mfrac>
                        <mrow>
                          <msup>
                            <mo>&Sigma;</mo>
                            <mi>n</mi>
                            <mi>i=1</mi>
                          </msup>
                          <mo>(</mo>
                          <msub>
                            <mi>x</mi>
                            <mi>i</mi>
                          </msub>
                          <mo>&nbsp;-&nbsp;</mo>
                          <mi>x&#772;</mi>
                          <mo>)</mo>
                          <mo>(</mo>
                          <msub>
                            <mi>y</mi>
                            <mi>i</mi>
                          </msub>
                          <mo>&nbsp;-&nbsp;</mo>
                          <mi>y&#772;</mi>
                          <mo>)</mo>
                        </mrow>
                        <mrow>
                          <mo>(</mo>
                          <mi>n</mi>
                          <mo>&nbsp;-&nbsp;</mo>
                          <mn>1</mn>
                          <mo>)</mo>
                          <msub>
                            <mi>s</mi>
                            <mi>x</mi>
                          </msub>
                          <msub>
                            <mi>s</mi>
                            <mi>y</mi>
                          </msub>
                        </mrow>
                      </mfrac>
                    </math>
                  </h6>
                </li>
                <li>
                  <h5>Correlation Matrix</h5>
                  <h7>A table where the variables are shown on both rows & columns, & the cell values are the correlation between the variables.</h7>
                  <table id="correlation_matrix">
                    <tr>
                      <th></th>
                      <th>v<sub>1</sub></th>
                      <th>v<sub>2</sub></th>
                      <th>v<sub>3</sub></th>
                    </tr>
                    <tr>
                      <th>v<sub>1</sub></th>
                      <td>1</td>
                      <td>0</td>
                      <td>0</td>
                    </tr>
                    <tr>
                      <th>v<sub>2</sub></th>
                      <td>0</td>
                      <td>1</td>
                      <td>0</td>
                    </tr>
                    <tr>
                      <th>v<sub>3</sub></th>
                      <td>0</td>
                      <td>0</td>
                      <td>1</td>
                    </tr>
                  </table>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </div>

    <div id="Inferential_Statistics">
      <h4>Inferential Statistics</h4>
      <h7><b>Putting foundational statistics to use with samplig to find meaningful statistics that will inform us about a population.</b>
        <br />"Scholars interested in human society . . . grasped these ideas and found to their surprise that the variation in human characteristics and behavior often displays the same pattern as the error in measurement . . ." (regarding the
        application of the standard normal distribution to social science in the early 19th century)
        <br />- Leonardo Mlodinow, <a target="_blank" href="https://www.amazon.com/Drunkards-Walk-Randomness-Rules-Lives/dp/0307275175"><i>The Drunkard's Walk: How Randomness Rules Our Lives</i></a></h7>
      <ul>
        <li>
          <h5>Simple Random Sample</h5>
          <h7><b>The most dependable data comes from simple random samples.</b></h7>
          <ul>
            <li>
              <h7>Each individual has the same probability of being chosen at any
                stage.</h7>
            </li>
            <li>
              <h7>Each subset of <i>k</i> individuals has the same probability of
                being chosen as any other subset containing <i>k</i> individuals.</h7>
            </li>
          </ul>
          <h7><b>Must exhibit two key characteristics:</b></h7>
          <ul>
            <li>
              <h7>Unbiased sample</h7>
            </li>
            <li>
              <h7>Independent data points</h7>
            </li>
          </ul>
        </li>
        <li>
          <a target="_blank" href="https://www.investopedia.com/terms/l/lawoflargenumbers.asp">
            <h5>Law of Large Numbers</h5>
          </a>
          <h7>When performing experiments, the average of the results from large numbers of trials should be close to the expected value & will tend to become closer to the expected valueas more trials are performed. Experimental probability will
            eventually lead to theoretical probability.
            As a sample size grows, its mean gets closer to the average of the whole population.</h7>
          <ul>
            <li>
              <h5>Theoretical Probability</h5>
              <h7><i>Classical</i> probability is the likelihood that an event will occur if we could run trials of an experiment an infinite number of times.</h7>
            </li>
          </ul>
        </li>
        <li>
          <a target="_blank" href="https://www.merriam-webster.com/dictionary/law%20of%20error#:~:text=%3A%20the%20equation%20of%20the%20normal,also%20normal%20law%20of%20error">
            <h5>Law of Error</h5>
          </a>
          <h7>The equation of the normal probability curve to which the accidental errors associated with an extended series of observations tend to conform.</h7>
        </li>
        <li>
          <a target="_blank" href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Probability/BS704_Probability12.html">
            <h5>Central Limit Theorem</h5>
          </a>
          <h7>If you have a population with mean μ and standard deviation σ and take sufficiently large random samples from the population with replacement , then the distribution of the sample means will be approximately normally distributed.</h7>
        </li>
        <li>
          <h5>Parametric vs. Non-Parametric</h5>
          <h7>"<i>Parametric tests assume that your data follows a particular known
              distribution, usually the Normal Distribution . . . Those distributions
              have been studied a lot . . .
              <br /> &emsp; The mean, median & standard deviation are examples of
              parameters & <b>testing the differences in the parameters</b> of distribution-A
              vs. Distribution-B <b>is exactly what parametric tests do</b>. They
              are useful & powerful because as long as your own data approximates
              the known distribution you can learn a lot about your own data by
              inferring the same conclusions you would with the known distribution.
              <br /> &emsp; Non-parametric tests don't make any assumption about
              what known distribution your data might follow. They don't assume the
              shape of your data is 'Normal' . . . and therefore are not able to
              infer powerful conclusions of those known distributions. Mostly N
              on-Parametric tests rank data in order and compare. Median tests work
              like this (e.g.Moods Median test). The Median is a parameter, but the
              test is not making assumptions about what distribution your data
              follows, thus it's a non-Parametric test."</i>
            <a target="_blank" href="https://www.reddit.com/r/explainlikeimfive/comments/98jk46/eli5_the_difference_between_parametric_and/">Reddit ELI5</a>
          </h7>
        </li>
        <li>
          <h5>Standard Error</h5>
          <h7>A single metric that sums up the variability in the sampling distribution for a statistic.</h7>
          <br />
          <h6>
            <math>
              <mn>Standard Error</mn>
              <mo>&nbsp;=&nbsp;</mo>
              <mi>SE</mi>
              <mo>&nbsp;=&nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>s</mi>
                </mrow>
                <mrow>
                  <msqrt stretchy=False>
                    <mi>n</mi>
                  </msqrt>
                </mrow>
              </mfrac>
            </math>
            <br />&nbsp; &#8627; where:
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <mi>s</mi>
              <mo>=</mo>
              <mn>standard deviation of the sample values</mn>
            </math>
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <mi>n</mi>
              <mo>=</mo>
              <mn>the sample size</mn>
            </math>
          </h6>
        </li>
        <li>
          <h5>Square Root of <i>n</i> Rule</h5>
          <h7>To reduce the <b><i>standard error</i></b> by a factor of 2, the
            sample size must be increased by a factor of 4.</h7>
        </li>
        <li>
          <h5>Bootstrap Algorithm</h5>
          <h7>A powerful tool for assessing the variability of a sample statistic. To draw additional samples, with replacement, from the sample
            itself & recalculate the statistic or model for each resample.</h7>
          <h6>
            <ol>
              <li>
                Draw a sample value, record it & then replace it.
              </li>
              <li>
                Repeat <i>n</i> times.
              </li>
              <li>
                Record the mean of the <i>n</i> resampled values.
              </li>
              <li>
                Repeat steps 1-3 <i>R</i> times.
              </li>
              <li>
                Use the <i>R</i> results to:
                <ul>
                  <li>
                    Calculate their standard deviation (this estimates sample mean standard error).
                  </li>
                  <li>
                    Produce a histogram or boxplot.
                  </li>
                  <li>
                    Find a confidence interval.
                  </li>
                </ul>
              </li>
            </ol>
          </h6>
        </li>
        <li>
          <a target="_blank" href="https://towardsdatascience.com/probability-concepts-explained-probability-distributions-introduction-part-3-4a5db81858dc">
            <h5>Probability Distribution vs. Probability Density Function</h5>
          </a>
          <h7>A <b><i>probability distribution</i></b> is a list of outcomes and
            their associated probabilities. A function that represents a discrete
            probability distribution is called a probability mass function. A
            function that represents a continuous probability distribution is
            called a <b><i>probability density function</i></b>.</h7>
        </li>
        <li>
          <h5>F-Distribution</h5>
          <h7>The F-statistic measures the extent to which differences among group
            means are greater than we might expect under normal random variation.
            Also called <b><i>residual variability</i></b>, this comparison is
            termed <b><i>analysis of variance</i></b>.</h7>
        </li>
        <li>
          <h5>T-tests & ANOVA</h5>
          <h7><b>Is there a significant difference among groups tested? How significant
              is that difference? Think Alpha level.</b></h7>
          <ul>
            <li>
              <h7>T-tests measure one or two groups.</h7>
            </li>
            <li>
              <h7>T-tests tell you which group is different.</h7>
            </li>
            <li>
              <h7>One-sample known as a <b><i>student t-test</i></b> & will
                determine significance against a known population mean.</h7>
            </li>
            <li>
              <h7>Two sample t-tests (<b><i>independent samples</i></b>) will
                determine significance between two groups
                of data.</h7>
            </li>
            <li>
              <h7>A paired t-test (<b><i>dependent samples</i></b>) will determine
                signifcance for the same group at different times (pre- & post-test).</h7>
            </li>
            <li>
              <h7>Calculating t-test require at least three values:</h7>
              <ul>
                <li>
                  <h7>the group means or mean difference</h7>
                </li>
                <li>
                  <h7>the standard deviation of each group</h7>
                </li>
                <li>
                  <h7>the # of data values of each group</h7>
                </li>
                <li>
                  <h7>for one-sample t-test, the hypothesized or population mean</h7>
                </li>
              </ul>
            </li>
            <li>
              <h7>ANOVA measures more than two groups.</h7>
            </li>
            <li>
              <h7>Both are parametric & means tests.</h7>
            </li>
            <li>
              <h7>Both require normal distributions, homogeneity of variance &
                random sampling.</h7>
            </li>
            <li>
              <h7>Both measure a ratio or interval level (continuous) dependent
                variable.</h7>
            </li>
            <li>
              <h7>If you have a significant difference among several groups,
                post-hoc testing will be necessary to provide further investigation.</h7>
            </li>
          </ul>
        </li>
        <li>
          <h5>Difference Between <b>r</b> & <b>R<sup>2</sup></b></h5>
          <ul>
            <li>
              <h7>The value <b>r</b> is the correlation between observed values
                of <b>Y</b> & predicted values of <b>Y&#770;</b>. In essence, it
                is the relationship between two variables, say weight & height.
                The positive & negative values express that relationship as
                proportional or inversely proportional. So, <b>r</b> deals with the
                relationship of two variables.</h7>
            </li>
            <li>
              <h7><b>R<sup>2</sup></b> is the <b><i>coefficient of determination</i></b>.
                It is the percentage of variation in the response variable that
                is explained by the linear model - how strongly multiple variables
                are correlated with the target variable. It is <b>r</b> times
                the <b>r</b> value.</h7>
            </li>
          </ul>
        </li>
        <li>
          <h5>Poisson Distributions</h5>
          <h7>Measuring a count of events over some interval of time/space. In
            many applications, the event rate, <b><i>&lambda;,</i></b> is known
            or can be estimated from prior data.</h7>
          <h6>
            <math>
              <mn>Event rate</mn>
              <mo>&nbsp;=&nbsp;</mo>
              <mi>&lambda;</mi>
              <mo>&nbsp;=&nbsp;</mo>
              <mn>mean # of events occurring in interval of time or space </mn>
            </math>
          </h6>
        </li>
        <li>
          <h5>Weibull Distribution</h5>
          <h7>An extension of the exponential distribution in which the event rate
            is allowed to change, as specified by a <b><i>shape parameter, &beta;</i></b>.</h7>
          <h6>
            <math>
              <mi>&beta;</mi>
              <mo>&nbsp;&#62;&nbsp;</mo>
              <mn>1</mn>
              <mo>&emsp;&rArr;&emsp;</mo>
              <mn>probability of event increases over time</mn>
            </math>
            <br />
            <math>
              <mi>&beta;</mi>
              <mo>&nbsp;&#60;&nbsp;</mo>
              <mn>1</mn>
              <mo>&emsp;&rArr;&emsp;</mo>
              <mn>probability of event decreases over time</mn>
            </math>
          </h6>
        </li>
        <li>
          <h5>Gaussian Distribution Formulas</h5>
        </li>
        <ul>
          <li><a target="_blank" title="" href="https://stattrek.com/probability-distributions/normal.aspx" />
            <h5>Probability Density Function, The Normal Equation</h5></a>
          </li>
          <h6>
            <math>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <mi>x | &mu;,</mi>
              <msup>
                <mi>&nbsp; &sigma;</mi>
                <mn>2</mn>
              </msup>
              <mo stretchy=False>) = </mo>
              <mfrac>
                <mrow>
                  <mi>1</mi>
                </mrow>
                <mrow>
                  <msqrt stretchy=False>
                    <mi>2 &pi;</mi>
                    <msup>
                      <mi>&sigma;</mi>
                      <mn>2</mn>
                    </msup>
                  </msqrt>
                </mrow>
              </mfrac>
              <msup>
                <mi>e</mi>
                <mn>
                  <mo>-</mo>
                  <mfrac>
                    <mrow>
                      <msup>
                        <mi>(x - &mu;)</mi>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                    <mrow>
                      <mi>2</mi>
                      <msup>
                        <mi>&sigma;</mi>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                  </mfrac>
                </mn>
              </msup>
            </math>
            <br />&nbsp; &#8627; where:
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <mi>&mu; = mean</mi>
            </math>
            <br />&nbsp; &nbsp; &nbsp; &sigma; = standard deviation
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <msup>
                <mi>&sigma;</mi>
                <mn>2</mn>
              </msup>
            </math>
            = variance
          </h6>
        </ul>
        <li>
          <h5>T Distribution</h5>
          <h7>Aka the Student's t-distribution, is a type of probability distribution that is similar to the normal distribution with its bell shape but has heavier tails. T distributions have a greater chance for extreme values than normal
            distributions, hence the fatter tails.</h7>
          <h6>
            <math>
              <mi>t</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>x&#772;</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>&mu;</mi>
                </mrow>
                <mrow>
                  <mi>s</mi>
                  <mo>/</mo>
                  <msqrt>
                    <mi>n</mi>
                  </msqrt>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </li>
        <li>
          <h5>Binomial Distribution Formulas</h5>
        </li>
        <ul>
          <li>
            <h5>Mean</h5>
          </li>
          <h6>
            <math>
              <mi>&mu; = n * p</mi>
            </math>
          </h6>
          <li>
            <h5>Standard Deviation</h5>
          </li>
          <h6>
            <math>
              <mi>&sigma; = </mi>
              <msqrt>
                <mi>n * p * (1 - p)</mi>
              </msqrt>
            </math>
          </h6>
          <li>
            <h5>Variance</h5>
          </li>
          <h6>
            <math>
              <msup>
                <mi>&sigma;</mi>
                <mn>2</mn>
              </msup>
              <mo>=</mo>
              <mi>n * p * (1 - p)</mi>
            </math>
          </h6>
          <li>
            <h5>Probability Density Function</h5>
          </li>
          <h6>
            <math>
              <mi>f</mi>
              <mo stretchy=false>(</mo>
              <mi>k</mi>
              <mo>,</mo>
              <mi>n</mi>
              <mo>,</mo>
              <mi>p</mi>
              <mo stretchy=false>)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>n</mi>
                  <mo>!</mo>
                </mrow>
                <mrow>
                  <mi>k</mi>
                  <mo>!(</mo>
                  <mi>n</mi>
                  <mo>-</mo>
                  <mi>k</mi>
                  <mo>)!</mo>
                </mrow>
              </mfrac>
              <msup>
                <mi>p</mi>
                <mn>k</mn>
              </msup>
              <mo stretchy=false>(</mo>
              <mo>1</mo>
              <mo>-</mo>
              <mi>&nbsp;</mi>
              <mi>p</mi>
              <mo stretchy=false>)</mo>
              <msup>
                <mi> </mi>
                <mn>(n - k)</mn>
              </msup>
            </math>
          </h6>
        </ul>
        <li><a target="_blank" title="" href="" />
          <h5>Sample Distribution of the Sample Proportion</h5></a>
        </li>
        <h7></h7>
        <ul>
          <li><a target="_blank" title="" href="">
              <h5>Mean & Standard Error</h5>
            </a></li>
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <msub>
                <mi>&mu;</mi>
                <mn>p&#770;</mn>
              </msub>
              <mo>=</mo>
              <mi>p</mi>
            </math>
            <br />
            <math>
              <mi>SE</mi>
              <mo>&#8658;</mo>
              <msub>
                <mi>&sigma;</mi>
                <mn>p&#770;</mn>
              </msub>
              <mo>=</mo>
              <msqrt>
                <mfrac>
                  <mrow>
                    <mi>p</mi>
                    <mo stretchy="false">(</mo>
                    <mi>1</mi>
                    <mo>-</mo>
                    <mi>p</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                  <mrow>
                    <mi>n</mi>
                  </mrow>
                </mfrac>
              </msqrt>
            </math>
          </h6>
          <li><a target="_blank" title="" href="https://en.wikipedia.org/wiki/Mean_squared_error">
              <h5>Mean Squared Error & Root Mean Squared Error</h5>
            </a></li>
          <h7>An estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value</h7>
        </ul>
        <li>
          <h5>Confidence Interval</h5>
          <h7><b>Simply, a confidence interval provides a level of confidence for
              a given interval.</b> Or, more specifically, a range of values so
            defined that there is a specified probability that the value of a parameter
            lies within it.</h7>
        </li>
        <h7></h7>
        <ul>
          <li><a target="_blank" title="" href="">
              <h5>CI for a Population Mean</h5>
            </a></li>
          <h6>
            <math>
              <mi>(a, b)</mi>
              <mo>=</mo>
              <mi>x&#772; &#177; z *</mi>
              <mfrac>
                <mrow>
                  <mi>&sigma;</mi>
                </mrow>
                <mrow>
                  <msqrt>
                    <mi>n</mi>
                  </msqrt>
                </mrow>
              </mfrac>
              <mo>&#8658;</mo>
              <mi>x&#772; &#177;</mi>
              <msub>
                <mi>&nbsp;z</mi>
                <mn>&alpha;/2</mn>
              </msub>
              <mo>*</mo>
              <mfrac>
                <mrow>
                  <mi>&sigma;</mi>
                </mrow>
                <mrow>
                  <msqrt>
                    <mi>n</mi>
                  </msqrt>
                </mrow>
              </mfrac><br />
            </math>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;or<br />
            <math>
              <mi>(a, b)</mi>
              <mo>=</mo>
              <mi>x&#772; &#177; z *</mi>
              <msub>
                <mi>&sigma;</mi>
                <mn>x&#772;</mn>
              </msub>
              <mo>&#8658;</mo>
              <mi>x&#772; &#177;</mi>
              <msub>
                <mi>&nbsp;z</mi>
                <mn>&alpha;/2</mn>
              </msub>
              <mo>&nbsp;*&nbsp;</mo>
              <msub>
                <mi>&sigma;</mi>
                <mn>x&#772;</mn>
              </msub>
              <br />
            </math>
            &nbsp; &#8627; where:<br />
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a = lower limit of confidence interval<br />
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b = upper limit of confidence interval<br />
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;z* = critical value &#8658; z-score<br />
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&alpha; = (1 - confidence level) &#8658; signicance level
          </h6>
          <li>
            <h5>CI for Population Proportion</h5>
          </li>
          <h6>
            <math>
              <mi>(a, b)</mi>
              <mo>=</mo>
              <mi>p&#770; &#177; z *</mi>
              <msqrt>
                <mfrac>
                  <mrow>
                    <mi>p&#770;(1 - p&#770;)</mi>
                  </mrow>
                  <mrow>
                    <mi>n</mi>
                  </mrow>
                </mfrac>
              </msqrt>
            </math>
            <br />
          </h6>
          <li>
            <h5>Solved for Sample Size (n)</h5>
          </li>
          <h6>
            <math>
              <mi>n = &nbsp;</mi>
              <mo stretchy=true>(</mo>
              <mfrac>
                <mrow>
                  <mi>z*</mi>
                  <msqrt>
                    <mi>p&#770;(1 - p&#770;)</mi>
                  </msqrt>
                </mrow>
                <mrow>
                  <mi>ME</mi>
                </mrow>
              </mfrac>
              <mo stretchy=true>)</mo>
              <msup>
                <mi></mi>
                <mn>2</mn>
              </msup>
            </math><br />
            &nbsp; &#8627; where:<br />
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p&#770; = sample proportion
          </h6>
          <li>
            <h5>Margin of Error (ME)</h5>
            <h7>"A margin of error tells you how many percentage points your
              results will differ from the real population value. For example,
              a 95% confidence interval with a 4 percent margin of error means
              that your statistic will be within 4 percentage points of the real
              population value 95% of the time." <a target="_blank" title="" href="https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/margin-of-error/">StatisticsHowTo</a></h7>
          </li>
          <h6>
            <math>
              <mi>ME = Distance from sample mean (x&#772;) or sample proportion (p&#770;) to either edge of confidence interval</mi>
              <br />
            </math>
            <math>
              <mi>&nbsp; &nbsp; &nbsp; &nbsp; = </mi>
              <mi>&nbsp; &#177;</mi>
              <mi>&nbsp;z</mi>
              <mo>&nbsp;*&nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>&sigma;</mi>
                </mrow>
                <mrow>
                  <msqrt>
                    <mi>n</mi>
                  </msqrt>
                </mrow>
              </mfrac><br />
            </math>
            <math>
              <mi>&nbsp; &nbsp; &nbsp; &nbsp; = </mi>
              <mi>&nbsp; &#177; z *</mi>
              <msqrt>
                <mfrac>
                  <mrow>
                    <mi>p&#770;(1 - p&#770;)</mi>
                  </mrow>
                  <mrow>
                    <mi>n</mi>
                  </mrow>
                </mfrac>
              </msqrt>
            </math>
          </h6>
        </ul>
        <li>
          <h5>Chi-Square Distribution</h5>
          <h7>The statistic that measures the extent to which results depart from
            the null expectation of independence. It is distribution-free & non-
            parametric. <b><i>Must be used when dealing with categorical dependent variable</i></b>,
            for example binary, "yes/no", target variable.</h7>
        </li>
        <li>
          <h5>Chi-Square Tests(&chi;<sup>2</sup>)</h5>
          <h5>Assumptions</h5>
          <ul>
            <li>
              <h7>Data in cells should be frequencies or counts of cases.</h7>
            </li>
            <li>
              <h7>Levels (or categories) of the variables are mutually exclusive.</h7>
            </li>
            <li>
              <h7>Each subject may contribute to one & only one cell.</h7>
            </li>
            <li>
              <h7>Study groups must be independent.</h7>
            </li>
            <li>
              <h7>Two variables, both are measured as categories, usuallys at the nominal level.</h7>
            </li>
            <li>
              <h7>Values in cells should be five or more.</h7>
            </li>
          </ul>
          <h5>Features</h5>
          <ul>
            <li>
              <h7>A hypothesis test comparing two or more proportions, H<sub>o</sub>: P<sub>1</sub> = P<sub>2</sub></h7>
            </li>
            <li>
              <h7>Random samples are required.</h7>
            </li>
            <li>
              <h7>Observations are independent.</h7>
            </li>
            <li>
              <h7>Uses &chi;<sup>2</sup> table to show the critical values of
                the &chi;<sup>2</sup> distribution.</h7>
            </li>
          </ul>
          <h5>I. <u>Goodness of Fit Test</u>:</h5>
          <h7><b>Tests if a categorical variable follows a hypothesized distribution.</b></h7>
          <ul>
            <li>
              <h7>Simple random sampling</h7>
            </li>
            <li>
              <h7>Categorical variables</h7>
            </li>
            <li>
              <h7>Expected frequency count from previous samples, ex. percentage by category</h7>
            </li>
            <li>
              <h7>Degrees of freedom is k - 1</h7>
            </li>
            <li>
              <h7>H<sub>o</sub>: the population frequencies = expected frequencies values.
                <br />H<sub>a</sub>: the null hypothesis is false.</h7>
            </li>
            <li>
              <h7>Test statistic is defined:</h7>
              <h6>
                <math>
                  <msup>
                    <mn>&chi;</mn>
                    <mn>2</mn>
                  </msup>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mn>&Sigma;</mn>
                  <mo stretchy=True>[</mo>
                  <mfrac>
                    <mrow>
                      <mo>(</mo>
                      <msub>
                        <mn>O</mn>
                        <mn>r, c</mn>
                      </msub>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mn>E</mn>
                        <mn>r, c</mn>
                      </msub>
                      <mo>)</mo>
                    </mrow>
                    <mrow>
                      <msub>
                        <mn>E</mn>
                        <mn>r, c</mn>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo stretchy=True>]</mo>
                </math>
              </h6>
            </li>
          </ul>
          <h5>II. <u>Test for Independence</u>:</h5>
          <h7><b>Looks for significant difference between two categorical variables.</b></h7>
          <ul>
            <li>
              <h7>Simple random sampling</h7>
            </li>
            <li>
              <h7>Categorical variables</h7>
            </li>
            <li>
              <h7>Expected frequency count for each cell of the table is at least five</h7>
            </li>
            <li>
              <h7>Degrees of freedom:</h7>
              <h6>
                <math>
                  <mn>df</mn>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>(</mo>
                  <mn>r &nbsp; - 1</mn>
                  <mo>)</mo>
                  <mo>*</mo>
                  <mo>(</mo>
                  <mn>c &nbsp; - 1</mn>
                  <mo>)</mo>
                </math>
                <br />&nbsp; &#8627; where:
                <br />&nbsp; &nbsp; &nbsp; r = # of levels (rows) for one categorical variable
                <br />&nbsp; &nbsp; &nbsp; c = # of levels (columns) for the other
              </h6>
            </li>
            <li>
              <h7>Expected Frequencies:</h7>
              <h6>
                <math>
                  <msub>
                    <mn>E</mn>
                    <mn>r, c</mn>
                  </msub>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mo>(</mo>
                      <msub>
                        <mn>n</mn>
                        <mn>r</mn>
                      </msub>
                      <mo>&nbsp; * &nbsp;</mo>
                      <msub>
                        <mn>n</mn>
                        <mn>c</mn>
                      </msub>
                      <mo>)</mo>
                    </mrow>
                    <mrow>
                      <mn>n</mn>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h7>Test statistic is defined:</h7>
              <h6>
                <math>
                  <msup>
                    <mn>&chi;</mn>
                    <mn>2</mn>
                  </msup>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mn>&Sigma;</mn>
                  <mo stretchy=True>[</mo>
                  <mfrac>
                    <mrow>
                      <mo>(</mo>
                      <msub>
                        <mn>O</mn>
                        <mn>r, c</mn>
                      </msub>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mn>E</mn>
                        <mn>r, c</mn>
                      </msub>
                      <mo>)</mo>
                    </mrow>
                    <mrow>
                      <msub>
                        <mn>E</mn>
                        <mn>r, c</mn>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo stretchy=True>]</mo>
                </math>
              </h6>
            </li>
          </ul>
          <h5>III. <u>Test for Homogeneity</u>:</h5>
          <h7><b>Tests for difference in proportion between several groups.</b></h7>
      </ul>
      </li>
      </ul>
      <h4>Statistical Significance Testing</h4>
      <ul>
        <li>
          <h5><u><b>Test Statistic</b></u>: proportion, average, difference
            between groups or a distribution</h5>
        </li>
        <li>
          <h5><u><b>Hypothesis Test Logic</b></u>: "Given the human tendency to
            react to unusual but random behavior and interpret it as something
            meaningful and real, in our experiements we will require proof that
            the difference between groups is <b><i>more extreme than what chance
                might reasonably produce.</i></b>"<a target="_blank" href="https://github.com/gedeck/practical-statistics-for-data-scientists"><i>Practical Statistics for Data Scientists (p. 94)</i></a></h5>
        </li>
        <li>
          <h5><u><b>Null Hypothesis</b></u><b>(H<sub>o</sub>)</b>: a baseline assumption that the treatments in an experment are equivalent & the results observed are a product of chance</h5>
        </li>
        <li>
          <h5><u><b>Alternative Hypothesis</b></u><b>(H<sub>a</sub> or H<sub>1</sub>)</b>: the results observed in an experiment cannot be explained by chance</h5>
        </li>
        <li>
          <h5><u><b>Significance Level</b></u>: the value of the test statistic needs to take before it is decided that the Null Hypothesis cannot explain the difference</h5>
        </li>
        <li>
          <h5><b><u>Statistically Significant</b></u>: "A result of an experiment
            is said to have statistical significance, or be statistically
            significant, if it is likely not caused by chance for a given
            statistical significance level. ... It also means that there is a 5%
            chance that you could be wrong."
            <a target="_blank" href="https://www.optimizely.com/optimization-glossary/statistical-significance/">Optipedia</a></h5>
        </li>
        <li>
          <h5>p-value</h5>
          <h7>Given a chance model that embodies the null hypothesis, the
            <b><i>p-value</i></b> is the probability (frequency) of obtaining results
            as unusual or extreme as the observed results.
          </h7>
        </li>
        <li>
          <h5>Alpha</h5>
          <h7>The <b><i>probability threshold</i></b> of "unusualness" that
            chance results must surpass for actual outcomes to be deemed
            statistically significant.</h7>
        </li>
        <li>
          <h5>Type I Error</h5>
          <h7>Mistakenly concluding an effect is real (when it is due to chance).</h7>
        </li>
        <li>
          <h5>Type II Error</h5>
          <h7>Mistakenly concluding an effect is due to chance (when it is real).</h7>
        </li>
        <li>
          <h5>Degrees of Freedom</h5>
          <h7>The number of values free to vary & affects the shape of the distribution;
            the name given the <i>n - 1</i> denominator seen in the calculation
            for variance & standard deviation. When you use a sample to estimate
            the variance for a population, you will end up with an estimate
            that is slightly biased downward if you use the <i>n</i> in the
            denominator. If you use <i>n - 1</i> in the denominator, the
            estimate will be free of bias.
            <br /><b><i>The concept of degrees of freedom lies behind the factoring
                of categorical variables into </i> n - 1 <i> indicator or dummy variables
                when doing a regression (to avoid</i> multicollinearity<i>).</i></b>
          </h7>
        </li>
      </ul>
      <ul>
        <li>
          <h5>ANOVA (Analysis of Variance)</h5>
          <h7>The statistical procedure that tests for a statistically significant
            difference among multiple groups.</h7>
          <ul>
            <li>
              <h5>Pairwise Comparison</h5>
              <h7>A hypothesis test (e.g., of means) between two groups among
                multiple groups. The more such pairwise comparisons we make, the
                greater the potential for being fooled by random chance.</h7>
            </li>
            <li>
              <h5>Omnibus Test</h5>
              <h7>A single hypothesis test of the overall variance among
                multiple group means.</h7>
            </li>
            <li>
              <h5>Decomposition of Variance</h5>
              <h7>Separation of components contributing to an individual value
                (e.g., from the overall average, from a treatment mean, & from
                residual error).</h7>
            </li>
            <li>
              <h5>F-statistic</h5>
              <h7>A standardized statistic that measures the extent to which
                differences among group means exceed what might be expected in a
                chance model.</h7>
            </li>
            <li>
              <h5>SS</h5>
              <h7>"Sum of squares," referring to deviations from some average
                value.</h7>
            </li>
          </ul>
        </li>
      </ul>
      <ul>
        <li>
          <h5>Common Significance Tests</h5>
          <h7><b>&nbsp; &#8627; Using the population mean (&mu;):</b></h7>
          <ul>
            <li>
              <h5>Z-Test | When &sigma; is known</h5>
              <h6>
                <math>
                  <mi>z</mi>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>x&#772;</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mi>&mu;</mi>
                        <mn>o</mn>
                      </msub>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>&sigma;</mi>
                        <mn>x&#772;</mn>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>x&#772;</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mi>&mu;</mi>
                        <mn>o</mn>
                      </msub>
                    </mrow>
                    <mrow>
                      <mfrac>
                        <mrow>
                          <mi>&sigma;</mi>
                        </mrow>
                        <mrow>
                          <msqrt>
                            <mi>n</mi>
                          </msqrt>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>T-Test | When &sigma; is unknown | large sample > 30</h5>
              <h6>
                <math>
                  <mi>t</mi>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>x&#772;</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mi>&mu;</mi>
                        <mn>o</mn>
                      </msub>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>s</mi>
                        <mn>x&#772;</mn>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>x&#772;</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mi>&mu;</mi>
                        <mn>o</mn>
                      </msub>
                    </mrow>
                    <mrow>
                      <mfrac>
                        <mrow>
                          <mi>s</mi>
                        </mrow>
                        <mrow>
                          <msqrt>
                            <mi>n</mi>
                          </msqrt>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>T-Test | When &sigma; is unknown | small sample < 30 | assume normal distribution</h5>
                  <h6>
                    <math>
                      <mi>t</mi>
                      <mo>=</mo>
                      <mfrac>
                        <mrow>
                          <mi>x&#772;</mi>
                          <mo>&nbsp; - &nbsp;</mo>
                          <msub>
                            <mi>&mu;</mi>
                            <mn>o</mn>
                          </msub>
                        </mrow>
                        <mrow>
                          <msub>
                            <mi>s</mi>
                            <mn>x&#772;</mn>
                          </msub>
                        </mrow>
                      </mfrac>
                      <mo>=</mo>
                      <mfrac>
                        <mrow>
                          <mi>x&#772;</mi>
                          <mo>&nbsp; - &nbsp;</mo>
                          <msub>
                            <mi>&mu;</mi>
                            <mn>o</mn>
                          </msub>
                        </mrow>
                        <mrow>
                          <mfrac>
                            <mrow>
                              <mi>s</mi>
                            </mrow>
                            <mrow>
                              <msqrt>
                                <mi>n</mi>
                              </msqrt>
                            </mrow>
                          </mfrac>
                        </mrow>
                      </mfrac>
                    </math>
                  </h6>
            </li>
          </ul>
          <h7><b>&nbsp; &#8627; Using the population proportion (p):</b></h7>
          <ul>
            <li>
              <h5>Pearson's Chi-Squared Test | Expected value of population proportion (p&#770;) known</h5>
              <h6>
                <math>
                  <mi>z</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mi>p&#770;</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mn>p</mn>
                        <mn>o</mn>
                      </msub>
                    </mrow>
                    <mrow>
                      <msqrt>
                        <mfrac>
                          <mrow>
                            <msub>
                              <mn>p</mn>
                              <mn>o</mn>
                            </msub>
                            <mo>(</mo>
                            <mo>1</mo>
                            <mo>&nbsp; - &nbsp;</mo>
                            <msub>
                              <mn>p</mn>
                              <mn>o</mn>
                            </msub>
                            <mo>)</mo>
                          </mrow>
                          <mrow>
                            <mi>n</mi>
                          </mrow>
                        </mfrac>
                      </msqrt>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
          </ul>
        </li>
      </ul>
      <h4>Regression</h4>
      <a target="_blank" href="https://blog.minitab.com/blog/statistics-and-quality-data-analysis/so-why-is-it-called-regression-anyway">
        <h7><b>&nbsp; &#8627; So . . . why is it called "Regression", anyway?</b></h7>
      </a>
      <ul>
        <li>
          <h5>Regression Analysis</h5>
          <h7>Process used to turn a set of disconnected data points into an equation that models the whole set; the process of aproximating a trend with a mathematical function</h7>
          <ul>
            <li>
              <h5>Trend or Regression Line, Approximating Curve, Line of Best Fit, Least Squares Line</h5>
              <h6>
                <math>
                  <mi>y&#770;</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mi>mx + b</mi>
                </math>
              </h6>
            </li>
            <li>
              <h5>Slope</h5>
              <h6>
                <math>
                  <mi>m</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mi>n&Sigma;xy - &Sigma;x&Sigma;y</mi>
                    </mrow>
                    <mrow>
                      <mi>n&Sigma;</mi>
                      <msup>
                        <mi>x</mi>
                        <mn>2</mn>
                      </msup>
                      <mo>&nbsp; - &nbsp;</mo>
                      <mi>(&Sigma;x)</mi>
                      <msup>
                        <mi></mi>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Y-intercept</h5>
              <h6>
                <math>
                  <mi>b</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mi>&Sigma;y - m&Sigma;x</mi>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Correlation Coefficient</h5>
              <h6>
                <math>
                  <mi>r</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mo>1</mo>
                    </mrow>
                    <mrow>
                      <mi>n - 1</mi>
                    </mrow>
                  </mfrac>
                  <mo stretchy=True>&Sigma;</mo>
                  <mo stretchy=True>(</mo>
                  <mfrac>
                    <mrow>
                      <msub>
                        <mi>x</mi>
                        <mn>i</mn>
                      </msub>
                      <mo>&nbsp; - &nbsp;</mo>
                      <mi>x&#772;</mi>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>s</mi>
                        <mn>x</mn>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo stretchy=True>)</mo>
                  <mo stretchy=True>(</mo>
                  <mfrac>
                    <mrow>
                      <msub>
                        <mi>y</mi>
                        <mn>i</mn>
                      </msub>
                      <mo>&nbsp; - &nbsp;</mo>
                      <mi>y&#772;</mi>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>s</mi>
                        <mn>y</mn>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo stretchy=True>)</mo>
                </math>
                <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or
                <br />
                <math>
                  <mi>r</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mo>1</mo>
                    </mrow>
                    <mrow>
                      <mi>n - 1</mi>
                    </mrow>
                  </mfrac>
                  <mo stretchy=True>&Sigma;</mo>
                  <msub>
                    <mi>z</mi>
                    <mn>
                      <msub>
                        <mi>x</mi>
                        <mn>i</mn>
                      </msub>
                    </mn>
                  </msub>
                  <mi>&nbsp;</mi>
                  <msub>
                    <mi>z</mi>
                    <mn>
                      <msub>
                        <mi>y</mi>
                        <mn>i</mn>
                      </msub>
                    </mn>
                  </msub>
                </math>
              </h6>
            </li>
            <li>
              <h5>Pearson Correlation Coefficient</h5>
              <h7>Method for quantifying linear correlation, represented by <i>r</i> is a number ranging from -1 to 1 & indicating how well a scatter plot fits a linear trend</h7>
              <div id="pearson-correlation-coefficient">
                <h6>
                  <math>
                    <mi>r</mi>
                    <mo>&nbsp; = &nbsp;</mo>
                    <mfrac>
                      <mrow>
                        <msup>
                          <mo>&Sigma;</mo>
                          <mi>n</mi>
                          <mi>i=1</mi>
                        </msup>
                        <mo>(</mo>
                        <msub>
                          <mi>x</mi>
                          <mi>i</mi>
                        </msub>
                        <mo>&nbsp; - &nbsp;</mo>
                        <mi>x&#772;</mi>
                        <mo>)</mo>
                        <mo>(</mo>
                        <mi>y</mi>
                        <mo>&nbsp; - &nbsp;</mo>
                        <mi>y&#772;</mi>
                        <mo>)</mo>
                      </mrow>
                      <mrow>
                        <msqrt>
                          <msup>
                            <mo>&Sigma;</mo>
                            <mi>n</mi>
                            <mi>i=1</mi>
                          </msup>
                          <mo>(</mo>
                          <msub>
                            <mi>x</mi>
                            <mi>i</mi>
                          </msub>
                          <mo>&nbsp; - &nbsp;</mo>
                          <mi>x&#772;</mi>
                          <mo>)</mo>
                          <msup>
                            <mo></mo>
                            <mn>2</mn>
                          </msup>
                        </msqrt>
                        <mo>&nbsp; </mo>
                        <msqrt>
                          <msup>
                            <mo>&Sigma;</mo>
                            <mi>n</mi>
                            <mi>i=1</mi>
                          </msup>
                          <mo>(</mo>
                          <msub>
                            <mi>y</mi>
                            <mi>i</mi>
                          </msub>
                          <mo>&nbsp; - &nbsp;</mo>
                          <mi>y&#772;</mi>
                          <mo>)</mo>
                          <msup>
                            <mo></mo>
                            <mn>2</mn>
                          </msup>
                        </msqrt>
                      </mrow>
                    </mfrac>
                  </math>
                </h6>
              </div>
            </li>
            <li>
              <h5>Standard Deviation</h5>
              <h6>
                <math>
                  <msub>
                    <mi>s</mi>
                    <mn>x</mn>
                  </msub>
                  <mo>&nbsp; = &nbsp;</mo>
                  <msqrt>
                    <mfrac>
                      <mrow>
                        <mi>&Sigma;(x&nbsp;-&nbsp;x&#772;)</mi>
                        <msup>
                          <mi></mi>
                          <mn>2</mn>
                        </msup>
                      </mrow>
                      <mrow>
                        <mi>n</mi>
                      </mrow>
                    </mfrac>
                  </msqrt>
                </math>
              </h6>
            </li>
            <li>
              <h5>Residual or Error</h5>
              <h6>
                <math>
                  <mi>residual</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mi>e</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mi>actual value - predicted value</mi>
                </math>
              </h6>
            </li>
            <li>
              <h5>Sum of Residuals</h5>
              <h6>
                <math>
                  <mi>&Sigma;residuals</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mi>&Sigma;e</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>0</mo>
                </math>
              </h6>
            </li>
            <li>
              <h5>Coefficient of Determination</h5>
              <h7>Gives a percentage of how much better fit the line of regression is than the y&#772;</h7>
              <h6>
                <math>
                  <msup>
                    <mi>r</mi>
                    <mn>2</mn>
                  </msup>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mfrac>
                    <mrow>
                      <mi>predicted squares - y&#772; squares</mi>
                    </mrow>
                    <mrow>
                      <mi>predicted squares</mi>
                    </mrow>
                  </mfrac>
                  <mo>&nbsp; &#8658; &nbsp;</mo>
                  <mi>expressed as %</mi>
                </math>
              </h6>
            </li>
            <li>
              <h5>Root Mean Squared Error (RMSE) or Standard Deviation of the Residuals</h5>
              <h7>The smaller the RMSE, the better fit the line of regression</h7>
              <h6>
                <math>
                  <mi>RMSE</mi>
                  <mo>&nbsp; = &nbsp;</mo>
                  <msqrt>
                    <mfrac>
                      <mrow>
                        <mo>&Sigma;</mo>
                        <msup>
                          <mi>e</mi>
                          <mn>2</mn>
                        </msup>
                      </mrow>
                      <mrow>
                        <mi>n - 1</mi>
                      </mrow>
                    </mfrac>
                  </msqrt>
                </math>
              </h6>
            </li>
            <li>
              <h5>Chi-Square Tests (&chi;<sup>2</sup>)</h5>
              <h7><a target="_blank" href="https://www.reddit.com/r/explainlikeimfive/comments/v9ji5/eli5_chisquare_test/">Pearson's Chi-Square Test is used to ask whether the differences you observe between different groups are real or imagined.</a>
                <br />The larger the the &chi;<sup>2</sup>-value, the more likely the two variables affect each other</h7>
              <h6>
                <math>
                  <msup>
                    <mi>&chi;</mi>
                    <mo>2</mo>
                  </msup>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mo>&Sigma;</mo>
                  <mfrac>
                    <mrow>
                      <mi>(observed - expected)</mi>
                      <msup>
                        <mi></mi>
                        <mo>2</mo>
                      </msup>
                    </mrow>
                    <mrow>
                      <mi>expected</mi>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
            </li>
            <li>
              <h5>Degrees of Freedom (df)</h5>
              <h7>The number of values you would need in your data in order to be able to know all the other values</h7>
            </li>
          </ul>
        </li>
      </ul>
    </div>
  </div>


  <br /><br />
  <div id="Calculus">
    <h3>Dynamic Calculus</h3>
    <h7><b>The mathematics of curves, motion and change, calculus is basically very advanced algebra (finding rates & slopes) & geometry (addition to infinity & finding area). </b></h7>
    <h4>Three Central Problems of Calculus</h4>
    <ul>
      <li>
        <h5><b>Forward Problem</b>: given a curve, find its slope everywhere</h5>
      </li>
      <li>
        <h5><b>Backward Problem</b>: given the slope everywhere, find the curve</h5>
      </li>
      <li>
        <h5><b>Area Problem</b>: given the curve, find the area under it</h5>
      </li>
    </ul>
    <h4>Fundamental Theorem of Calculus (FTC)</h4>
    <h7>Shows the relationship between differentiation & integration. If a function
      is integrated & then differentiated, it is back to the original function. Integration & differentiation are inverse to each other.</h7>
    <ul>
      <li>
        <h5>Part 1</h5>
        <ul>
          <li>
            <h5>Differentiation</h5>
            <h6>
              <div id="FTC">
                <math>
                  <mi>If &nbsp;</mi>
                  <mi>r</mi>
                  <mo>(</mo>
                  <mi>x</mi>
                  <mo>)</mo>
                  <mi>is continuous on &nbsp;</mi>
                  <mo>[</mo>
                  <mi>a</mi>
                  <mo>,&nbsp;</mo>
                  <mi>b</mi>
                  <mo>]&nbsp;</mo>
                  <mi>then</mi>
                </math>
                <br /><br />&emsp;
                <math>
                  <mi>f</mi>
                  <mo stretchy=False>(</mo>
                  <mi>x</mi>
                  <mo stretchy=False>)</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <msup>
                    <mo>&#8747;</mo>
                    <mn>b</mn>
                    <mn>a</mn>
                  </msup>
                  <mi>r</mi>
                  <mo stretchy=False>(</mo>
                  <mi>t</mi>
                  <mo stretchy=False>)</mo>
                  <mo>&nbsp;</mo>
                  <mi>d</mi>
                  <mi>t</mi>
                </math>
                <br /><br />
                <math>
                  <mi>is continuous on &nbsp;</mi>
                  <mo>[</mo>
                  <mi>a</mi>
                  <mo>,&nbsp;</mo>
                  <mi>b</mi>
                  <mo>],&nbsp;</mo>
                  <mi>it is differentiable on &nbsp;</mi>
                  <mo>(</mo>
                  <mi>a</mi>
                  <mo>,&nbsp;</mo>
                  <mi>b</mi>
                  <mo>),&nbsp;</mo>
                  <mi>and</mi>
                </math>
                <br /><br />&emsp;
                <math>
                  <mi>f</mi>
                  <mo>&#x2032;</mo>
                  <mo stretchy=False>(</mo>
                  <mi>x</mi>
                  <mo stretchy=False>)</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mi>r</mi>
                  <mo stretchy=False>(</mo>
                  <mi>x</mi>
                  <mo stretchy=False>)</mo>
                </math>
              </div>
            </h6>
          </li>
        </ul>
      </li>
    </ul>
    <h4>Differentiation</h4>
    <h7>The derivative function tells how fast & where the function is increasing or decreasing.</h7>
    <ul>
      <li>
        <h5>Derivatives</h5>
        <h7>Finding the slope of a function at a specific point.</h7>
        <ul>
          <li>
            <h5>f&prime;(x) or
              <math>
                <mfrac>
                  <mrow>
                    <mi>d</mi>
                    <mi>y</mi>
                  </mrow>
                  <mrow>
                    <mi>d</mi>
                    <mi>x</mi>
                  </mrow>
                </mfrac>
              </math>
            </h5>
            <h6>
              <math>
                <mi>f&prime;(x)</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <span id="" class="lim_zero" style="font-size: 16px;">lim</span>
              </math>
              <math>
                <mfrac>
                  <mrow>
                    <mn>f(x + h) -f(x)</mn>
                  </mrow>
                  <mrow>
                    <mn>h</mn>
                  </mrow>
                </mfrac>
              </math>
              <br />&nbsp; &#8627; where:
              <br />&emsp;
              <math>
                <mn>h</mn>
                <mo>&nbsp; = &nbsp;</mo>
                <msub>
                  <mn>x</mn>
                  <mn>2</mn>
                </msub>
                <mo>&nbsp; - &nbsp;</mo>
                <msub>
                  <mn>x</mn>
                  <mn>1</mn>
                </msub>
              </math>
            </h6>
          </li>
        </ul>
      </li>
    </ul>
    <h4>Integration</h4>
    <h7>The integral of a function models the area under the graph of a function. </h7>
    <ul>
      <li>
        <h5>Antiderivatives & Indefinite Integrals</h5>
        <h7>Find the area under the curve everywhere, over the entire domain of the function; the interval is unbounded & there are no limits on the interval.</h7>
        <ul>
          <li>
            <h5>Integral for Basic Power Functions</h5>
            <h6>
              <math>
                <mo>&#8747;</mo>
                <msup>
                  <mn>x</mn>
                  <mn>a</mn>
                </msup>
                <mi>d</mi>
                <mi>x</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <msup>
                      <mn>x</mn>
                      <mn>a + 1</mn>
                    </msup>
                  </mrow>
                  <mrow>
                    <mn>a + 1</mn>
                  </mrow>
                </mfrac>
              </math>
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Definite Integrals</h5>
        <ul>
          <li>
            <h5>The Interval</h5>
            <h7>Find the area under the curve over a specific interval, at the limits of integration.</h7>
            <h6>
              <math>
                <msup>
                  <mo>&#8747;</mo>
                  <mn>b</mn>
                  <mn>a</mn>
                </msup>
                <mi>f</mi>
                <mn>(x)</mn>
                <mo>&nbsp;</mo>
                <mi>d</mi>
                <mi>x</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>F(b) - F(a)</mi>
              </math>
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Riemann Sums</h5>
        <h7>Way to geometrically estimate the area under a curve: divide the area into many thin rectangles, find the subsequent areas & then sum those areas</h7>
        <ul>
          <li>
            <h5>Summation Notation</h5>
            <h6>
              <math>
                <span id="" class="riemann_sums" style="font-size: 20px;">&Sigma;</span>
                <mo>(</mo>
                <mi>n - 1</mi>
                <mo>)</mo>
                <mo>(</mo>
                <mi>n + 2</mi>
                <mo>)</mo>
                <mo>&nbsp; = &nbsp;</mo>
              </math>
              <math>
                <msub>
                  <mn>a</mn>
                  <mn>n</mn>
                </msub>
              </math>
            </h6>
          </li>
          <li>
            <h5>Expanding Series</h5>
            <h6>
              <math>
                <span id="" class="riemann_sums" style="font-size: 20px;">&Sigma;</span>
              </math>
              <math>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <msup>
                      <mi>n</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo>&nbsp; = &nbsp;</mo>
              </math>
              <math>
                <msub>
                  <mn>a</mn>
                  <mn>n</mn>
                </msub>
              </math>
              <br />
              <math>
                <mo>&emsp;&emsp;&emsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <msup>
                      <mn>1</mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <msup>
                      <mn>2</mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <msup>
                      <mn>3</mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <msup>
                      <mn>4</mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <msup>
                      <mn>5</mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <msup>
                      <mn>6</mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
              </math>
              <br />
              <math>
                <mo>&emsp;&emsp;&emsp; = &nbsp;</mo>
                <mn>1</mn>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <mn>4</mn>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <mn>9</mn>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <mn>16</mn>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <mn>25</mn>
                  </mrow>
                </mfrac>
                <mo>&nbsp; + &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <mn>36</mn>
                  </mrow>
                </mfrac>
              </math>
            </h6>
          </li>
          <li>
            <h5>Riemann Sum Formula</h5>
            <h7>Use midpoints, left or right endpoints of finite # of rectangles to estimate the area under the curve</h7>
            <h6>
              <math>
                <msub>
                  <mi>R</mi>
                  <mi>n</mi>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>
              </math>
              <math>
                <mi>f</mi>
                <mo>(</mo>
                <msub>
                  <mi>x</mi>
                  <mi>i</mi>
                </msub>
                <mo>)</mo>
                <mn>&Delta;</mn>
                <mi>x</mi>
              </math>
              <br />
              <br />&nbsp; &#8627; expanded:
              <br />
              <br />
              <math>
                <msub>
                  <mi>R</mi>
                  <mi>n</mi>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <mn>&Delta;</mn>
                <mi>x</mi>
                <mo>[</mo>
                <mi>f</mi>
                <mo>(</mo>
                <msub>
                  <mi>x</mi>
                  <mi>1</mi>
                </msub>
                <mo>)</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mi>f</mi>
                <mo>(</mo>
                <msub>
                  <mi>x</mi>
                  <mi>2</mi>
                </msub>
                <mo>)</mo>
                <mo>&nbsp; + </mo>
                <mo>. . .</mo>
                <mo> + &nbsp;</mo>
                <mi>f</mi>
                <mo>(</mo>
                <msub>
                  <mi>x</mi>
                  <mi>n</mi>
                </msub>
                <mo>)</mo>
                <mo>]</mo>
              </math>
              <br />
              <br />&nbsp; &#8627; where:
              <br />&emsp;
              <math>
                <mn>&Delta;</mn>
                <mi>x</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mi>b</mi>
                    <mo>&nbsp; - &nbsp;</mo>
                    <mi>a</mi>
                  </mrow>
                  <mrow>
                    <mi>n</mi>
                  </mrow>
                </mfrac>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>width of subinterval/rectangle</mi>
              </math>
              <br />&emsp;
              <math>
                <mi>f</mi>
                <mo>(</mo>
                <msub>
                  <mi>x</mi>
                  <mi>i</mi>
                </msub>
                <mo>)</mo>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>length of rectangle</mi>
              </math>
              <br />&emsp;
              <math>
                <mi>n</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mi># of subintervals</mi>
              </math>
            </h6>
          </li>
      </li>
      <li>
        <h5>Midpoint Rule</h5>
        <div id="midpoint-rule-formula">
          <h6>
            <math>
              <msub>
                <mi>M</mi>
                <mi>n</mi>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>b</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>a</mi>
                </mrow>
                <mrow>
                  <mi>n</mi>
                </mrow>
              </mfrac>
              <mo>[</mo>
              <mi>f</mi>
              <mo>(</mo>
              <mfrac>
                <mrow>
                  <msub>
                    <mi>x</mi>
                    <mi>0</mi>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>1</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mn>2</mn>
                </mrow>
              </mfrac>
              <mo>)</mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mi>f</mi>
              <mo>(</mo>
              <mfrac>
                <mrow>
                  <msub>
                    <mi>x</mi>
                    <mi>1</mi>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>2</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mn>2</mn>
                </mrow>
              </mfrac>
              <mo>)</mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mi>f</mi>
              <mo>(</mo>
              <mfrac>
                <mrow>
                  <msub>
                    <mi>x</mi>
                    <mi>2</mi>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>3</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mn>2</mn>
                </mrow>
              </mfrac>
              <mo>)</mo>
              <mo>. . . </mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mi>f</mi>
              <mo>(</mo>
              <mfrac>
                <mrow>
                  <msub>
                    <mi>x</mi>
                    <mi>n - 1</mi>
                  </msub>
                  <mo>&nbsp; + &nbsp;</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>n</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mn>2</mn>
                </mrow>
              </mfrac>
              <mo>)</mo>
              <mo>]</mo>
            </math>
          </h6>
        </div>
      </li>
    </ul>
    <li>
      <h5>Other Approximation Methods</h5>
      <ul>
        <li>
          <h5>Limit Process to Find Area</h5>
          <h6>
            <math>
              <msup>
                <mo>&#8747;</mo>
                <mn>b</mn>
                <mn>a</mn>
              </msup>
              <mi>f</mi>
              <mn>(x)</mn>
              <mo>&nbsp;</mo>
              <mi>d</mi>
              <mi>x</mi>
              <mo>&nbsp; = &nbsp;</mo>
            </math>
            <math>
              <span id="" class="lim_infinity" style="font-size: 16px;">lim</span>
              <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>
            </math>
            <math>
              <mi>f</mi>
              <mo>(</mo>
              <msub>
                <mi>x</mi>
                <mi>i</mi>
              </msub>
              <mo>)</mo>
              <mn>&Delta;</mn>
              <mi>x</mi>
            </math>
            <br />
            <br />
            <u>Step 1</u>:&nbsp; define width of subinterval or &Delta;x
            <br />&emsp;&emsp;&emsp;&#8627;
            <math>
              <mo>&Delta;</mo>
              <mi>x</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>b</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mi>a</mi>
                </mrow>
                <mrow>
                  <mi>n</mi>
                </mrow>
              </mfrac>
            </math>
            <br />
            <br />
            <u>Step 2</u>:&nbsp; define <i>x</i><sub><i>i</i></sub> as # of subintervals
            <br />&emsp;&emsp;&emsp;&#8627;
            <math>
              <msub>
                <mi>x</mi>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>a</mi>
              <mo>&nbsp; + &nbsp;</mo>
              <mi>i</mi>
              <mo>&Delta;</mo>
              <mi>x</mi>
            </math>
            <br />
            <br />
            <u>Step 3</u>:&nbsp; apply summation notation for <i>i</i>,
            <i>i</i><sup>2</sup> & <i>i</i><sup>3</sup> as series
            <br />&emsp;&emsp;&emsp;&#8627;
            <math>
              <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>
            </math>
            <math>
              <mi>i</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>n(n + 1)</mi>
                </mrow>
                <mrow>
                  <mn>2</mn>
                </mrow>
              </mfrac>
            </math>
            <br />&emsp;&emsp;&emsp;&#8627;
            <math>
              <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>
            </math>
            <math>
              <msup>
                <mi>i</mi>
                <mn>2</mn>
              </msup>
            </math>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>n(n + 1)(2n + 1)</mi>
                </mrow>
                <mrow>
                  <mn>6</mn>
                </mrow>
              </mfrac>
            </math>
            <br />&emsp;&emsp;&emsp;&#8627;
            <math>
              <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>
            </math>
            <math>
              <msup>
                <mi>i</mi>
                <mn>3</mn>
              </msup>
            </math>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <msup>
                    <mo>n</mo>
                    <mn>2</mn>
                  </msup>
                  <mi>(n + 1)</mi>
                  <msup>
                    <mn></mn>
                    <mo>2</mo>
                  </msup>
                </mrow>
                <mrow>
                  <mn>4</mn>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </li>

        <li>
          <h5>Trapezoidal Rule</h5>
          <h7>Approximating area under curve may be more accurate because
            trapezoids get closer to the actual curve than rectangles</h7>
          <h6>
            <math>
              <msup>
                <mo>&#8747;</mo>
                <mn>b</mn>
                <mn>a</mn>
              </msup>
              <mi>f</mi>
              <mn>(x)</mn>
              <mo>&nbsp;</mo>
              <mi>d</mi>
              <mi>x</mi>
              <mo>&nbsp; &#8776; &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mn>&Delta;</mn>
                  <mi>x</mi>
                </mrow>
                <mrow>
                  <mn>2</mn>
                </mrow>
              </mfrac>
              <mo>[</mo>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <msub>
                <mi>x</mi>
                <mn>0</mn>
              </msub>
              <mo stretchy=False>)</mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mn>2</mn>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo stretchy=False>)</mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mn>2</mn>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo stretchy=False>)</mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mo>. . . </mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mn>2</mn>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <msub>
                <mi>x</mi>
                <mn>n-2</mn>
              </msub>
              <mo stretchy=False>)</mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mn>2</mn>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <msub>
                <mi>x</mi>
                <mn>n-1</mn>
              </msub>
              <mo stretchy=False>)</mo>
              <mo>&nbsp; + &nbsp;</mo>
              <mi>f</mi>
              <mo stretchy=False>(</mo>
              <msub>
                <mi>x</mi>
                <mi>n</mi>
              </msub>
              <mo stretchy=False>)</mo>
              <mo>]</mo>
            </math>
          </h6>
        </li>
        <li>
          <h5>Simpson's Rule</h5>
          <h7>The value of <i>n</i> must be even</h7>
          <div id="simpsons-rule-formula">
            <h6>
              <math>
                <msub>
                  <mi>S</mi>
                  <mi>n</mi>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mn>&Delta;</mn>
                    <mi>x</mi>
                  </mrow>
                  <mrow>
                    <mn>3</mn>
                  </mrow>
                </mfrac>
                <mo>[</mo>
                <mi>f</mi>
                <mo stretchy=False>(</mo>
                <msub>
                  <mi>y</mi>
                  <mn>0</mn>
                </msub>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mn>4</mn>
                <mi>f</mi>
                <mo stretchy=False>(</mo>
                <msub>
                  <mi>y</mi>
                  <mn>1</mn>
                </msub>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mn>2</mn>
                <mi>f</mi>
                <mo stretchy=False>(</mo>
                <msub>
                  <mi>y</mi>
                  <mn>2</mn>
                </msub>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mn>4</mn>
                <mi>f</mi>
                <mo stretchy=False>(</mo>
                <msub>
                  <mi>y</mi>
                  <mn>3</mn>
                </msub>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mo>. . . </mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mn>2</mn>
                <mi>f</mi>
                <mo stretchy=False>(</mo>
                <msub>
                  <mi>y</mi>
                  <mn>n-2</mn>
                </msub>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mn>4</mn>
                <mi>f</mi>
                <mo stretchy=False>(</mo>
                <msub>
                  <mi>y</mi>
                  <mn>n-1</mn>
                </msub>
                <mo stretchy=False>)</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mi>f</mi>
                <mo stretchy=False>(</mo>
                <msub>
                  <mi>y</mi>
                  <mi>n</mi>
                </msub>
                <mo stretchy=False>)</mo>
                <mo>]</mo>
              </math>
            </h6>
          </div>
        </li>
      </ul>
    </li>
    <li>
      <h5>Error Bounds</h5>
      <h7>Largest possible value of error of approximation; level of reliability</h7>
      <ul>
        <li>
          <h5>Midpoint Rule (E<sub>M</sub>)</h5>
          <div id="error-bound-midpoint-rule">
            <h6>
              <math>
                <mo stretchy=False>|</mo>
                <msub>
                  <mi>E</mi>
                  <mi>M</mi>
                </msub>
                <mo stretchy=False>|</mo>
                <mo>&nbsp; &#8804; &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mi>K</mi>
                    <mo>(</mo>
                    <mi>b &nbsp;</mi>
                    <mo>-</mo>
                    <mi>&nbsp; a</mi>
                    <mo>)</mo>
                    <msup>
                      <mn></mn>
                      <mn>3</mn>
                    </msup>
                  </mrow>
                  <mrow>
                    <mn>24</mn>
                    <msup>
                      <mi>n</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo stretchy=False>&emsp; |</mo>
                <msup>
                  <mi>f</mi>
                  <mi>&#x2033;</mi>
                </msup>
                <mo stretchy=False>(</mo>
                <mi>x</mi>
                <mo stretchy=False>)</mo>
                <mo stretchy=False>|</mo>
                <mo>&nbsp; &#8804; &nbsp;</mo>
                <mi>K</mi>
              </math>
            </h6>
          </div>
        </li>

        <li>
          <h5>Trapezoidal Rule (E<sub>T</sub>)</h5>
          <div id="error-bound-midpoint-rule">
            <h6>
              <math>
                <mo stretchy=False>|</mo>
                <msub>
                  <mi>E</mi>
                  <mi>T</mi>
                </msub>
                <mo stretchy=False>|</mo>
                <mo>&nbsp; &#8804; &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mi>K</mi>
                    <mo>(</mo>
                    <mi>b &nbsp;</mi>
                    <mo>-</mo>
                    <mi>&nbsp; a</mi>
                    <mo>)</mo>
                    <msup>
                      <mn></mn>
                      <mn>3</mn>
                    </msup>
                  </mrow>
                  <mrow>
                    <mn>12</mn>
                    <msup>
                      <mi>n</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo stretchy=False>&emsp; |</mo>
                <msup>
                  <mi>f</mi>
                  <mi>&#x2033;</mi>
                </msup>
                <mo stretchy=False>(</mo>
                <mi>x</mi>
                <mo stretchy=False>)</mo>
                <mo stretchy=False>|</mo>
                <mo>&nbsp; &#8804; &nbsp;</mo>
                <mi>K</mi>
              </math>
            </h6>
          </div>
        </li>
      </ul>
    </li>
    </ul>
  </div>

  <br /><br />
  <div id="Computer_Science_Arithmetic">
    <h3>Computer Science Arithmetic</h3>
    <h4>Absolute Value Inequalities</h4>
    <ul>
      <li>
        <h5>Absolute Value of a Function</h5>
        <ul>
          <li>
            <h5>Less Than <i>a</i></h5>
            <h7>Closer to zero than <i>a</i></h7>
            <h6>
              <math>
                <mo>|</mo>
                <mi>f</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo>|</mo>
                <mo>&nbsp; &#60; &nbsp;</mo>
                <mi>a</mi>
              </math>
              <br />
              <math>
                <mi>f</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo>&#62;</mo>
                <mi>-</mi>
                <mi>a</mi>
                <mi>&ensp; and &ensp;</mi>
                <mi>f</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo>&#60;</mo>
                <mi>a</mi>
              </math>
              <br />
              <math>
                <mi>-</mi>
                <mi>a</mi>
                <mo>&#60;</mo>
                <mi>f</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo>&#60;</mo>
                <mi>a</mi>
              </math>
              <br />
              <math>
                <mo>(</mo>
                <mi>-</mi>
                <mi>a</mi>
                <mo>,</mo>
                <mi>a</mi>
                <mo>)</mo>
              </math>
            </h6>
          </li>
          <li>
            <h5>Greater Than <i>a</i></h5>
            <h7>Further away from zero than <i>a</i></h7>
            <h6>
              <math>
                <mo>|</mo>
                <mi>f</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo>|</mo>
                <mo>&nbsp; &#62; &nbsp;</mo>
                <mi>a</mi>
              </math>
              <br />
              <math>
                <mi>f</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo>&#62;</mo>
                <mi>a</mi>
                <mi>&ensp; or &ensp;</mi>
                <mi>f</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo>&#60;</mo>
                <mi>-</mi>
                <mi>a</mi>
              </math>
            </h6>
          </li>
        </ul>
      </li>
    </ul>
    <h4>Scientific Notation</h4>
    <h7>Any number can be written in scientific notation. It involves shifting
      the decimal place to the left (positive) or right (negative) until the result
      is a number with only one place before the decimal point & then multiplying
      by 10 raised to the number of places shifted.</h7>
    <ul>
      <li>
        <h5>Notation Process Result</h5>
        <ol>
          <li>
            <h7>A decimal number less than 10 and greater than 1 multiplied by, </h7>
          </li>
          <li>
            <h7>10 raised to a specific whole number</h7>
          </li>
        </ol>
      </li>
      <li>
        <h5>Example:</h5>
        <h6>
          <math>
            <mn>&emsp;&ensp;1.17E</mn>
            <mo>&nbsp; + &nbsp;</mo>
            <mn>07</mn>
            <mo>&nbsp; = &nbsp;</mo>
            <mn>1.17</mn>
            <mo>&nbsp; * &nbsp;</mo>
            <msup>
              <mn>10</mn>
              <mn>7</mn>
            </msup>
            <mo>&nbsp; = &nbsp;</mo>
            <mn>11,700,000</mn>
          </math>
        </h6>
      </li>
    </ul>
  </div>

  <br /><br />
  <div id="Logarithms">
    <h3>Marvelous Logarithms</h3>
    <h7><b>Logarithms were the supercomputers their era. &nbsp; See the <a target="_blank" href=href="https://www.britannica.com/topic/Description-of-the-Marvelous-Canon-of-Logarithms"><i>Description of the Marvelous Canon of Logarithms</i></a> by
        John Napier</b>
    </h7>
    <ul>
      <li>
        <h5>Rule of Logs: the log of a product is the sum of the logs
          <br />Logarithms undo the actions of exponential functions. Logarithms & exponentials are inverse functions</h5>
      </li>
      <ul>
        <li>
          <h5>The inverse of an exponential function</h5>
          <h6><i>y</i> = <i>a</i><sup><i>x</i></sup> &ensp; &#8658; &ensp; <i>x</i> = <i>a</i><sup><i>y</i></sup></h6>
        </li>
        <li>
          <h5>The relationship of exponetial to logarithmic</h5>
          <h6>(the exponential function) <i>x</i> = <i>a</i><sup><i>y</i></sup> &ensp; &#8658; &ensp; log<sub><i>a</i></sub> of <i>x</i> = <i>y</i> (the logarithmic function)</h6>
        </li>
        <li>
          <h5>Arithmetic visualization</h5>
          <h6>100 = 10<sup>2</sup> &ensp; &#8658; &ensp; log<sub>10</sub> of 100 = 2</h6>
        </li>
      </ul>
      <li>
        <h5>The Binary Logarithm</h5>
        <h7>Log<sup>2</sup>&nbsp;<i>n</i> is the power to which the number 2 must be raised to obtain the value <i>n</i>.
          <br />For any real number x:</h7>
        <h6>
          <math>
            <mi>x</mi>
            <mo>&nbsp; = &nbsp;</mo>
            <msub>
              <mn>log</mn>
              <mn>2</mn>
            </msub>
            <mi>&nbsp;n</mi>
            <mo>&emsp; &#8660; &emsp;</mo>
            <msup>
              <mn>2</mn>
              <mi>x</mi>
            </msup>
            <mo>&nbsp; = &nbsp;</mo>
            <mi>n</mi>
          </math>
        </h6>
      </li>
    </ul>
  </div>


  <br /><br />
  <div id="discrete-mathematics">
    <h3>Cordially Discrete Mathematics</h3>
    <h7><b>Branch of mathematics dealing with discrete (distinct & disconnected) or finite sets of elements
        rather than continuous or infinite sets of elements. The terms <i>discrete</i> & <i>continuous</i> are analogous to the computer science terms <i>digital</i> & <i>analog</i>.</b>
      <br />* Brilliant course from Shawn Grooms at freeCodeCamp: <a href="https://www.youtube.com/playlist?list=PLWKjhJtqVAbndUuYBE5sVViMIvyzp_dB1"><i><b>Math for Programmers</b></i></a></h7>
    <ul>
      <li>
        <h5>Set of Natural Numbers</h5>
        <h6>&#8469; = {1, 2, 3, . . .} &ensp; <b style="color:turquoise">&#8658;
          </b> &ensp; The set of Natural Numbers (Cardinal or Counting Numbers)
          include all positive, non-zero integers.</h6>
      </li>
      <li>
        <h5>Set of Integers</h5>
        <h6>&#8484; = {. . . , -1, 0, 1, . . .}</h6>
      </li>
      <li>
        <h5>Set of Rational Numbers</h5>
        <h6>
          <math>
            <mo>&#8474;</mo>
            <mn>&nbsp; = &nbsp;</mn>
            <mo>{</mo>
            <mfrac>
              <mrow>
                <mi>a</mi>
              </mrow>
              <mrow>
                <mi>b</mi>
              </mrow>
            </mfrac>
            <mo>&nbsp; : &nbsp;</mo>
            <mi>a</mi>
            <mo>, &nbsp;</mo>
            <mi>b</mi>
            <mo>&nbsp; &#8712; &nbsp;</mo>
            <mo>&nbsp; &#8484;, &nbsp;</mo>
            <mi>b</mi>
            <mo>&nbsp; &#8800; &nbsp;</mo>
            <mn>0</mn>
            <mo>}</mo>
          </math>&nbsp;
          <b style="color:turquoise">&#8658;</b> &nbsp; The set of Rational Numbers
          include ratios of two integers where the denominator is non-zero.
        </h6>
      </li>
      <li>
        <h5>Binary Operators for Sets</h5>
        <ul>
          <li>
            <h5>For Sets:</h5>
            <h6><b>A = {x, y, z}</b>
              <br /><b>B = {c, x, y}</b>
            </h6>
          </li>
          <li>
            <h5>Union</h5>
            <h6>
              <math>
                <mn>A</mn>
                <mo>&nbsp; &#8746; &nbsp;</mo>
                <mn>B</mn>
                <mo>=</mo>
                <mo>{</mo>
                <mi>p</mi>
                <mo>: &nbsp;</mo>
                <mi>p</mi>
                <mo>&nbsp; &#8712; &nbsp;</mo>
                <mn>A</mn>
                <mi>&nbsp; or &nbsp;</mi>
                <mi>p</mi>
                <mo>&nbsp; &#8712; &nbsp;</mo>
                <mn>B</mn>
                <mo>}</mo>
              </math>&nbsp;
              <b style="color:turquoise">&#8658;</b> &nbsp; A union B equals the set
              containing elements p, such that p is an element of A or p is an element of B.</h6>
          </li>
          <li>
            <h5>Intersection</h5>
            <h6>
              <math>
                <mn>A</mn>
                <mo>&nbsp; &#8745; &nbsp;</mo>
                <mn>B</mn>
                <mo>=</mo>
                <mo>{</mo>
                <mi>p</mi>
                <mo>: &nbsp;</mo>
                <mi>p</mi>
                <mo>&nbsp; &#8712; &nbsp;</mo>
                <mn>A</mn>
                <mi>&nbsp; and &nbsp;</mi>
                <mi>p</mi>
                <mo>&nbsp; &#8712; &nbsp;</mo>
                <mn>B</mn>
                <mo>}</mo>
              </math>&nbsp;
              <b style="color:turquoise">&#8658;</b> &nbsp; A intersection B equals the set
              containing elements p, such that p is an element of A and p is an element of B.</h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Logic</h5>
        <h7>Logic is a systematic way of thinking that allows us to deduce new information from old information & to parse the meaning of sentences.</h7>
        <h6>Logic &nbsp; <b style="color:turquoise">&#8658;</b> &nbsp; Mathematics &nbsp;
          <b style="color:turquoise">&#8658;</b> &nbsp; Algorithms &nbsp;
          <b style="color:turquoise">&#8658;</b> &nbsp; Code
        </h6>
      </li>
      <li>
        <h5>The Universal Set</h5>
        <h7>The Universe is the maximum boundary of extant sets; it is the largest set; everything outside the Universal Set does not exist.
          <br />If the Universel Set is not defined, we assume it to be the set of Real Numbers (&#8477;).</h7>
      </li>
      <li>
        <h5>Associativity</h5>
        <h7>We can regroup the sets we are talking about - it does not matter where we put our parentheses.</h7>
        <h6>
          <math>
            <mn>A</mn>
            <mo>&nbsp; &#8746; &nbsp;</mo>
            <mo>(</mo>
            <mn>B</mn>
            <mo>&nbsp; &#8746; &nbsp;</mo>
            <mn>C</mn>
            <mo>)</mo>
            <mo>&nbsp; = &nbsp;</mo>
            <mo>(</mo>
            <mn>A</mn>
            <mo>&nbsp; &#8746; &nbsp;</mo>
            <mn>B</mn>
            <mo>)</mo>
            <mo>&nbsp; &#8746; &nbsp;</mo>
            <mn>C</mn>
          </math>
          <br />
          <math>
            <mn>A</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mo>(</mo>
            <mn>B</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mn>C</mn>
            <mo>)</mo>
            <mo>&nbsp; = &nbsp;</mo>
            <mo>(</mo>
            <mn>A</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mn>B</mn>
            <mo>)</mo>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mn>C</mn>
          </math>
        </h6>
      </li>
      <li>
        <h5>Commutativity</h5>
        <h7>We may switch which side our sets are on relative to the operator.</h7>
        <h6>
          <math>
            <mn>A</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mn>B</mn>
            <mo>&nbsp; = &nbsp;</mo>
            <mn>B</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mn>A</mn>
          </math>
          <br />
          <math>
            <mo>{</mo>
            <mi>x</mi>
            <mo>:</mo>
            <mi>x</mi>
            <mo>&#8712;</mo>
            <mn>A</mn>
            <mo>&nbsp; and &nbsp;</mo>
            <mi>x</mi>
            <mo>&#8712;</mo>
            <mn>B</mn>
            <mo>}</mo>
            <mo>&nbsp; = &nbsp;</mo>
            <mo>{</mo>
            <mi>x</mi>
            <mo>:</mo>
            <mi>x</mi>
            <mo>&#8712;</mo>
            <mn>B</mn>
            <mo>&nbsp; and &nbsp;</mo>
            <mi>x</mi>
            <mo>&#8712;</mo>
            <mn>A</mn>
            <mo>}</mo>
          </math>
        </h6>
      </li>
      <li>
        <h5>Distributivity</h5>
        <h7>A set & its operation will be shared over another set & operation.</h7>
        <h6>
          <math>
            <mn>A</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mo>(</mo>
            <mn>B</mn>
            <mo>&nbsp; &#8746; &nbsp;</mo>
            <mn>C</mn>
            <mo>)</mo>
            <mo>&nbsp; = &nbsp;</mo>
            <mo>(</mo>
            <mn>A</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mn>B</mn>
            <mo>)</mo>
            <mo>&nbsp; &#8746; &nbsp;</mo>
            <mo>(</mo>
            <mn>A</mn>
            <mo>&nbsp; &#8745; &nbsp;</mo>
            <mn>C</mn>
            <mo>)</mo>
          </math>
        </h6>
      </li>
      <li>
        <h5>Propositions</h5>
        <h7>A proposition is a declarative statement with a verifiable truth value; usually denoted with a lower-case letter.</h7>
        <h6>p = Cats are smart, furry animals. &ensp; <b style="color:turquoise">> </b>^<b style="color:salmon">+</b>^
          <b style="color:turquoise">
            < </b>
              <br />q = Cats have pet humans.
        </h6>
      </li>
      <li>
        <h5>Composite Propositions</h5>
        <h7>A proposition is a declarative statement with a verifiable truth value; including two or more subpropositions.</h7>
        <ul>
          <li>
            <h5>Conjuction (AND, "&#8743;")</h5>
            <h6>p&#8743;q = "Cats are smart, furry animals AND cats have pet humans."</h6>
          </li>
          <li>
            <h5>Disjuction (OR, "&#8744;")</h5>
            <h6>p&#8744;q = "Cats are smart, furry animals OR cats have pet humans."</h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Truth Tables</h5>
        <h7>Easy visualization of why a statement is true or false</h7>
        <table id="truth_table">
          <tr>
            <th>p</th>
            <th>q</th>
            <th>p&#8743;q</th>
            <th>p&#8744;q</th>
          </tr>
          <tr>
            <td>T</td>
            <td>T</td>
            <td>T&#8743;T = T</td>
            <td>T&#8744;T = T</td>
          </tr>
          <tr>
            <td>T</td>
            <td>F</td>
            <td>T&#8743;F = F</td>
            <td>T&#8744;F = T</td>
          </tr>
          <tr>
            <td>F</td>
            <td>T</td>
            <td>F&#8743;T = F</td>
            <td>F&#8744;T = T</td>
          </tr>
          <tr>
            <td>F</td>
            <td>F</td>
            <td>F&#8743;F = F</td>
            <td>F&#8744;F = F</td>
          </tr>
        </table>
      </li>
      <li>
        <h5>Algebraic Laws of Logic</h5>
        <ul>
          <li>
            <h5>Idempotence Law</h5>
            <h7>Denoting an element of a set which is unchanged in value when multiplied or otherwise operated on by itself.</h7>
            <h6>P &#8801; P&#8744;P &#8801; P&#8743;P</h6>
          </li>
          <li>
            <h5>Identity Law</h5>
            <h7>The <b><i>conjunction</i></b> of any proposition <b>P</b> with an arbitrary tautology <b>T</b> will always have the same truth value as <b>P</b>. It will be logically equivalent to <b>P</b>
              <br />The <b><i>disjunction</i></b> of any proposition <b>P</b> with an arbitrary tautology <b>T</b> will always be true. It will itsefl be a tautology.</h7>
            <h6>P &#8801; P &#8744; False &#8801; P &#8743; True
              <br />True &#8801; P &#8744; True
              <br />False &#8801; P &#8743; False</h6>
          </li>
          <li>
            <h5>Complements Law</h5>
            <h6>Where a propostion P is True:
              <br />P&#8744;&not;P &#8801; True &emsp; True &#8801; &not; False
              <br />P&#8743;&not;P &#8801; False &emsp; False &#8801; &not; True</h6>
          </li>
          <li>
            <h5>Involution Law</h5>
            <h7>If we have a proposition and we feed it through a function twice we'll end up in the same spot.</h7>
            <h6>P &#8801; &not;&not; P</h6>
          </li>
          <li>
            <h5>Commutative Law</h5>
            <h7>Relating to number operations of addition & multiplication, any finite sum is unaltered by reordering its terms or factors.</h7>
            <h6>p &#8744; q &#8801; q &#8744; p
              <br />p &#8743; q &#8801; q &#8743; p</h6>
          </li>
          <li>
            <h5>Associative Law</h5>
            <h6>(p &#8744; q) &#8744; r &#8801; p &#8744; (q &#8744; r)
              <br />(p &#8743; q) &#8743; r &#8801; p &#8743; (q &#8743; r)</h6>
          </li>
          <li>
            <h5>Binary Operation</h5>
            <h7>A calculation that combines two elements (called operands) to produce another element.</h7>
          </li>
        </ul>
      </li>
      <li>
        <h5>Logical Quantifiers</h5>
        <ul>
          <li>
            <h5>Propositional Function, p(x)</h5>
            <h7>A statement expressed in a form that would take on a value of true or false were it not for the appearance within it of a variable x (or of several variables), which leaves the statement undetermined as long as no definite values
              are
              specified for the variables.
              <br /><a target="_blank" href="https://www.britannica.com/science/propositional-function">Encyclopedia Britannica</a></h7>
          </li>
          <li>
            <h5>Universal Quantifier, <b>&#8704;</b></h5>
            <h7>Literally "for every" or "for all"</h7>
            <h6>
              <math>
                <mo>(</mo>
                <mo>&#8704;&nbsp;</mo>
                <mi>x</mi>
                <mo>&nbsp;&#8712;&nbsp;</mo>
                <mi>U</mi>
                <mo>)&ensp;</mo>
                <mi>p</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo style="color:turquoise">&emsp;&#8658;&emsp;</mo>
                <mi>For every&nbsp;</mi>
                <mi>x</mi>
                <mi>&nbsp;that is an element of the Universe,&nbsp;</mi>
                <mi>p</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mi>&nbsp;is either True or False.</mi>
              </math>
            </h6>
            <h7>Shorthand:</h7>
            <h6>
              <math>
                <mo>&#8704;&nbsp;</mo>
                <mi>x</mi>
                <mi>&ensp;</mi>
                <mi>p</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
                <mo style="color:turquoise">&emsp;&#8658;&emsp;</mo>
                <mi>For every&nbsp;</mi>
                <mi>x</mi>
                <mo>&nbsp;</mo>
                <mi>p</mi>
                <mo>(</mo>
                <mi>x</mi>
                <mo>)</mo>
              </math>
            </h6>
          </li>
          <li>
            <h5>Existential Quantifier, <b>&exist;</b></h5>
            <h7>Literally "there exists (at least one)"</h7>
            <h6>
              <math>
                <mo>(</mo>
                <mo>&exist;&nbsp;</mo>
                <mi>x</mi>
                <mo>&nbsp;&#8712;&nbsp;</mo>
                <mi>&#8477;</mi>
                <mo>)&ensp;</mo>
                <mo style="color:turquoise">&emsp;&#8658;&emsp;</mo>
                <mi>There exists&nbsp;</mi>
                <mi>x</mi>
                <mi>&nbsp;that is an element of the Real Numbers.</mi>
              </math>
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Tautologies</h5>
        <h7>Propositions that are always true.</h7>
        <ul>
          <li>
            <h5>Law of Excluded Middle</h5>
            <h6>P&#8744;&not;P</h6>
            <h7>"P OR not P"</h7>
          </li>
          <li>
            <h5>Law of Contradiction</h5>
            <h6>&not;(P&#8743;&not;P)</h6>
            <h7>"The negation of P AND not P"</h7>
          </li>
          <li>
            <h5>Modus Tollens or "Denying the Consequent"</h5>
            <h7><a target="_blank" href="https://www.google.com/search?q=meaning+modus+tollens&rlz=1C1CHBF_enUS900US900&oq=meaning+modus+tollens&aqs=chrome..69i57.4430j0j7&sourceid=chrome&ie=UTF-8">The rule of logic stating that if a conditional
                statement (“if p then q ”) is accepted, and the consequent does not hold ( not-q ), then the negation of the antecedent ( not-p ) can be inferred.</a></h7>
            <h6>[(P &#8658; q) &#8743; &not;q] &#8658; &not;P</h6>
            <h7>"P implies q, AND not q, implies not P"</h7>
          </li>
        </ul>
      </li>
      <li>
        <h5>Proofs Terminology</h5>
        <ul>
          <li>
            <h5>Theorem</h5>
            <h7>A mathematical statement that is true & can be (and has been) verified as true.</h7>
          </li>
          <li>
            <h5>Proof</h5>
            <h7>A proof of a theorem is a written verification that shows that the theorem is definitely and unequivocally true.</h7>
          </li>
          <li>
            <h5>Definition</h5>
            <h7>An exact, unambiguous explanation of the meaning of a mathematical word or phrase.</h7>
          </li>
          <li>
            <h5>Proposition</h5>
            <h7>A statement that is true and verifiable but not as significant as a theorem.</h7>
          </li>
          <li>
            <h5>Lemma</h5>
            <h7>A theorem whose main purpose is to help prove another theorem.</h7>
          </li>
          <li>
            <h5>Corollary</h5>
            <h7>A result that is an immediate consequence of a theorem or proposition.</h7>
          </li>
        </ul>
      </li>
    </ul>
  </div>

  <br /><br />
  <div id="number-theory">
    <h3>Nimble Number Theory</h3>
    <h7><b>The study of the numbers & their properties.</b></h7>
    <h4>The Integers</h4>
    <ul>
      <li>
        <h5>The Fundamental Theorem of Arithmetic</h5>
        <h7>Every positive integer can be written uniquely as the product of primes.</h7>
      </li>
    </ul>
  </div>

  <br /><br />
  <div id="construct-universe">
    <h3>Constructs of the Universe</h3>
    <h7><b>Mind-expanding & ancient wisdom from <a target="_blank" href="https://www.amazon.com/Beginners-Guide-Constructing-Universe-Mathematical/dp/0060926716"><i>A Beginner's Guide to Constructing the Universe</i></a> - Michael S. Schneider</b>
    </h7>
    <h4>The Monad | One</h4>
    <h7>"The ancient philosophers conceived that the Monad breathes in the void and creates all subsequent numbers"</h7>
    <ul>
      <li>
        <a target="_blank" href="https://grahamhancock.com/schneiderm1/">
          <h5>"Unity is all there really is, but polarity is required for any creation, so One casts its own shadow and pretends to be Two to generate the single digits:"</h5>
        </a>
        <h6>1 x 1 = <b style="color:turquoise">1</b>
          <br />11 x 11 = 1<b style="color:turquoise">2</b>1
          <br />111 x 111 = 12<b style="color:turquoise">3</b>21
          <br />1111 x 1111 = 123<b style="color:turquoise">4</b>321
          <br />11111 x 11111 = 1234<b style="color:turquoise">5</b>4321
          <br />111111 x 111111 = 12345<b style="color:turquoise">6</b>54321
          <br />1111111 x 1111111 = 123456<b style="color:turquoise">7</b>654321
          <br />11111111 x 11111111 = 1234567<b style="color:turquoise">8</b>7654321
          <br />111111111 x 111111111 = 12345678<b style="color:turquoise">9</b>87654321
        </h6>
      </li>
      <li>
        <a target="_blank" href="https://www.mathsisfun.com/pascals-triangle.html">
          <h5>Pascal's Triangle</h5>
        </a>
        <h7>Build the triangle with 1 at the top, continue placing numbers below in a triangular pattern. Each number below is the sum of the two numbers balanced above it.
          <br />&emsp;&emsp;&emsp;&emsp;&emsp;<b style="color:turquoise">Horizontal Sums &emsp;&#8658;&emsp; Powers of 2</b></h7>
        <h6><b style="color:#DB4437">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</b><b
            style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
            1</b> = 2<sup>0</sup>
          <br /><b style="color:#DB4437">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</b><b style="color:#ffa500">&nbsp;1</b><b
            style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
            2</b> = 2<sup>1</sup>
          <br /><b style="color:#DB4437">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;</b><b style="color:#ffa500">2</b><b style="color:gold">&nbsp;&nbsp;&nbsp;1</b><b
            style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= 4</b>
          =
          2<sup>2</sup>
          <br /><b style="color:#DB4437">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;</b><b style="color:#ffa500">3&nbsp;</b><b style="color:gold">&nbsp;&nbsp;3</b><b style="color:#0F9D58">&nbsp;&nbsp;&nbsp;&nbsp;1</b><b
            style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= 8</b> =
          2<sup>3</sup>
          <br /><b style="color:#DB4437">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;</b><b style="color:#ffa500">4&nbsp;</b><b style="color:gold">&nbsp;&nbsp;6&nbsp;</b><b style="color:#0F9D58">&nbsp;&nbsp;&nbsp;4</b><b
            style="color:#4285F4">&nbsp;&nbsp;&nbsp;&nbsp;1 &nbsp;</b><b style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= 16</b> = 2<sup>4</sup>
          <br /><b style="color:#DB4437">&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;</b><b style="color:#ffa500">5&nbsp;</b><b style="color:gold">10</b><b style="color:#0F9D58">&nbsp;&nbsp;10&nbsp;</b><b style="color:#4285F4">&nbsp;&nbsp;5 &nbsp;</b><b
            style="color:purple">1 &nbsp;</b><b style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= 32</b> = 2<sup>5</sup>
          <br /><b style="color:#DB4437">&nbsp;&nbsp;&nbsp;1&nbsp;</b><b style="color:#ffa500">6&nbsp;</b><b style="color:gold">15</b><b style="color:#0F9D58">&nbsp;20&nbsp;</b><b style="color:#4285F4">&nbsp;15 &nbsp;</b><b style="color:purple">6
            &nbsp;</b><b style="color:#EE82EE">1 &nbsp;</b><b style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= 64</b> = 2<sup>6</sup>
          <br /><b style="color:#DB4437">&nbsp;&nbsp;1&nbsp;</b><b style="color:#ffa500">7&nbsp;</b><b style="color:gold">21</b><b style="color:#0F9D58">&nbsp;35&nbsp;</b><b style="color:#4285F4">&nbsp;35 &nbsp;</b><b style="color:purple">21
            &nbsp;</b><b style="color:#EE82EE">7 &nbsp;</b><b style="color:pink">1 &nbsp;</b><b style="color:turquoise">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= 128</b> = 2<sup>7</sup>
          <br /><b style="color:#DB4437">&nbsp;1&nbsp;</b><b style="color:#ffa500">8&nbsp;</b><b style="color:gold">28</b><b style="color:#0F9D58">&nbsp;56&nbsp;</b><b style="color:#4285F4">&nbsp;70 &nbsp;</b><b style="color:purple">&nbsp;56
            &nbsp;</b><b style="color:#EE82EE">28 &nbsp;</b><b style="color:pink">8 &nbsp;</b><b style="color:darkgray">1 &nbsp;</b><b style="color:turquoise">&nbsp;&nbsp;= 256</b> = 2<sup>8</sup>
          <br /><b style="color:#DB4437">1&nbsp;</b><b style="color:#ffa500">9&nbsp;</b><b style="color:gold">36</b><b style="color:#0F9D58">&nbsp;84</b><b style="color:#4285F4">&nbsp;126&nbsp;</b><b style="color:purple">126&nbsp;</b><b
            style="color:#EE82EE">84&nbsp;</b><b style="color:pink">36&nbsp;</b><b style="color:darkgray">9&nbsp;</b><b style="color:lightgray">1</b><b style="color:turquoise">&nbsp;= 512</b> = 2<sup>9</sup>
        </h6>
        <ul>
          <li>
            <h5>Diagonals</h5>
            <h7><b style="color:#DB4437">&#8594; Ones</b>
              <br /><b style="color:#ffa500">&#8594; Counting Numbers</b>
              <br /><b style="color:gold">&#8594; Triangular Numbers</b>
              <br /><b style="color:#0F9D58">&#8594; Tetrahedral Numbers</b>
              <br /><b style="color:#4285F4">&#8594; Pentatope Numbers</b>
              <!-- <br /><b style="color:purple">&#8594; Hexahedral Numbers</b>
              <br /><b style="color:#EE82EE">&#8594; Heptahedral Numbers</b>
              <br /><b style="color:pink">&#8594; Octahedral Numbers</b>
              <br /><b style="color:darkgray">&#8594; Nonahedral Numbers</b> -->
            </h7>
          </li>
        </ul>
      </li>
    </ul>
    <h4>The Dyad | Two</h4>
    <h7></h7>
    <ul>
      <li>
        <h5>"The simplest arithmetic properties of any number reveal its deepest nature. Two is the balance or door linking the One with the Many."</h5>
        <h6>1 + 1 > 1 x 1 &#8594; <b>the Unique</b>
          <br />2 + 2 = 2 x 2 &#8594; <b style="color:turquoise">the Door</b>
          <br />3 + 3
          < 3 x 3 &#8600; <br />4 + 4 < 4 x 4 &#8594; <b style="color:Maroon">the Many</b>
            <br />5 + 5 < 5 x 5 &#8599; </h6>
      </li>
    </ul>
    <h4>The Triad | Three</h4>
    <h7>The unity of the circle manifests as a trinity: center or point, radius or line & circumference.</h7>
    <ul>
      <li>
        <h5>The only number of the infinitely many to equal the sum of all terms below it.</h5>
        <h6>3 = 2 + 1</h6>
      </li>
      <li>
        <h5>The only number whose sum with those below equal their product.</h5>
        <h6>1 + 2 + 3 = 3 x 2 x 1</h6>
      </li>
    </ul>
    <h4>The Tetrad | Four</h4>
    <h7>Three points define a flat surface, but it takes a fourth to define depth, progress to three dimensions and express geometry as volume.</h7>
    <ul>
      <li>
        <h5>Using four 4s, create numbers 0 - 9 using mathematical operators <a target="_blank" href="https://youtu.be/Noo4lN-vSvw"><i>Numberphile demonstration</i></a>:</h5>
        <h6>4 - 4 + 4 - 4 &emsp;= 0
          <br />(4 &#247; 4) + 4 - 4 = 1
          <br />4 - (4 + 4) &#247; 4 = 2
          <br />(4 &#215; 4 - 4) &#247; 4 = 3
          <br />4 + 4 &#215; (4 - 4) = 4
          <br />(4 &#215; 4 + 4) &#247; 4 = 5
          <br />(4 + 4) &#247; 4 + 4 = 6
          <br />4 + 4 - 4 &#247; 4 &emsp;= 7
          <br />4 &#247; 4 &#215; 4 + 4 &ensp;= 8
          <br />4 &#247; 4 + 4 + 4 &ensp;= 9
          <br />. . .
          <br />4 <b style="color:Maroon">?</b> 4 <b style="color:Maroon">?</b> 4 <b style="color:Maroon">?</b> 4 &emsp;= <b style="color:turquoise">&#8734;</b>
        </h6>
      </li>
    </ul>
    <h4>The Pentad | Five</h4>
    <h7>Pentagonal symmetry is the supreme symbol of life.</h7>
    <ul>
      <li>
        <h5>The principle of ongoing growth-from-within is the esssence of the Pentad's principle of regeneration & is visible in the Fibonacci Sequence</h5>
        <h6>0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610 . . .</h6>
      </li>
    </ul>
    <h4>The Hexad | Six</h4>
    <h7>The Hexad is sometimes symbolized by the "Pythagorean triangle" or "3-4-5
      right triangle" made by the ancient method using a twelve-knotted rope. It
      displays the sequence from one to six (1 - 6): one right angle (1), two unequal angles
      (2), sides of three (3), four (4), and five (5), and closing an area of six square units (6).</h7>
    <ul>
      <li>
        <h5>Multiples of six & the duodecimal frame are used for the structure, function & order of space-time</h5>
        <ul>
          <li>
            <h5>Structure</h5>
            <h6>12 inches = 1 foot
              <br />36 inches = 1 yard
              <br />360 degrees = measure of a circle
              <br />60 minutes = 1 degree of arc
              <br />60 seconds = 1 minute of arc</h6>
          </li>
          <li>
            <h5>Function</h5>
            <h6>12 = 1 dozen
              <br />12 dozen = 1 gross</h6>
          </li>
          <li>
            <h5>Order</h5>
            <h6>60 seconds = 1 minute
              <br />60 minutes = 1 hour
              <br />24 hours = 1 day
              <br />30 days = 1 month
              <br />12 months = 1 year
            </h6>
          </li>
        </ul>
      </li>
    </ul>
    <h4>The Heptad | Seven</h4>
    <h7>Seven is perhaps the most venerated number of the Dekad, the number par excellence in the ancient world</h7>
    <ul>
      <li>
        <h5>Only Seven Numbers Exist</h5>
        <h6>The ancient philosophers did not consider 1, 2 or 10 to be actual numbers but rather their source & result. So, the Dekad contains only 7 numbers: 3, 4, 5, 6, 7, 8 & 9.</h6>
      </li>
      <li>
        <h5>A Link & a Chasm</h5>
        <h6>1 &#215; 2 &#215; 3 &#215; 4 &#215; 5 &#215; 6 &#215; 7 &ensp; = &ensp; <b style="color:turquoise">5,040</b> &ensp; = &ensp; 7 &#215; 8 &#215; 9 &#215; 10</h6>
      </li>
    </ul>
    <h4>The Octad | Eight</h4>
    <h7>Periodic Renewal & the doubling number</h7>
    <ul>
      <li>
        <h5>Triple doubling & the beginning of exponetial growth</h5>
        <h6>
          <math>
            <msup>
              <mn>2</mn>
              <mn>3</mn>
            </msup>
            <mo>&nbsp; = &nbsp;</mo>
            <mn>2</mn>
            <mo>&#215;</mo>
            <mn>2</mn>
            <mo>&#215;</mo>
            <mn>2</mn>
            <mo>&nbsp; = &nbsp;</mo>
            <mn>8</mn>
          </math>
        </h6>
      </li>
      <li>
        <h5>Curious Mathematical Relationship of Septad & Octad</h5>
        <h6>Calculate 1 divide by 49 (=7&#215;7)</h6>
        <h6>The answer is an endless decimal built on the process of doubling = 0.020408163264128256. . .</h6>
      </li>
    </ul>
    <h4>The Ennead | Nine</h4>
    <h7>Composed of a trinity of trinities, the number nine represents the principles of the sacred Triad taken to their utmost expression.
      <br />The ancient Greeks called nine "the horizon," as it lies at the edge of the numerical shore before the boundless ocean of numbers that repeat in endless cycles the principles of the first nine digits.</h7>
    <ul>
      <li>
        <h5>Multiplying by nine reveals a mirror symmetry among the numbers.
          <br />When <i>any</i> number is multipled by nine the resulting digits always add to nine.</h5>
        <h6>1 &#215; 9 = <b style="color:turquoise">09</b> &emsp; <b style="color:turquoise">90</b> = 9 &#215; 10
          <br />2 &#215; 9 = <b style="color:turquoise">18</b> &emsp; <b style="color:turquoise">81</b> = 9 &#215; 9
          <br />3 &#215; 9 = <b style="color:turquoise">27</b> &emsp; <b style="color:turquoise">72</b> = 9 &#215; 8
          <br />4 &#215; 9 = <b style="color:turquoise">36</b> &emsp; <b style="color:turquoise">63</b> = 9 &#215; 7
          <br />5 &#215; 9 = <b style="color:turquoise">45</b> &emsp; <b style="color:turquoise">54</b> = 9 &#215; 6</h6>
      </li>
    </ul>
    <h4>The Decad | Ten</h4>
    <h7>The Decad represents the power to generate numbers beyond itself, toward the infinite. Multiplying any number by ten does not change its essential nature but only acts to expand its power.</h7>
    <ul>
      <li>
        <h5>The Tetraktys: an equilateral cosmological model of completeness of ten points unfolding in four levels.</h5>
        <h6>10 = 1 + 2 + 3 + 4
          <br />
          <br /><b style="color:turquoise">&#8857; &emsp;&#8857; &emsp;&emsp;&#8857; &emsp;&emsp;&emsp;&#8857;</b>
          <br /><b style="color:turquoise">&emsp;&ensp; &#8857; &#8857;&ensp; &#8857; &#8857;&emsp;&emsp; &#8857; &#8857;</b>
          <br /><b style="color:turquoise">&ensp;&ensp;&emsp; &emsp;&emsp;&#8857; &#8857; &#8857;&emsp;&#8857; &#8857; &#8857;</b>
          <br /><b style="color:turquoise">&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&#8857; &#8857; &#8857; &#8857;</b>
          <br />
          <br />1 &emsp;&ensp; 3 &emsp;&emsp;&ensp;6&emsp;&emsp;&emsp; 10</h6>
      </li>
    </ul>
  </div>

  <br /><br />
  <div id="References">
    <h3>Positively Brilliant References</h3>
    <ul>
      <li>
        <h7>Koshy, T. (2003). <i>Discrete Mathematics & Its Applications</i>.
          Academic Press. <a target="_blank" href="https://www.amazon.com/Discrete-Mathematics-Applications-Thomas-Koshy/dp/0124211801">Amazon</a></h7>
      </li>
      <li>
        <h7>Massaron, L. (2016). <i>Regression Analysis with Python</i>.
          Packt Publishing. <a target="_blank" href="https://www.amazon.com/Regression-Analysis-Python-Luca-Massaron/dp/1785286315">Amazon</a></h7>
      </li>
      <li>
        <h7>Schneider, M. (1994). <i>A Beginner's Guide to Constructing the
            Universe: The Mathematical Archetypes of Nature, Art, & Science</i>.
          HarperCollins Publishers. <a target="_blank" href="https://www.amazon.com/Beginners-Guide-Constructing-Universe-Mathematical/dp/0060926716">Amazon</a></h7>
      </li>
    </ul>
  </div>

  <br /><br />
  <div id="about">
    <h3>About Ryan L Buchanan</h3>
    <p class="para">
      I am training as a Data Analyst & Machine Learning Engineer.&nbsp; I
      am currently enrolled in a Masters in Data Analytics.&nbsp; I am also
      acquiring certifications as an ML Engineer & Algorithmic Trader from Udacity.
      &nbsp; I have an MBA & an MS in Instructional Design.
      <br /><br />
      I have a multi-displinary background including military intelligence,
      psychology, linguistics, economics, virtual reality & educational technology.&nbsp; I have
      worked abroad for ten years with military, universities & vocational schools.
      &nbsp; I have working knowledge of Arabic, Chinese & French.&nbsp; I am very
      mobile, able to relocate quickly, adapt easily to diverse working conditions
      & have a current passport.
      <br /><br />
      I have a passion for mathematics, statistics & artificial intelligence.&nbsp;
      I am enthusiastic, highly self-motivated & enjoy presenting informative data
      to decision makers.&nbsp; I am eager to work with dynamic teams to create
      high quality products & services.
    </p>
  </div>


  <script src="scripts/script.js"></script>

</body>

<footer>
  <div id="My_Links">
    <section>
      <h4 class="visuallyhidden"></h4>
      <a target="_blank" class="social-link" href="https://github.com/RyanLBuchanan">
        <img src="assets/social-github.png" alt="GitHub">
      </a>
      <a target="_blank" class="social-link" href="https://www.facebook.com/buchananryan22">
        <img src="assets/social-facebook.png" alt="Facebook">
      </a>
      <a target="_blank" class="social-link" href="https://www.linkedin.com/in/ryanlbuchanan/">
        <img src="assets/social-linkedin.png" alt="LinkedIn">
      </a>
      <a target="_blank" class="social-link" href="https://twitter.com/buchananryan22">
        <img src="assets/social-twitter.png" alt="Twitter">
      </a>
      <a target="_blank" class="social-link" href="https://stackoverflow.com/users/story/7541619?view=Timeline">
        <img src="assets/social-stack-overflow.png" alt="Stack Overflow">
      </a>
      <a target="_blank" class="social-link" href="https://www.ryangineer.com/virtual_reality.html">
        <img src="assets/social-youtube.png" alt="VR Dev Kids">
      </a>
      <a target="_blank" class="social-link" href="https://www.instagram.com/ryanlbuchanan/">
        <img src="assets/social-instagram.png" alt="Instagram">
      </a>
    </section>
  </div>
</footer>

</html>
