<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Ryangineer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
  <script src="scripts/jquery.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
  <!-- jQuery Content Delivery Network -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <!-- CDN React libraries-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/umd/react.profiling.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/cjs/react.development.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/cjs/react.production.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/babel-standalone/6.26.0/babel.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <!-- My Stylesheet -->
  <link rel="stylesheet" type="text/css" href="stylesheets/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
  <link rel="shortcut icon" href="assets/favicon.ico" type="image/x-icon">
  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a target="_blank" class="navbar-brand" href="#"></a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/ai_finance.html">Artificial Intelligence Finance</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/">Machine Learning</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/data_dashboard.html">Data Dashboard</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/virtual_reality.html">Virtual Reality</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/about.html">About</a>
        </li>
      </ul>
    </div>
  </nav>



  <div id="bio_image" style="float: left;">
    <figure>
      <img src="assets/bio_image.png" alt="Ryan L Buchanan" class="img-bio_image">
      <figcaption>
        <a target="_blank" href="mailto:buchananryan22@gmail.com">
          <b>buchananryan22@gmail.com</b></a><br />
        <a target="_blank" href="https://goo.gl/maps/UnhTaBZieDZU5F5w6"><b>Ogden, Utah, USA</b></a>
      </figcaption>
    </figure>
  </div>

  <div id="img_pythagoras">
    <img src="assets/pythagoras.png" alt="Pythagora" class="img-fluid">
  </div>

  <div>
    <h1 id="ryangineer"><b>Ryangineer</b></h1>
    <h2 id="ryangineer_sub" style="font-weight:bold;">Machine Learning Mathematics<br />&<br />Virtual Reality Aesthetics<br /><br /></h2>
  </div>

  <div id="Rodgers_Quotation" class="container">
    <div class="jumbotron">
      <p id="rodgers_quotation" style="border: 1px solid gray;"><b>"Mathematics requires a small dose, not of genius, but of an imaginative freedom which, in a larger dose, would be insanity."</b><br />Angus K. Rodgers</p>
    </div>
  </div>

  <br /><br />
  <div id="My_ML_projects">
    <h3>My Machine Learning Projects</h3>
    <table>
      <tr>
        <td>
          <ul>
            <li><a target="_blank" title="Data Preprocessing Template" href="https://github.com/RyanLBuchanan/Data_Preprocessing_Template_Python" /><b>Data Preprocessing Template</b></a></li>
            <li><a target="_blank" title="Iris ML" href="https://github.com/RyanLBuchanan/iris-ml" /><b>Iris Machine Learning</b></a></li>
            <li><a target="_blank" title="Titanic ML" href="https://github.com/RyanLBuchanan/Titanic_ML_Project" /><b>Titanic Machine Learning</b></a></li>
            <li><a target="_blank" title="Simple Linear Regression" href="https://github.com/RyanLBuchanan/Simple_Linear_Regression" /><b>Simple Linear Regression</b></a></li>
            <li><a target="_blank" title="Multiple Linear Regression" href="https://github.com/RyanLBuchanan/Multiple_Linear_Regression" /><b>Multiple Linear Regression</b></a></li>
            <li><a target="_blank" title="Polynomial Linear Regression" href="https://github.com/RyanLBuchanan/Polynomial_Linear_Regression" /><b>Polynomial Linear Regression</b></a></li>
            <li><a target="_blank" title="Support Vector Regression" href="https://github.com/RyanLBuchanan/Support_Vector_Regression" /><b>Support Vector Regression</b></a></li>
            <li><a target="_blank" title="Decision Tree Regression" href="https://github.com/RyanLBuchanan/Decision_Tree_Regression" /><b>Decision Tree Regression</b></a></li>
            <li><a target="_blank" title="Random Forest Regression" href="https://github.com/RyanLBuchanan/Random_Forest_Regression" /><b>Random Forest Regression</b></a></li>
            <li><a target="_blank" title="Logistic Regression" href="https://github.com/RyanLBuchanan/Logistic_Regression" /><b>Logistic Regression</b></a></li>
          </ul>
        </td>
        <td>
          <ul>
            <li><a target="_blank" title="Support Vector Machine" href="https://github.com/RyanLBuchanan/Support_Vector_Machine" /><b>Support Vector Machine</b></a></li>
            <li><a target="_blank" title="Kernel SVM Nonlinear" href="https://github.com/RyanLBuchanan/Kernel_SVM" /><b>Kernel SVM Nonlinear</b></a></li>
            <li><a target="_blank" title="Naive Bayes Classifier" href="https://github.com/RyanLBuchanan/Naive_Bayes" /><b>Naive Bayes Classifier</b></a></li>
            <li><a target="_blank" title="K-Nearest Neighbors" href="https://github.com/RyanLBuchanan/K_Nearest_Neighbors_Algorithm" /><b>K-Nearest Neighbors</b></a></li>
            <li><a target="_blank" title="K-Means Clustering" href="https://github.com/RyanLBuchanan/K-Means_Clustering" /><b>K-Means Clustering</b></a></li>
            <li><a target="_blank" title="Hierarchical Clustering" href="https://github.com/RyanLBuchanan/Hierarchical_Clustering" /><b>Hierarchical Clustering</b></a></li>
            <li><a target="_blank" title="Apriori" href="https://github.com/RyanLBuchanan/Apriori" /><b>Apriori Association</b></a></li>
            <li><a target="_blank" title="Upper Confidence Bound" href="https://github.com/RyanLBuchanan/Upper_Confidence_Bound" /><b>Upper Confidence Bound</b></a></li>
            <li><a target="_blank" title="Thompson Sampling" href="https://github.com/RyanLBuchanan/thompson_sampling" /><b>Thompson Sampling</b></a></li>
          </ul>
        </td>
      </tr>
    </table>
  </div>

  <br /><br />
  <div id="ML_Algorithms">
    <h3>Noteworthy Machine Learning Algorithms</h3>
    <a target="_blank" href="https://en.wikipedia.org/wiki/Supervised_learning">
      <h4>Supervised Learning</h4>
    </a>
    <h7><b>&nbsp; &#8627; "learning a function that maps to an output based on the example of input-output pairs"</b></h7>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Linear Regression | Predict Real Values</h5></a>
      </li>
      <h7>Estimate or predict real values based on continuous variables -> establish relationship between independent variables (matrix of features) & dependent variable (output) by fitting a best line</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Derivation of Line of Best Fit | Ordinary Least Squares method | Sum of Squares Residual</h5>
          </a></li>
        <h6>SS<sub>res</sub> = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>(y - y&#770;)<sup>2</sup> &#8594; min</h6>
        <li><a target="_blank" title="" href="">
            <h5>Simple Linear Regression</h5>
          </a></li>
        <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub></h6>
        <li><a target="_blank" title="" href="">
            <h5>Multiple Linear Regression</h5>
          </a></li>
        <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub> + b<sub>2</sub>x<sub>2</sub> + . . . + b<sub>n</sub>x<sub>n</sub></h6>
        <li><a target="_blank" title="" href="">
            <h5>Polynomial Linear Regression</h5>
          </a></li>
        <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub> + b<sub>2</sub>x<sub>2</sub><sup>2</sup> + . . . + b<sub>n</sub>x<sub>n</sub><sup>n</sup></h6>
        <li><a target="_blank" title="" href="">
            <h5>R Squared | Goodness of Fit Parameter</h5>
          </a></li>
        <h6>R<sup>2</sup> = 1 - SS<sub>res</sub>/SS<sub>tot</sub><br />
          &nbsp; &#8627; where: <br />
          <ul>&#8627; SS<sub>tot</sub> = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>(y - y<sub>avg</sub>)<sup>2</sup></ul>
        </h6>
        <li><a target="_blank" title="" href="">
            <h5>Adjusted R Squared</h5>
          </a></li>
        <h6>Adj R<sup>2</sup> = 1 - (1 - r<sup>2</sup>) * [(n - 1)/(n - p - 1)] <br />
          &nbsp; &#8627; where: <br />
          <ul>
            &#8627; p = number of regressors <br />
            &#8627; n = sample size
          </ul>
        </h6>
      </ul>
      <li><a target="_blank" title="" href="https://www.mathworks.com/help/stats/understanding-support-vector-machine-regression.html" />
        <h5>Support Vector Regression | Classification</h5></a>
      </li>
      <h7>Use as a regression method, maintaining all the main features that characterize the algorithm (maximal margin). The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences.
      </h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Epsilon-Insensitive Tube</h5>
          </a></li>
        <h6>1/2 ||w|| + C<span id="epsilon" style="font-size: 20px;">&Sigma;</span>(ξ<sub>i</sub> + ξ<sub>i</sub><sup>*</sup>) &#8594; min</h6>
        <li><a target="_blank" title="" href="">
            <h5>The Gaussian RBF Kernel</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>K</mi>
              <mo stretchy="false">(</mo>
              <mi>x&#8407;, &nbsp;</mi>
              <msup>
                <mi>l&#8407;</mi>
                <mn>&nbsp;i</mn>
              </msup>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mi>exp</mi>
              <mo stretchy="true">(</mo>
              <mo>-</mo>
              <mfrac>
                <mrow>
                  <mi>|| x&#8407;, &nbsp;</mi>
                  <msup>
                    <mi>l&#8407;</mi>
                    <mn>&nbsp;i</mn>
                  </msup>
                  <msup>
                    <mi>||</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
                <mrow>
                  <mi>2</mi>
                  <msup>
                    <mi>&sigma;</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
              </mfrac>
              <mo stretchy="true">)</mo>
            </math><br />
          </h6>
        </div>
      </ul>
      <li><a target="_blank" title="" href="" />
        <h5>Logistic Regression | Classification</h5></a>
      </li>
      <h7>Used to estimate discrete values, binary values (0/1, yes/no, true/false) based on given set of independent variables; predicts probability between 0 & 1 as output values</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Linear Regression | Sigmoid Function | Predicting Probability (p&#770;) </h5>
          </a></li>
        <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub><br /><br />
          <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
            <mi>&nbsp; &#8627;p</mi>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>1 &nbsp;</mi>
              </mrow>
              <mrow>
                <mi>1 &nbsp; +</mi>
                <msup>
                  <mi>&nbsp; e</mi>
                  <mn>-y</mn>
                </msup>
              </mrow>
            </mfrac>
          </math><br /><br />
          <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
            <mi>&nbsp;&nbsp;&nbsp;&#8627;&nbsp;ln</mi>
            <mo stetchy=false>(</mo>
            <mfrac>
              <mrow>
                <mi>p &nbsp;</mi>
              </mrow>
              <mrow>
                <mi>1 - p</mi>
              </mrow>
            </mfrac>
            <mo stetchy=false>)</mo>
            <mo>=</mo>
            <msub>
              <mi>b</mi>
              <mn>0</mn>
            </msub>
            <mi>+</mi>
            <msub>
              <mi>b</mi>
              <mn>1</mn>
            </msub>
            <mi>x</mi>
          </math><br />
        </h6>
      </ul>
      <li><a target="_blank" title="" href="" />
        <h5>Decision Tree Regression</h5></a>
      </li>
      <h7>Supervised learning algorithm used for classification problems; works for categorical & continuous variables</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Standard Deviation Reduction</h5>
          </a></li>
        <h6>F(T, X) = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>P(c)S(c)</h6>
      </ul>
      <li><a target="_blank" title="" href="" />
        <h5>Support Vector Machines | Discriminative Classifier</h5></a>
      </li>
      <h7>Discriminative classifier formally defined by a separating hyperplane</h7>
      <ul>
        <li><a target="_blank" title="" href="https://medium.com/@ankitnitjsr13/math-behind-support-vector-machine-svm-5e7376d0ee4d">
            <h5>Maximum Margin Hyperplane | Support Vectors</h5>
          </a></li>
        <h6>{x<sub><i>i</i></sub>, y<sub><i>i</i></sub>} where <i>i</i> = 1 . . . L, y<sub><i>i</i></sub> &#8712; {-1, 1}, x &#8712; &#8477;<sup>D</sup></h6>
      </ul>
      <li><a target="_blank" title="Kernel Functions" href="https://towardsdatascience.com/kernel-function-6f1d2be6091" />
        <h5>Kernel SVM | Nonlinear</h5></a>
      </li>
      <h7>Mapping to a higher-dimensional space, applying the support vector algorithm & then projecting back to lower dimensional space resulting in a nonlinear separator</h7>
      <ul>
        <li><a target="_blank" title="The Math Behind SVM" href="https://medium.com/@ankitnitjsr13/math-behind-support-vector-machine-svm-5e7376d0ee4d">
            <h5>Linearly Separable with Hyperplane in 3D</h5>
          </a></li>
        <h6>&phi;(x<sub>1</sub>, x<sub>2</sub>) &#8658; (x<sub>1</sub>, x<sub>2</sub>, z) </h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">
            <h5>The Gaussian or Radial Basis Function (RBF) Kernel</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>K</mi>
              <mo stretchy="false">(</mo>
              <mi>x&#8407;, &nbsp;</mi>
              <msup>
                <mi>l&#8407;</mi>
                <mn>&nbsp;i</mn>
              </msup>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mi>exp</mi>
              <mo stretchy="true">(</mo>
              <mo>-</mo>
              <mfrac>
                <mrow>
                  <mi>|| x&#8407;, &nbsp;</mi>
                  <msup>
                    <mi>l&#8407;</mi>
                    <mn>&nbsp;i</mn>
                  </msup>
                  <msup>
                    <mi>||</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
                <mrow>
                  <mi>2</mi>
                  <msup>
                    <mi>&sigma;</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
              </mfrac>
              <mo stretchy="true">)</mo>
            </math><br />
          </h6>
        </div>
        <h6>&#8627; where:<br />
          <ul>
            &#8627; K = function applied to two vectors<br />
            &#8627; x = point in datasets<br />
            &#8627; <i>l</i> = landmark
          </ul>
        </h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="http://www.cs.toronto.edu/~duvenaud/cookbook/index.html">
            <h5>Sigmoid Kernel</h5>
          </a></li>
        <h6><i>K(X, Y)</i> = tanh(<i>&gamma; <b>&dot;</b> X<sup>T</sup>Y + r</i>)</h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="http://www.cs.toronto.edu/~duvenaud/cookbook/index.html">
            <h5>Polynomial Kernel</h5>
          </a></li>
        <h6><i>K(X, Y)</i> = tanh(<i>&gamma; <b>&dot;</b> X<sup>T</sup>Y + r</i>)<sup><i>d</i></sup>, <i>&gamma;</i> &#62; 0</h6>
      </ul>
      <li><a target="_blank" title="" href="" />
        <h5>Naive Bayes Classification</h5></a>
      </li>
      <h7>Probabilistic classifier based on Bayes Theorem with an assumption of independence between predictors (aka, features or independent variables)</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Bayes Theorem &#8658; The probability of an event given prior knowledge of related events that occurred earlier</h5>
          </a></li>
        <div style="text-align: left;">
          <math id="bayes_theorem" xmlns="http://www.w3.org/1998/Math/MathML">
            <mi>P</mi>
            <mo stretchy="false">(</mo>
            <mi>y</mi>
            <mo>&#x2223;</mo>
            <msub>
              <mi>x</mi>
              <mn>1</mn>
            </msub>
            <mo>,</mo>
            <mo>&#x2026;</mo>
            <mo>,</mo>
            <msub>
              <mi>x</mi>
              <mi>n</mi>
            </msub>
            <mo stretchy="false">)</mo>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>P</mi>
                <mo stretchy="false">(</mo>
                <mi>y</mi>
                <mo stretchy="false">)</mo>
                <mi>P</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mn>1</mn>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;</mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mi>n</mi>
                </msub>
                <mo>&#x2223;</mo>
                <mi>y</mi>
                <mo stretchy="false">)</mo>
              </mrow>
              <mrow>
                <mi>P</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mn>1</mn>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;</mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mi>n</mi>
                </msub>
                <mo stretchy="false">)</mo>
              </mrow>
            </mfrac>
          </math>
        </div>
      </ul>
      <li><a target="_blank" title="" href="" />
        <h5>K-Nearest Neighbors</h5></a>
      </li>
      <h7>Used for classification & regression; a simple algorithm that stores all available cases & classifies new cases by a "majority vote" of its K-nearest neighbors</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Euclidean Distance</h5>
          </a></li>
        <div style="text-align: left;">
          <math id="euclidean" xmlns="http://www.w3.org/1998/Math/MathML">
            <mi>Between</mi>
            <msub>
              <mi>P</mi>
              <mn>1</mn>
            </msub>
            <mo stretchy="false"> & </mo>
            <msub>
              <mi>P</mi>
              <mn>2</mn>
            </msub>
            <mo>=</mo>
            <msqrt>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>x</mi>
                <mi>1</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <msup>
                <mi>2</mi>
              </msup>
              <mo stretchy="false">+</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>y</mi>
                <mn>2</mn>
              </msub>
              <mo>-</mo>
              <msub>
                <mi>y</mi>
                <mi>1</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <msup>
                <mi>2</mi>
              </msup>
            </msqrt>
          </math>
        </div>
      </ul>
    </ul>
    <br />
    <a target="_blank" title="" href="https://en.wikipedia.org/wiki/Unsupervised_learning#:~:text=Unsupervised%20learning%20is%20a%20type,a%20minimum%20of%20human%20supervision" />
    <h4>Unsupervised Learning</h4></a>
    <h7><b>&nbsp; &#8627; "looks for previously undetected patterns in a data set with no pre-existing labels and with a minimum of human supervision"</b></h7>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>K-Means Clustering</h5></a>
      </li>
      <h7>Unsupervised algorithm which solves clustering problems; follows simple/easy way to classify a dataset through a certain number of clusters</h7>
      <ul>
        <li><a target="_blank" title="" href="https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce#:~:text=Within%20Cluster%20Sum%20of%20Squares&text=To%20calculate%20WCSS%2C%20you%20first,by%20the%20number%20of%20points.">
            <h5>Within Cluster Sum of Squares (WCSS)| Quantifiable metric to evaluate how certain number of clusters performs compared to different number of clusters</h5>
          </a></li>
        <h6>WCSS = <span id="wcss1" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>1</sub>)<sup>2</sup> + <span id="wcss2" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>2</sub>)<sup>2</sup>
          +<span id="wcss3" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>3</sub>)<sup>2</sup></h6>
        <h6>&#8627; where:<br />
          <ul>
            &#8627; distance = distance between each point inside cluster<br />
            &#8627; C = centroids, respectively<br />
          </ul>
        </h6>
      </ul>
      <li><a target="_blank" title="" href="https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html" />
        <h5>Apriori Association</h5></a>
      </li>
      <h7>Analyzes the association of specific preferences in customer transactions (movies watched, items purchased in convenience store - beer & pampers urban myth) to discover relationships and how items are associated with each other</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Support</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>Movie recommendation example: <br />
            &nbsp; &#8627; where M = specific <u>M</u>ovie<br />
            <br />
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Support(M)</mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi># of user watchlists containing M</mi>
                </mrow>
                <mrow>
                  <mi># of user watchlists</mi>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </div>
        <li><a target="_blank" title="" href="">
            <h5>Confidence</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Confidence</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>M</mi>
                <mn>1</mn>
              </msub>
              <mo>&#x2192;</mo>
              <msub>
                <mi>M</mi>
                <mi>2</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi># of user watchlists containing</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>&#x2192;</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi># of user watchlists containing</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>1</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </div>
        <li><a target="_blank" title="" href="">
            <h5>Lift &#8594; measuring the relevance of an associated rule & the improvement prediction</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Lift</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>M</mi>
                <mn>1</mn>
              </msub>
              <mo>&#x2192;</mo>
              <msub>
                <mi>M</mi>
                <mi>2</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>Confidence</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>&#x2192;</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>Support</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </div>
      </ul>
    </ul>
    <br />
    <a target="_blank" href="https://en.wikipedia.org/wiki/Reinforcement_learning">
      <h4>Reinforcement Learning</h4>
    </a>
    <h7><b>&nbsp; &#8627; "how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward"</b></h7>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Upper Confidence Bound Algorithm | Deterministic Model</h5></a>
      </li>
      <a target="_blank" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">
        <h7>Modern application of Multi-Armed Bandit Problem (reference slot machine distributions)</h7>
      </a>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Advertising Model (requires update at every round)</h5>
          </a></li>
        <h6><u>Step 1</u>: Each round <i>n</i> considers two numbers for each ad <i>i</i>:<br />
          <ul>
            &nbsp; &#8627; <i>N<sub>i</sub></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> selected up to round <i>n</i><br />
            &nbsp; &#8627; <i>R<sub>i</sub></i>(<i>n</i>) &#x2192; &Sigma; of rewards of ad <i>i</i> up to round <i>n</i><br />
          </ul><br />
          <u>Step 2</u>: From these two numbers we compute:<br />
          <ul>
            &nbsp; &#8627; Average reward of ad <i>i</i> up to round <i>n</i> with:
        </h6>
        <div style="text-align: left;">
          <ul>
            <h6>&nbsp; &nbsp; &nbsp; &nbsp;
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>r&#772;</mi>
                <mo stretchy="false">(</mo>
                <mi>n</mi>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <mfrac>
                  <mrow>
                    <msub>
                      <mi>R</mi>
                      <mn>i</mn>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                  <mrow>
                    <msub>
                      <mi>N</mi>
                      <mn>i</mn>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                </mfrac>
              </math><br />
            </h6>
          </ul>
        </div>
        <ul>
          <h6>&nbsp; &#8627; Confidence interval [<i>r&#772;<sub>i</sub></i>(<i>n</i>) - &#x25B3;<sub><i>i</i></sub>(<i>n</i>), <i>r&#772;<sub>i</sub></i>(<i>n</i>) +
            &#x25B3;<sub><i>i</i></sub>(<i>n</i>)] at round <i>n</i> with:</h6>
        </ul>
        <div>
          <ul>
            <h6>&nbsp; &nbsp; &nbsp; &nbsp;
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <msub>
                  <mi>&#x25B3;</mi>
                  <mn>i</mn>
                </msub>
                <mo stretchy="false">(</mo>
                <mi>n</mi>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <msqrt>
                  <mfrac>
                    <mrow>
                      <mi>3</mi>
                    </mrow>
                    <mrow>
                      <mi>2</mi>
                    </mrow>
                  </mfrac>
                  <mo>*</mo>
                  <mfrac>
                    <mrow>
                      <mi>log</mi>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>N</mi>
                        <mn>i</mn>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                  </mfrac>
                </msqrt>
              </math><br />
            </h6>
          </ul>
        </div>
        <h6><u>Step 3</u>: Select the ad <i>i</i> that has the maximum UCB <i>r&#772;<sub>i</sub></i>(<i>n</i>) +
          &#x25B3;<sub><i>i</i></sub>(<i>n</i>)<br />
      </ul>
    </ul>
    </ul>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Thompson Sampling Algorithm | Probabilistic Model</h5></a>
      </li>
      <a target="_blank" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">
        <h7>Constructs distributions of where we think the actual expected value might lie; an auxiliary mechanism to solve the problem</h7>
      </a>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Advertising Model (can accomodate delayed feedback & has better empirical evidence than UCB)</h5>
          </a></li>
        <h6><u>Step 1</u>: Each round <i>n</i> considers two numbers for each ad <i>i</i>:<br />
          <ul>
            &nbsp; &#8627; <i>N<sub>i</sub><sup>1</sup></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> rewarded 1 up to round <i>n</i><br />
            &nbsp; &#8627; <i>N<sub>i</sub><sup>0</sup></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> rewarded 0 up to round <i>n</i><br />
          </ul><br />
          <u>Step 2</u>: For each ad <i>i</i>, we take a random draw from the distribution below:<br />
          <ul>
            <br />
            <i>&theta;</i><sub>i</sub>(<i>n</i>) = <i>&beta;</i>(<i>N<sub>i</i></sub><sup>1</sup>(<i>n</i>) + 1, <i>N<sub>i</sub></i><sup>0</sup>(<i>n</i> + 1))
          </ul>
          <br />
        </h6>
        <h6><u>Step 3</u>: Select the ad <i>i</i> that has highest <i>&theta;</i><sub>i</sub>(<i>n</i>)<br />
      </ul>
    </ul>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Random Forest Regression</h5></a>
      </li>
      <h7>Ensemble decision trees; a collection of decision trees (aka forest) to classify a new object based on attributes; each tree gives a classification & we say the tree "votes" for the class </h7>
      <!-- <ul>
        <li><a target="_blank" title="" href="">
            <h5>Type</h5>
          </a></li>
        <h6>Equation</h6>
      </ul> -->
      <li><a target="_blank" title="" href="" />
        <h5>Dimensionality Reduction</h5></a>
      </li>
      <h7>Identifies highly significant variables when you have thousands</h7>
      <!-- <ul>
        <li><a target="_blank" title="" href="">
            <h5>Type</h5>
          </a></li>
        <h6>Equation</h6>
      </ul> -->
      <li><a target="_blank" title="" href="" />
        <h5>Gradient Boosting</h5></a>
      </li>
      <h7>Ensemble of machine learning algorithms</h7>
      <!-- <ul>
        <li><a target="_blank" title="" href="">
            <h5>Type</h5>
          </a></li>
        <h6>Equation</h6>
      </ul> -->
    </ul>
  </div>

  <br /><br />
  <div id="My_NN_Projects">
    <h3>My Neural Networks Projects</h3>
    <table>
      <tr>
        <td>
          <ul>
            <li><a target="_blank" title="ANN_Regression" href="https://github.com/RyanLBuchanan/ANN_Regression" /><b>Artificial Neural Network | Regression</b></a></li>
            <li><a target="_blank" title="ANN-geodemographic-segmentation" href="https://github.com/RyanLBuchanan/ANN-geodemographic-segmentation" /><b>Artificial Neural Network | Geodemographic Segmentation of Bank Clients</b></a></li>
            <li><a target="_blank" title="CNN_boilerplate" href="https://github.com/RyanLBuchanan/CNN_boilerplate" /><b>Convolutional Neural Network | Boiler Plate</b></a></li>
            <li><a target="_blank" title="Face_Recognition_CNN" href="https://github.com/RyanLBuchanan/Face_Recognition_CNN" /><b>Convolutional Neural Network | Facial Recognition</b></a></li>

          </ul>
        </td>
        <td>
          <ul>
            <li><a target="_blank" title="CNN_Cat_r_Dog" href="https://github.com/RyanLBuchanan/CNN_Cat_r_Dog" /><b>Convolutional Neural Network | Is it a Cat or Dog?</b></a></li>
            <li><a target="_blank" title="Generative Adversarial Network | Neural Style Transfer" href="https://github.com/RyanLBuchanan/Neural_Style_Transfer" /><b>Generative Adversarial Network | Neural Style Transfer</b></a></li>
            <li><a target="_blank" title="Natural Language Processing" href="https://github.com/RyanLBuchanan/Natural_Language_Processing" /><b>Natural Language Processing</b></a></li>
            <li><a target="_blank" title="Bidirectional Encoder Representations from Transformers" href="https://github.com/RyanLBuchanan/Bidirectional_Encoder_Representations_Transformers" /><b>Bidirectional Encoder Representations from
                Transformers</b></a></li>
          </ul>
        </td>
      </tr>
    </table>
  </div>

  <br /><br />
  <div id="Deep_Learning">
    <h3>Lovely Deep Learning</h3>
    <div id="ANNs">
      <a id="definition" target="_blank" href="https://towardsdatascience.com/understanding-neural-networks-what-how-and-why-18ec703ebd31">
        <h4>Artificial Neural Networks</h4>
      </a>
      <h7><b>&nbsp; &#8627; A computing system that consist of a number of simple but highly interconnected elements or nodes, called ‘neurons’, which are organized in layers which process information using dynamic state responses to external inputs,
          an extremely useful algorithm for finding patterns too complex to be manually extracted</b></h7>
      <ul>
        <li><a target="_blank" title="Understanding neural networks 1: The concept of neurons" href="https://becominghuman.ai/understanding-neural-networks-1-the-concept-of-neurons-287be36d40f" />
          <h5>Neuron Definition</h5></a>
        </li>
        <h7>A mathematical operation that takes its input, multiplies it by its weight & then passes the sum through an activation function</h7>
        <ul>
          <li><a target="_blank" title="Understanding neural networks 2: The math of neural networks in 3 equations" href="https://becominghuman.ai/understanding-neural-networks-2-the-math-of-neural-networks-in-3-equations-6085fd3f09df">
              <h5>Neuron Formula</h5>
            </a></li>
          <h6>Y<sub>1</sub> = activation(w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub> + . . . + w<sub>m</sub>x<sub>m</sub>)</h6>
          <li><a target="_blank" title="Understanding neural networks 2: The math of neural networks in 3 equations" href="https://becominghuman.ai/understanding-neural-networks-1-the-concept-of-neurons-287be36d40f">
              <h5>Sigmoid Activation Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>1 &nbsp;</mi>
                </mrow>
                <mrow>
                  <mi>1 &nbsp; +</mi>
                  <msup>
                    <mi>&nbsp; e</mi>
                    <mn>-z</mn>
                  </msup>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Threshold Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mo stretchy="true">{</mo>
              <mrow>
                <mi>1 if x &#x2265; 0</mi>
              </mrow>
              <mrow>
                <mi>&nbsp;,&nbsp;0 if x < 0</mi>
              </mrow>
              <mo stretchy="true">}</mo>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Rectifier Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mo stretchy="false">(</mo>
              <mi>x, 0</mi>
              <mo stretchy="false">)</mo>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Hyperbolic Tangent Function (tanh)</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>1&nbsp; - &nbsp;</mi>
                  <msup>
                    <mi>e</mi>
                    <mn>-2x</mn>
                  </msup>
                </mrow>
                <mrow>
                  <mi>1&nbsp; + &nbsp;</mi>
                  <msup>
                    <mi>e</mi>
                    <mn>-2x</mn>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </ul>
      </ul>
    </div>
    <br />
    <div id="CNNs">
      <a id="definition" target="_blank" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">
        <h4>Convolutional Neural Networks</h4>
      </a>
      <h7><b>&nbsp; &#8627; A class of deep neural networks, most commonly applied to analyzing visual imagery. CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each
          neuron in one layer is connected to all neurons in the next layer.</b></h7>
      <ul>
        <li><a target="_blank" title="" href="" />
          <h5>Convolution | Visual Imagery Analysis</h5></a>
        </li>
        <h7>A special kind of mathematical linear operation to give a network a degree of translation invariance; eg, a typical image convolution is a form of blurring</h7>
      </ul>
    </div>
    <br />
    <div id="NLPs">
      <a id="definition" target="_blank"
        href="https://classroom.udacity.com/nanodegrees/nd009t/parts/c4bacd6f-3766-4b62-994f-23e44e4c1f68/modules/52fce89d-5551-4d94-8bdc-48089274b27b/lessons/ab4cc389-336f-401c-937a-54f8c2aea24c/concepts/f5efb207-200c-4194-9ada-1189f4d66312">
        <h4>Natural Language Processing</h4>
      </a>
      <h7><b>&nbsp; &#8627; Starts with raw text in whatever format available, processes it, extracts relevant features and builds models to accomplish various NLP tasks</b></h7>
      <ul>
        <li><a target="_blank" title="" href="" />
          <h5>NLP Pipeline</h5></a>
        </li>
        <h6>Text Processing &nbsp; &#8658; &nbsp; Feature Extraction &nbsp; &#8658; &nbsp; Modeling</h6>
        <ul>
          <li>
            <h5>Document-Term Matrix</h5>
            <h7>Compute dot product (sum of the products of corresponding elements) to find similarities</h7>
            <h6>a * b = &Sigma; (a<sub>1</sub>b<sub>1</sub> + a<sub>2</sub>b<sub>2</sub> + a<sub>3</sub>b<sub>3</sub> + . . . + a<sub>n</sub>b<sub>n</sub>)</h6>
          </li>
          <li>
            <h5>Cosine Similarity</h5>
            <h7>Divide the product of two vectors by their magnitudes or Euclidean norms</h7>
            <h6>
              <math>
                <mi>cos(&theta;) = </mi>
                <mfrac>
                  <mrow>
                    <mi>a*b</mi>
                  </mrow>
                  <mrow>
                    <mi>||a||*||b||</mi>
                  </mrow>
                </mfrac>
                <br />&nbsp; &#8627; where:
                <br />&nbsp; &nbsp; &nbsp; Identical vectors &#x2192; cos(&theta;) = 1
                <br />&nbsp; &nbsp; &nbsp; Orthogonal vectors &#x2192; cos(&theta;) = 0
                <br />&nbsp; &nbsp; &nbsp; Exact opposite vectors &#x2192; cos(&theta;) = -1
              </math>
            </h6>
          </li>
          <li>
            <h5>TF-IDF Transform</h5>
            <h7>Term frequency-inverse document frequency</h7>
            <br />
            <h6>
              <mi>tfidf(t, d, D) = tf(t, d) * idf(t, D)</mi>
              <br />&nbsp; &#8627; where:
              <br />&nbsp; &nbsp; &nbsp;
              <mi>tf(t, d) = </mi>
              <math>
                <mi></mi>
                <mfrac>
                  <mrow>
                    <mi>count(t, d)</mi>
                  </mrow>
                  <mrow>
                    <mi>|d|</mi>
                  </mrow>
                </mfrac>
              </math>
              <br />&nbsp; &nbsp; &nbsp;
              <mi>idf(t, D) = </mi>
              <math>
                <mi>Log</mi>
                <mo stretchy=True>(</mo>
                <mfrac>
                  <mrow>
                    <mi>|D|</mi>
                  </mrow>
                  <mrow>
                    <mi>|{d &#8712; D : t &#8712; d}|</mi>
                  </mrow>
                </mfrac>
                <mo stretchy=True>)</mo>
              </math>
            </h6>
          </li>
        </ul>
        <li>
          <h5>Stemming</h5>
          <h7>Takes the root of a word removing conjugation to simplify & understand gist meaning (reducing final dimension )</h7>
        <li><a target="_blank" title="" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html#:~:text=Lemmatization%20usually%20refers%20to%20doing,is%20known%20as%20the%20lemma%20." />
        </li>
        <h5>Lemmatization</h5></a>
        </li>
        <h7>Refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.</>
      </ul>
    </div>
  </div>

  <br /><br />
  <div id="Linear_Algebra">
    <h3>Intimate Linear Algebra</h3>
    <h4>Determinants</h4>
    <a target="_blank" href="https://en.wikipedia.org/wiki/Determinant">
      <h7><b>&nbsp; &#8627; The volume scaling factor of the linear transformation described by the matrix</b></h7>
    </a>
    <ul>
      <li>
        <h5>Square Matrices</h5>
        <ul>
          <li>
            <h5>Determinant Equation 2x2 Matrix</h5>
            <h6>
              <math>
                <mrow>
                  <mo>|</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <mn>a</mn>
                      </mtd>
                      <mtd>
                        <mn>b</mn>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <mn>c</mn>
                      </mtd>
                      <mtd>
                        <mn>d</mn>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>|</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mn>ad</mn>
                  <mo>&nbsp; - &nbsp;</mo>
                  <mn>bc</mn>
                </mrow>
              </math>
            </h6>
          </li>
          <li>
            <h5>Trace of Matrix</h5>
            <h7>Equal to the sum of the values along the main diagonal</h7>
            <h6>
              <math>
                <mrow>
                  <mi>Trace </mi>
                  <mo>[</mo>
                  <mtable>
                    <mtr>
                      <mtd>
                        <mn>a</mn>
                      </mtd>
                      <mtd>
                        <mn>b</mn>
                      </mtd>
                    </mtr>
                    <mtr>
                      <mtd>
                        <mn>c</mn>
                      </mtd>
                      <mtd>
                        <mn>d</mn>
                      </mtd>
                    </mtr>
                  </mtable>
                  <mo>]</mo>
                  <mo>&nbsp; = &nbsp;</mo>
                  <mn>a</mn>
                  <mo>&nbsp; + &nbsp;</mo>
                  <mn>d</mn>
                </mrow>
              </math>
            </h6>
          </li>
        </ul>
      </li>
    </ul>
    <a target="_blank" title="No BS Guide to Linear Algebra" href="https://github.com/minireference/noBSLAnotebooks#chapters-overview">
      <h4>Geometrical Aspects of Linear Algebra</h4>
    </a>
    <h7><b>&nbsp; &#8627; Mathematics to used see through to the governing dynamics of the physical universe</b></h7>
    <ul>
      <li><a target="_blank" title="Intuitive Math" href="https://intuitive-math.club/" />
        <h5>Orthogonality & Change of Basis</h5></a>
        <ul>
          <li><a target="_blank" title="" href="">
              <h5>Least Squares Solution</h5>
            </a>
            <h6>
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <msup>
                  <mi>A</mi>
                  <mn>T</mn>
                </msup>
                <mi>A</mi>
                <msup>
                  <mi>x&#8407;</mi>
                  <mn>*</mn>
                </msup>
                <mo>=</mo>
                <msup>
                  <mi>A</mi>
                  <mn>T</mn>
                </msup>
                <mi> b&#8407; </mi>
              </math>
            </h6>
          </li>
      </li>
    </ul>
    <li>
      <h5>Orthonormal Bases</h5>
      <ul>
        <li>
          <h5>Orthogonality</h5>
          <h7>Every vector in set is orthogonal to every other vector in set; as perpendicular is to two-dimensional space (vectors at 90&#176; angle), orthogonal is to three- or n-dimensional space.</h7>
          <h6>
            <math>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&#8901;</mo>
              <msub>
                <mi>v&#8407;</mi>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>0</mo>
            </math>
          </h6>
        </li>
        <li>
          <h5>Normality</h5>
          <h7>Every vector has been normalized; every vector has a length of 1.</h7>
          <h6>
            <math>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&#8901;</mo>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>&#8741;</mo>
              <msub>
                <mi>v&#8407;</mi>
                <mn>1</mn>
              </msub>
              <mo>&#8741;</mo>
              <msup>
                <mi></mi>
                <mn>2</mn>
              </msup>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>1</mo>
            </math>
          </h6>
        </li>
        <li>
          <h5>Projection onto an Orthonormal Basis</h5>
          <h7>Using an orthonormal subspace drastically simplifies projection equation from:</h7>
          <h6>
            <math>
              <msub>
                <mi>Proj</mi>
                <mn>v</mn>
              </msub>
              <mi>x&#8407;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>A</mo>
              <mo>(</mo>
              <msup>
                <mn>A</mn>
                <mn>T</mn>
              </msup>
              <mn>A</mn>
              <mo>)</mo>
              <msup>
                <mn></mn>
                <mn>-1</mn>
              </msup>
              <msup>
                <mn>A</mn>
                <mn>T</mn>
              </msup>
              <mi>x&#8407;</mi>
            </math>
            <br />
            <mn>&emsp;&emsp;&emsp;&nbsp; &#8595;</mn>
            <br />
            <math>
              <msub>
                <mi>Proj</mi>
                <mn>v</mn>
              </msub>
              <mi>x&#8407;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mn>A</mn>
              <msup>
                <mn>A</mn>
                <mn>T</mn>
              </msup>
              <mi>x&#8407;</mi>
            </math>
          </h6>
        </li>
        <li>
          <h5>Gram-Schmidt Process</h5>
          <h7>Converts non-orthonormal set into an orthonormal set</h7>
          <h6>
            <math>
              <mi>Subspace v</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
              <mi>&emsp;&emsp;&emsp;&emsp;Step 1: &emsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <msub>
                    <mn>v&#8407;</mn>
                    <mn>1</mn>
                  </msub>
                </mrow>
                <mrow>
                  <mn>&#8741;</mn>
                  <msub>
                    <mn>v&#8407;</mn>
                    <mn>1</mn>
                  </msub>
                  <mn>&#8741;</mn>
                </mrow>
              </mfrac>
            </math>
            <br />
            <mi>&emsp;&emsp;&emsp;&emsp;&ensp;</mi>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
              <mi>&emsp;&emsp;&emsp;&emsp; Step 2: &emsp;</mi>
              <msub>
                <mn>w&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; - &nbsp;</mo>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>&nbsp; &#8901; &nbsp;</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>)</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
            </math>
            <br />
            <mi>&emsp;&emsp;&emsp;&emsp;&ensp;</mi>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
              <mi>&emsp;&emsp;&emsp;&emsp; Step 3: &emsp;</mi>
              <msub>
                <mn>w&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; - &nbsp;</mo>
              <mo>[</mo>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; &#8901; &nbsp;</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>)</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <mo>(</mo>
              <msub>
                <mn>v&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>&nbsp; &#8901; &nbsp;</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>)</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mo>]</mo>
            </math>
            <br />
            <mi>&emsp;&emsp;&emsp;&emsp;&ensp;</mi>
            <math>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>span</mi>
              <mo>(</mo>
              <msub>
                <mn>u&#8407;</mn>
                <mn>1</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>2</mn>
              </msub>
              <mi>, &nbsp;</mi>
              <msub>
                <mn>u&#8407;</mn>
                <mn>3</mn>
              </msub>
              <mo>)</mo>
            </math>
          </h6>
        </li>
      </ul>
    <li>
      <h5>Eigenvalues & Eigenvectors</h5>
      <a target="_blank" href="https://www.reddit.com/r/explainlikeimfive/comments/1avwm7/eli5_eigenvalues_and_eigenvectors_and_why_are/">
        <h7>Literally "special" values/vectors that correspond to a matrix or linear transformation; a way to diagonalize a problem, adjusting specific parts without disturbing others</h7>
      </a>
      <ul>
        <li>
          <h5>Eigenvector Transformation</h5>
          <h6>
            <math>
              <mi>T(v&#8407;)</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>Av&#8407;</mi>
            </math>
            <br />
            <math>
              <mi>T(v&#8407;)</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>&lambda;v&#8407;</mi>
              <br />&nbsp; &#8627; where:
              <br />&nbsp; &nbsp; &nbsp;
            </math>
            <math>
              <mi>&lambda;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>eigenvalue; a scalar</mi>
            </math>
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <mn>v&#8407; </mn>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>eigenvector</mi>
            </math>
            <br />
            <math>
              <mo>&#8756; &nbsp; </mo>
              <mi>Av&#8407;</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mi>&lambda;v&#8407;</mi>
            </math>
            <br />&nbsp; &#8627; algebraically:
            <br />&nbsp; &nbsp; &nbsp;
            <math>
              <mo>0&#8407;</mo>
              <mo>&nbsp; = &nbsp;</mo>
              <mo>(</mo>
              <mo>&lambda;</mo>
              <msub>
                <mn>I</mn>
                <mn>n</mn>
              </msub>
              <mo>&nbsp; - &nbsp;</mo>
              <mo>A</mo>
              <mo>)</mo>
              <mn>v&#8407;</mn>
            </math>
          </h6>
        </li>
        <li>
          <h5>Eigenspace (E<sub>&lambda;</sub>)</h5>
          <h6>
            <math>
              <mrow>
                <msub>
                  <mn>E</mn>
                  <mn>&lambda;</mn>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <mn>N</mn>
                <mo>(</mo>
                <mn>&lambda;</mn>
                <msub>
                  <mn>I</mn>
                  <mn>n</mn>
                </msub>
                <mo>&nbsp; - &nbsp;</mo>
                <mn>A</mn>
                <mo>)</mo>
              </mrow>
            </math>
            <br />&nbsp; &#8627; where:
            <br />&emsp;
            <math>
              <mrow>
                <mn>N</mn>
                <mo>&nbsp; = &nbsp;</mo>
                <mn>Null Space</mn>
              </mrow>
            </math>
            <br />&emsp;
            <math>
              <mrow>
                <msub>
                  <mn>I</mn>
                  <mn>n</mn>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>Identity Matrix</mi>
              </mrow>
            </math>
          </h6>
        </li>
      </ul>
    </li>
    </li>
    </ul>
  </div>

  <br /><br />
  <div id="Statistics_Probabilities">
    <h3>Salient Statistics & Probabilities</h3>
    <h7><b>&nbsp; &#8627; Is statistics a field of mathematics? Some say it is not mathematics but the science of data. Whatever you decide, you must embrace it, my Dear Friends.</b></h7>
    <h4>Probability Fundamentals</h4>
    <ul>
      <li>
        <h5>Basic Formulae</h5>
      </li>
      <ul>
        <li>
          <h5>Probability of an Event</h5>
        </li>
        <h6>
          <math>
            <mi>P(A)</mi>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>Outcome(s) You Are Looking For</mi>
              </mrow>
              <mrow>
                <mi>Total Possible Outcomes</mi>
              </mrow>
            </mfrac>
            <mo>&#8658;</mo>
            <mfrac>
              <mrow>
                <mi>Event</mi>
              </mrow>
              <mrow>
                <mi>Sample space</mi>
              </mrow>
            </mfrac>
            <mo>&#8658;</mo>
            <mfrac>
              <mrow>
                <mi>A, B, etc.</mi>
              </mrow>
              <mrow>
                <mo>S</mo>
              </mrow>
            </mfrac>
          </math>
        </h6>
        <li>
          <h5>Complement of an Event</h5>
        </li>
        <h6>
          <math>
            <mi>P(A&#772;)</mi>
            <mo>=</mo>
            <mi> 1 - P(A)</mi>
          </math>
        </h6>
        <li>
          <h5>Union(&#8746;, Or) & Intersection(&#8745;, And)</h5>
        </li>
        <h6>P(A &#8746; B) = P(A) + P(B) - P(A &#8745; B)</h6>
      </ul>
    </ul>
    <h4>Sampling</h4>
    <ul>
      <li>
        <h5>Gaussian Distribution Formulas</h5>
      </li>
      <ul>
        <li><a target="_blank" title="" href="https://en.wikipedia.org/wiki/Probability_density_function" />
          <h5>Probability Density Function</h5></a>
        </li>
        <h6>
          <math>
            <mi>f</mi>
            <mo stretchy=False>(</mo>
            <mi>x | &mu;,</mi>
            <msup>
              <mi>&nbsp; &sigma;</mi>
              <mn>2</mn>
            </msup>
            <mo stretchy=False>) = </mo>
            <mfrac>
              <mrow>
                <mi>1</mi>
              </mrow>
              <mrow>
                <msqrt stretchy=False>
                  <mi>2 &pi;</mi>
                  <msup>
                    <mi>&sigma;</mi>
                    <mn>2</mn>
                  </msup>
                </msqrt>
              </mrow>
            </mfrac>
            <msup>
              <mi>e</mi>
              <mn>
                <mo>-</mo>
                <mfrac>
                  <mrow>
                    <msup>
                      <mi>(x - &mu;)</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                  <mrow>
                    <mi>2</mi>
                    <msup>
                      <mi>&sigma;</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
              </mn>
            </msup>
          </math>
          <br />&nbsp; &#8627; where:
          <br />&nbsp; &nbsp; &nbsp;
          <math>
            <mi>&mu; = mean</mi>
          </math>
          <br />&nbsp; &nbsp; &nbsp; &sigma; = standard deviation
          <br />&nbsp; &nbsp; &nbsp;
          <math>
            <msup>
              <mi>&sigma;</mi>
              <mn>2</mn>
            </msup>
          </math>
          = variance
        </h6>
      </ul>
      <li>
        <h5>Binomial Distribution Formulas</h5>
      </li>
      <ul>
        <li>
          <h5>Mean</h5>
        </li>
        <h6>
          <math>
            <mi>&mu; = n * p</mi>
          </math>
        </h6>
        <li>
          <h5>Standard Deviation</h5>
        </li>
        <h6>
          <math>
            <mi>&sigma; = </mi>
            <msqrt>
              <mi>n * p * (1 - p)</mi>
            </msqrt>
          </math>
        </h6>
        <li>
          <h5>Variance</h5>
        </li>
        <h6>
          <math>
            <msup>
              <mi>&sigma;</mi>
              <mn>2</mn>
            </msup>
            <mo>=</mo>
            <mi>n * p * (1 - p)</mi>
          </math>
        </h6>
        <li>
          <h5>Probability Density Function</h5>
        </li>
        <h6>
          <math>
            <mi>f</mi>
            <mo stretchy=false>(</mo>
            <mi>k</mi>
            <mo>,</mo>
            <mi>n</mi>
            <mo>,</mo>
            <mi>p</mi>
            <mo stretchy=false>)</mo>
            <mo>=</mo>
            <mfrac>
              <mrow>
                <mi>n</mi>
                <mo>!</mo>
              </mrow>
              <mrow>
                <mi>k</mi>
                <mo>!(</mo>
                <mi>n</mi>
                <mo>-</mo>
                <mi>k</mi>
                <mo>)!</mo>
              </mrow>
            </mfrac>
            <msup>
              <mi>p</mi>
              <mn>k</mn>
            </msup>
            <mo stretchy=false>(</mo>
            <mo>1</mo>
            <mo>-</mo>
            <mi>&nbsp;</mi>
            <mi>p</mi>
            <mo stretchy=false>)</mo>
            <msup>
              <mi> </mi>
              <mn>(n - k)</mn>
            </msup>
          </math>
        </h6>
      </ul>
      <li><a target="_blank" title="" href="" />
        <h5>Sample Distribution of the Sample Proportion</h5></a>
      </li>
      <h7></h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Mean & Standard Error</h5>
          </a></li>
        <h6>
          <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
            <msub>
              <mi>&mu;</mi>
              <mn>p&#770;</mn>
            </msub>
            <mo>=</mo>
            <mi>p</mi>
          </math>
          <br />
          <math>
            <mi>SE</mi>
            <mo>&#8658;</mo>
            <msub>
              <mi>&sigma;</mi>
              <mn>p&#770;</mn>
            </msub>
            <mo>=</mo>
            <msqrt>
              <mfrac>
                <mrow>
                  <mi>p</mi>
                  <mo stretchy="false">(</mo>
                  <mi>1</mi>
                  <mo>-</mo>
                  <mi>p</mi>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>n</mi>
                </mrow>
              </mfrac>
            </msqrt>
          </math>
        </h6>
        <li><a target="_blank" title="" href="https://en.wikipedia.org/wiki/Mean_squared_error">
            <h5>Mean Squared Error & Root Mean Squared Error</h5>
          </a></li>
        <h7>An estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value</h7>
      </ul>
      <li><a target="_blank" title="" href="" />
        <h5>Confidence Interval</h5></a>
      </li>
      <h7></h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>CI for a Population Mean</h5>
          </a></li>
        <h6>
          <math>
            <mi>(a, b)</mi>
            <mo>=</mo>
            <mi>x&#772; &#177; z *</mi>
            <mfrac>
              <mrow>
                <mi>&sigma;</mi>
              </mrow>
              <mrow>
                <msqrt>
                  <mi>n</mi>
                </msqrt>
              </mrow>
            </mfrac>
            <mo>&#8658;</mo>
            <mi>x&#772; &#177;</mi>
            <msub>
              <mi>&nbsp;z</mi>
              <mn>&alpha;/2</mn>
            </msub>
            <mo>*</mo>
            <mfrac>
              <mrow>
                <mi>&sigma;</mi>
              </mrow>
              <mrow>
                <msqrt>
                  <mi>n</mi>
                </msqrt>
              </mrow>
            </mfrac><br />
          </math>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          &nbsp;or<br />
          <math>
            <mi>(a, b)</mi>
            <mo>=</mo>
            <mi>x&#772; &#177; z *</mi>
            <msub>
              <mi>&sigma;</mi>
              <mn>x&#772;</mn>
            </msub>
            <mo>&#8658;</mo>
            <mi>x&#772; &#177;</mi>
            <msub>
              <mi>&nbsp;z</mi>
              <mn>&alpha;/2</mn>
            </msub>
            <mo>&nbsp;*&nbsp;</mo>
            <msub>
              <mi>&sigma;</mi>
              <mn>x&#772;</mn>
            </msub>
            <br />
          </math>
          &nbsp; &#8627; where:<br />
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a = lower limit of confidence interval<br />
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b = upper limit of confidence interval<br />
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;z* = critical value &#8658; z-score<br />
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&alpha; = (1 - confidence level) &#8658; signicance level
        </h6>
        <li>
          <h5>CI for Population Proportion</h5>
        </li>
        <h6>
          <math>
            <mi>(a, b)</mi>
            <mo>=</mo>
            <mi>p&#770; &#177; z *</mi>
            <msqrt>
              <mfrac>
                <mrow>
                  <mi>p&#770;(1 - p&#770;)</mi>
                </mrow>
                <mrow>
                  <mi>n</mi>
                </mrow>
              </mfrac>
            </msqrt>
          </math>
          <br />
        </h6>
        <li>
          <h5>Solved for Sample Size (n)</h5>
        </li>
        <h6>
          <math>
            <mi>n = &nbsp;</mi>
            <mo stretchy=true>(</mo>
            <mfrac>
              <mrow>
                <mi>z*</mi>
                <msqrt>
                  <mi>p&#770;(1 - p&#770;)</mi>
                </msqrt>
              </mrow>
              <mrow>
                <mi>ME</mi>
              </mrow>
            </mfrac>
            <mo stretchy=true>)</mo>
            <msup>
              <mi></mi>
              <mn>2</mn>
            </msup>
          </math><br />
          &nbsp; &#8627; where:<br />
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p&#770; = sample proportion
        </h6>
        <li><a target="_blank" title="" href="">
            <h5>Margin of Error (ME)</h5>
          </a></li>
        <h6>
          <math>
            <mi>ME = Distance from sample mean (x&#772;) or sample proportion (p&#770;) to either edge of confidence interval</mi>
            <br />
          </math>
          <math>
            <mi>&nbsp; &nbsp; &nbsp; &nbsp; = </mi>
            <mi>&nbsp; &#177;</mi>
            <mi>&nbsp;z</mi>
            <mo>&nbsp;*&nbsp;</mo>
            <mfrac>
              <mrow>
                <mi>&sigma;</mi>
              </mrow>
              <mrow>
                <msqrt>
                  <mi>n</mi>
                </msqrt>
              </mrow>
            </mfrac><br />
          </math>
          <math>
            <mi>&nbsp; &nbsp; &nbsp; &nbsp; = </mi>
            <mi>&nbsp; &#177; z *</mi>
            <msqrt>
              <mfrac>
                <mrow>
                  <mi>p&#770;(1 - p&#770;)</mi>
                </mrow>
                <mrow>
                  <mi>n</mi>
                </mrow>
              </mfrac>
            </msqrt>
          </math>
        </h6>
      </ul>
    </ul>
    <h4>Hypothesis Testing</h4>
    <ul>
      <li>
        <h5>Calculate Test Statistic</h5>
      </li>
      <h7><b>&nbsp; &#8627; Using the population mean (&mu;):</b></h7>
      <ul>
        <li>
          <h5>When &sigma; is known</h5>
          <h6>
            <math>
              <mi>z</mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>x&#772;</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <msub>
                    <mi>&mu;</mi>
                    <mn>o</mn>
                  </msub>
                </mrow>
                <mrow>
                  <msub>
                    <mi>&sigma;</mi>
                    <mn>x&#772;</mn>
                  </msub>
                </mrow>
              </mfrac>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>x&#772;</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <msub>
                    <mi>&mu;</mi>
                    <mn>o</mn>
                  </msub>
                </mrow>
                <mrow>
                  <mfrac>
                    <mrow>
                      <mi>&sigma;</mi>
                    </mrow>
                    <mrow>
                      <msqrt>
                        <mi>n</mi>
                      </msqrt>
                    </mrow>
                  </mfrac>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </li>
        <li>
          <h5>When &sigma; is unknown | large sample > 30</h5>
          <h6>
            <math>
              <mi>t</mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>x&#772;</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <msub>
                    <mi>&mu;</mi>
                    <mn>o</mn>
                  </msub>
                </mrow>
                <mrow>
                  <msub>
                    <mi>s</mi>
                    <mn>x&#772;</mn>
                  </msub>
                </mrow>
              </mfrac>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>x&#772;</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <msub>
                    <mi>&mu;</mi>
                    <mn>o</mn>
                  </msub>
                </mrow>
                <mrow>
                  <mfrac>
                    <mrow>
                      <mi>s</mi>
                    </mrow>
                    <mrow>
                      <msqrt>
                        <mi>n</mi>
                      </msqrt>
                    </mrow>
                  </mfrac>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </li>
        <li>
          <h5>When &sigma; is unknown | small sample < 30 | assume normal distribution</h5>
              <h6>
                <math>
                  <mi>t</mi>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>x&#772;</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mi>&mu;</mi>
                        <mn>o</mn>
                      </msub>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>s</mi>
                        <mn>x&#772;</mn>
                      </msub>
                    </mrow>
                  </mfrac>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>x&#772;</mi>
                      <mo>&nbsp; - &nbsp;</mo>
                      <msub>
                        <mi>&mu;</mi>
                        <mn>o</mn>
                      </msub>
                    </mrow>
                    <mrow>
                      <mfrac>
                        <mrow>
                          <mi>s</mi>
                        </mrow>
                        <mrow>
                          <msqrt>
                            <mi>n</mi>
                          </msqrt>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </mfrac>
                </math>
              </h6>
        </li>
      </ul>
      <h7><b>&nbsp; &#8627; Using the population proportion (p):</b></h7>
      <ul>
        <li>
          <h5>Expected value of population proportion (p&#770;) known</h5>
          <h6>
            <math>
              <mi>z</mi>
              <mo>&nbsp; = &nbsp;</mo>
              <mfrac>
                <mrow>
                  <mi>p&#770;</mi>
                  <mo>&nbsp; - &nbsp;</mo>
                  <msub>
                    <mn>p</mn>
                    <mn>o</mn>
                  </msub>
                </mrow>
                <mrow>
                  <msqrt>
                    <mfrac>
                      <mrow>
                        <msub>
                          <mn>p</mn>
                          <mn>o</mn>
                        </msub>
                        <mo>(</mo>
                        <mo>1</mo>
                        <mo>&nbsp; - &nbsp;</mo>
                        <msub>
                          <mn>p</mn>
                          <mn>o</mn>
                        </msub>
                        <mo>)</mo>
                      </mrow>
                      <mrow>
                        <mi>n</mi>
                      </mrow>
                    </mfrac>
                  </msqrt>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </li>
      </ul>
    </ul>
    <h4>Regression</h4>
    <a target="_blank" href="https://blog.minitab.com/blog/statistics-and-quality-data-analysis/so-why-is-it-called-regression-anyway">
      <h7><b>&nbsp; &#8627; So . . . why is it called "Regression", anyway?</b></h7>
    </a>
    <ul>
      <li>
        <h5>Regression Analysis</h5>
        <h7>Process used to turn a set of disconnected data points into an equation that models the whole set</h7>
        <ul>
          <li>
            <h5>Trend or Regression Line, Approximating Curve, Line of Best Fit, Least Squares Line</h5>
            <h6>
              <math>
                <mi>y&#770;</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>mx + b</mi>
              </math>
            </h6>
          </li>
          <li>
            <h5>Slope</h5>
            <h6>
              <math>
                <mi>m</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mi>n&Sigma;xy - &Sigma;x&Sigma;y</mi>
                  </mrow>
                  <mrow>
                    <mi>n&Sigma;</mi>
                    <msup>
                      <mi>x</mi>
                      <mn>2</mn>
                    </msup>
                    <mo>&nbsp; - &nbsp;</mo>
                    <mi>(&Sigma;x)</mi>
                    <msup>
                      <mi></mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
              </math>
            </h6>
          </li>
          <li>
            <h5>Y-intercept</h5>
            <h6>
              <math>
                <mi>b</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mi>&Sigma;y - m&Sigma;x</mi>
                  </mrow>
                  <mrow>
                    <mi>n</mi>
                  </mrow>
                </mfrac>
              </math>
            </h6>
          </li>
          <li>
            <h5>Correlation Coefficient</h5>
            <h6>
              <math>
                <mi>r</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mo>1</mo>
                  </mrow>
                  <mrow>
                    <mi>n - 1</mi>
                  </mrow>
                </mfrac>
                <mo stretchy=True>&Sigma;</mo>
                <mo stretchy=True>(</mo>
                <mfrac>
                  <mrow>
                    <msub>
                      <mi>x</mi>
                      <mn>i</mn>
                    </msub>
                    <mo>&nbsp; - &nbsp;</mo>
                    <mi>x&#772;</mi>
                  </mrow>
                  <mrow>
                    <msub>
                      <mi>s</mi>
                      <mn>x</mn>
                    </msub>
                  </mrow>
                </mfrac>
                <mo stretchy=True>)</mo>
                <mo stretchy=True>(</mo>
                <mfrac>
                  <mrow>
                    <msub>
                      <mi>y</mi>
                      <mn>i</mn>
                    </msub>
                    <mo>&nbsp; - &nbsp;</mo>
                    <mi>y&#772;</mi>
                  </mrow>
                  <mrow>
                    <msub>
                      <mi>s</mi>
                      <mn>y</mn>
                    </msub>
                  </mrow>
                </mfrac>
                <mo stretchy=True>)</mo>
              </math>
              <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or
              <br />
              <math>
                <mi>r</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mo>1</mo>
                  </mrow>
                  <mrow>
                    <mi>n - 1</mi>
                  </mrow>
                </mfrac>
                <mo stretchy=True>&Sigma;</mo>
                <msub>
                  <mi>z</mi>
                  <mn>
                    <msub>
                      <mi>x</mi>
                      <mn>i</mn>
                    </msub>
                  </mn>
                </msub>
                <mi>&nbsp;</mi>
                <msub>
                  <mi>z</mi>
                  <mn>
                    <msub>
                      <mi>y</mi>
                      <mn>i</mn>
                    </msub>
                  </mn>
                </msub>
              </math>
            </h6>
          </li>
          <li>
            <h5>Standard Deviation</h5>
            <h6>
              <math>
                <msub>
                  <mi>s</mi>
                  <mn>x</mn>
                </msub>
                <mo>&nbsp; = &nbsp;</mo>
                <msqrt>
                  <mfrac>
                    <mrow>
                      <mi>&Sigma;(x&nbsp;-&nbsp;x&#772;)</mi>
                      <msup>
                        <mi></mi>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                    <mrow>
                      <mi>n</mi>
                    </mrow>
                  </mfrac>
                </msqrt>
              </math>
            </h6>
          </li>
          <li>
            <h5>Residual or Error</h5>
            <h6>
              <math>
                <mi>residual</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>e</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>actual value - predicted value</mi>
              </math>
            </h6>
          </li>
          <li>
            <h5>Sum of Residuals</h5>
            <h6>
              <math>
                <mi>&Sigma;residuals</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mi>&Sigma;e</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <mo>0</mo>
              </math>
            </h6>
          </li>
          <li>
            <h5>Coefficient of Determination</h5>
            <h7>Gives a percentage of how much better fit the line of regression is than the y&#772;</h7>
            <h6>
              <math>
                <msup>
                  <mi>r</mi>
                  <mn>2</mn>
                </msup>
                <mo>&nbsp; = &nbsp;</mo>
                <mfrac>
                  <mrow>
                    <mi>predicted squares - y&#772; squares</mi>
                  </mrow>
                  <mrow>
                    <mi>predicted squares</mi>
                  </mrow>
                </mfrac>
                <mo>&nbsp; &#8658; &nbsp;</mo>
                <mi>expressed as %</mi>
              </math>
            </h6>
          </li>
          <li>
            <h5>Root Mean Squared Error (RMSE) or Standard Deviation of the Residuals</h5>
            <h7>The smaller the RMSE, the better fit the line of regression</h7>
            <h6>
              <math>
                <mi>RMSE</mi>
                <mo>&nbsp; = &nbsp;</mo>
                <msqrt>
                  <mfrac>
                    <mrow>
                      <mo>&Sigma;</mo>
                      <msup>
                        <mi>e</mi>
                        <mn>2</mn>
                      </msup>
                    </mrow>
                    <mrow>
                      <mi>n - 1</mi>
                    </mrow>
                  </mfrac>
                </msqrt>
              </math>
            </h6>
          </li>
          <li>
            <h5>Chi-Square Tests (&chi;<sup>2</sup>)</h5>
            <h7>The larger the the &chi;<sup>2</sup>-value, the more likely the two variables affect each other</h7>
            <h6>
              <math>
                <msup>
                  <mi>&chi;</mi>
                  <mo>2</mo>
                </msup>
                <mo>&nbsp; = &nbsp;</mo>
                <mo>&Sigma;</mo>
                <mfrac>
                  <mrow>
                    <mi>(observed - expected)</mi>
                    <msup>
                      <mi></mi>
                      <mo>2</mo>
                    </msup>
                  </mrow>
                  <mrow>
                    <mi>expected</mi>
                  </mrow>
                </mfrac>
              </math>
            </h6>
          </li>
          <li>
            <h5>Degrees of Freedom (df)</h5>
            <h7>The number of values you would need in your data in order to be able to know all the other values</h7>
          </li>
        </ul>
      </li>
    </ul>
  </div>


  <br /><br />
  <div id="Calculus">
    <h3>Transcendental Calculus</h3>
    <h7><b>&nbsp; &#8627; The mathematics of change, calculus is basically very advanced algebra (finding rates & slopes) & geometry (addition to infinity & finding area). </b></h7>
    <h4>Integration</h4>
    <ul>
      <li>
        <h5>Antiderivatives & Indefinite Integrals</h5>
        <h7></h7>
        <ul>
          <li>
            <h5>Integral for Basic Power Functions</h5>
          </li>
        </ul>
      </li>
      </ul>
    </div>

      <br /><br />
      <div id="about">
        <h3>About Ryan L Buchanan</h3>
        <p class="para">
          I am re-skilling as a Machine Learning Engineer for Business Intelligence.&nbsp; This includes certifications with Udacity's ML Engineer & AI for Trading NanoDegrees.&nbsp; I have also just been accepted to a Data Analytics Masters
          program.&nbsp; I have a Masters in Education - Instructional Design & an MBA.&nbsp; I'd like to combine all of this into a Finance Data Scientist role, eventually.
          <br /><br />
          I am very interested the Data Mining & Data Engineering industries, preferably with an emphasis on artificial intelligence for finance.&nbsp; I am eager to start out with machine learning & progress to deep learning.&nbsp; I am
          enthusiastic,
          highly self-motivated & enjoy presenting informative data to decision makers.&nbsp; I'm eager to begin at entry level & quickly understand & apply industry-standard best practices.&nbsp; I look forward to working with motivated project
          teams to
          create the best possible products & services.
        </p>
      </div>

</body>

<footer>
  <div id="My_Links">
    <section>
      <h4 class="visuallyhidden"></h4>
      <a target="_blank" class="social-link" href="https://github.com/RyanLBuchanan">
        <img src="assets/social-github.png" alt="GitHub">
      </a>
      <a target="_blank" class="social-link" href="https://www.facebook.com/buchananryan22">
        <img src="assets/social-facebook.png" alt="Facebook">
      </a>
      <a target="_blank" class="social-link" href="https://www.linkedin.com/in/ryanlbuchanan/">
        <img src="assets/social-linkedin.png" alt="LinkedIn">
      </a>
      <a target="_blank" class="social-link" href="https://twitter.com/buchananryan22">
        <img src="assets/social-twitter.png" alt="Twitter">
      </a>
      <a target="_blank" class="social-link" href="https://stackoverflow.com/users/story/7541619?view=Timeline">
        <img src="assets/social-stack-overflow.png" alt="Stack Overflow">
      </a>
      <a target="_blank" class="social-link" href="https://www.ryangineer.com/virtual_reality.html">
        <img src="assets/social-youtube.png" alt="VR Dev Kids">
      </a>
      <a target="_blank" class="social-link" href="https://www.instagram.com/ryanlbuchanan/">
        <img src="assets/social-instagram.png" alt="Instagram">
      </a>
    </section>
  </div>
</footer>

</html>
