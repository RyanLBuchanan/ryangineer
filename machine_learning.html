<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Ryangineer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
  <script src="scripts/jquery.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
  <!-- jQuery Content Delivery Network -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <!-- CDN React libraries-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/umd/react.profiling.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/cjs/react.development.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/react/16.13.1/cjs/react.production.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/babel-standalone/6.26.0/babel.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <!-- My Stylesheet -->
  <link rel="stylesheet" type="text/css" href="stylesheets/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
  <!-- Favicon -->
  <link rel="shortcut icon" href="assets/favicon.ico" type="image/x-icon">
  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a target="_blank" class="navbar-brand" href="#"></a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/">Home</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/ai_finance.html">AI Finance</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/data_cleaning.html">Data Cleaning</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/data_dashboard.html">Data Dashboard</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/data_science.html">Data Science Diction</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/exploratory_data_analysis.html">Exploratory Data Analysis</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/machine_learning.html">Machine Learning</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/mathematicians.html">Mathematicians</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/virtual_reality.html">VR Dev Kids</a>
        </li>
        <li class="nav-item">
          <a target="_blank" class="nav-link" href="https://www.ryangineer.com/about.html">About</a>
        </li>
      </ul>
    </div>
  </nav>


  <div id="bio_image" style="float: left;">
    <figure>
      <img src="assets/bio_image.png" alt="Ryan L Buchanan" class="img-bio_image">
      <figcaption>
        <a target="_blank" href="mailto:buchananryan22@gmail.com">
          <b>buchananryan22@gmail.com</b></a><br />
        <a target="_blank" href="https://goo.gl/maps/UnhTaBZieDZU5F5w6"><b>Ogden, Utah, USA</b></a>
      </figcaption>
    </figure>
  </div>

  <div id="img_pythagoras">
    <img src="assets/pythagoras.png" alt="Pythagora" class="img-fluid">
  </div>

  <div>
    <h1 id="ryangineer"><b>Ryangineer</b></h1>
    <h2 id="ryangineer_sub" style="font-weight:bold;">Machine Learning<br />Algorithms<br /><br /></h2>
  </div>

  <div id="Dijkstra_Quotation" class="container">
    <div class="jumbotron">
      <p id="dijkstra_quotation" style="border: 1px solid gray;"><b>"The question of whether a computer can think is no more interesting than the question of whether a submarine can swim."</b><br />Edsger W. Dijkstra</p>
    </div>
  </div>

  <br /><br />
  <div id="My_ML_projects">
    <h3>My Machine Learning Projects</h3>
    <table>
      <tr>
        <td>
          <ul>
            <li><a target="_blank" title="Data Preprocessing Template" href="https://github.com/RyanLBuchanan/Data_Preprocessing_Template_Python" /><b>Data Preprocessing Template</b></a></li>
            <li><a target="_blank" title="Iris ML" href="https://github.com/RyanLBuchanan/iris-ml" /><b>Iris Machine Learning</b></a></li>
            <li><a target="_blank" title="Titanic ML" href="https://github.com/RyanLBuchanan/Titanic_ML_Project" /><b>Titanic Machine Learning</b></a></li>
            <li><a target="_blank" title="Simple Linear Regression" href="https://github.com/RyanLBuchanan/Simple_Linear_Regression" /><b>Simple Linear Regression</b></a></li>
            <li><a target="_blank" title="Multiple Linear Regression" href="https://github.com/RyanLBuchanan/Multiple_Linear_Regression" /><b>Multiple Linear Regression</b></a></li>
            <li><a target="_blank" title="Polynomial Linear Regression" href="https://github.com/RyanLBuchanan/Polynomial_Linear_Regression" /><b>Polynomial Linear Regression</b></a></li>
            <li><a target="_blank" title="Support Vector Regression" href="https://github.com/RyanLBuchanan/Support_Vector_Regression" /><b>Support Vector Regression</b></a></li>
            <li><a target="_blank" title="Decision Tree Regression" href="https://github.com/RyanLBuchanan/Decision_Tree_Regression" /><b>Decision Tree Regression</b></a></li>
            <li><a target="_blank" title="Random Forest Regression" href="https://github.com/RyanLBuchanan/Random_Forest_Regression" /><b>Random Forest Regression</b></a></li>
            <li><a target="_blank" title="Logistic Regression" href="https://github.com/RyanLBuchanan/Logistic_Regression" /><b>Logistic Regression</b></a></li>
          </ul>
        </td>
        <td>
          <ul>
            <li><a target="_blank" title="Support Vector Machine" href="https://github.com/RyanLBuchanan/Support_Vector_Machine" /><b>Support Vector Machine</b></a></li>
            <li><a target="_blank" title="Kernel SVM Nonlinear" href="https://github.com/RyanLBuchanan/Kernel_SVM" /><b>Kernel SVM Nonlinear</b></a></li>
            <li><a target="_blank" title="Naive Bayes Classifier" href="https://github.com/RyanLBuchanan/Naive_Bayes" /><b>Naive Bayes Classifier</b></a></li>
            <li><a target="_blank" title="K-Nearest Neighbors" href="https://github.com/RyanLBuchanan/K_Nearest_Neighbors_Algorithm" /><b>K-Nearest Neighbors</b></a></li>
            <li><a target="_blank" title="K-Means Clustering" href="https://github.com/RyanLBuchanan/K-Means_Clustering" /><b>K-Means Clustering</b></a></li>
            <li><a target="_blank" title="Hierarchical Clustering" href="https://github.com/RyanLBuchanan/Hierarchical_Clustering" /><b>Hierarchical Clustering</b></a></li>
            <li><a target="_blank" title="Apriori" href="https://github.com/RyanLBuchanan/Apriori" /><b>Apriori Association</b></a></li>
            <li><a target="_blank" title="Upper Confidence Bound" href="https://github.com/RyanLBuchanan/Upper_Confidence_Bound" /><b>Upper Confidence Bound</b></a></li>
            <li><a target="_blank" title="Thompson Sampling" href="https://github.com/RyanLBuchanan/thompson_sampling" /><b>Thompson Sampling</b></a></li>
          </ul>
        </td>
      </tr>
    </table>
  </div>

  <br /><br />
  <div id="ML_Algorithms">
    <h3>Noteworthy Machine Learning Algorithms</h3>
    <h7><b>&nbsp; Machine Learning &nbsp; &#8658; &nbsp; software able to detect patterns, make decisions, predict outcomes, learn from mistakes & optimize own performance without being explicitly programmed to do so</b></h7>
    <a target="_blank" href="https://en.wikipedia.org/wiki/Supervised_learning">
      <h4>Supervised Learning</h4>
    </a>
    <h7><b>&nbsp; &#8627; "learning a function that maps to an output based on the example of input-output pairs"</b></h7>
    <ul>
      <li>
        <h5>Linear Regression | Predict Real Values</h5>
        <h7>Estimate or predict real values based on continuous variables -> establish relationship between independent variables (matrix of features) & dependent variable (output) by fitting a best line</h7>
      </li>
      <ul>
        <li>
          <h5>Homoscedasticity</h5>
          <h7>"Homoskedastic . . . refers to a condition in which the variance
            of the residual, or error term, [that is, the “noise” or random disturbance
            in the relationship between the independent variables and the dependent
            variable], in a regression model is constant. That is, the error term
            does not vary much as the value of the predictor variable changes." <a target="_blank" href="https://www.investopedia.com/terms/h/homoskedastic.asp">Investopedia</a></h7>
        </li>
        <li>
          <h5>Multicollinearity</h5>
          <h7>"[R]efers to predictors that are correlated with other predictors.
            Multicollinearity occurs when your model includes multiple factors that
            are correlated not just to your response variable, but also to each
            other. In other words, it results when you have factors that are a bit
            redundant." <a target="_blank" href="https://blog.minitab.com/en/understanding-statistics/handling-multicollinearity-in-regression-analysis">Minitab</a> </h7>
        </li>
        <li>
          <h5>Derivation of Line of Best Fit | Ordinary Least Squares method | Sum of Squares Residual</h5>
          <h6>SS<sub>res</sub> = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>(y - y&#770;)<sup>2</sup> &#8594; min</h6>
        </li>
        <li>
          <h5>Simple Linear Regression</h5>
          <h7>Combining one variable in an equation to predict a single outcome</h7>
        </li>
        <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub></h6>
        <li>
          <h5>Multiple Linear Regression</h5>
          <h7>Combining many variables in an equation to predict a single outcome</h7>
          <h6>
            <math>
              <msub>
                <mi>y</mi>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; = &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>0</mn>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mn></mn>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mn></mn>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&beta;</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mn></mn>
                <mi>i</mi>
              </msub>
              <mo>&nbsp; + &nbsp;</mo>
              <msub>
                <mi>&epsilon;</mi>
                <mi>i</mi>
              </msub>
            </math>
          </h6>
        </li>
        <li>
          <h5>Polynomial Linear Regression</h5>
          <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub> + b<sub>2</sub>x<sub>2</sub><sup>2</sup> + . . . + b<sub>n</sub>x<sub>n</sub><sup>n</sup></h6>
        </li>
        <li>
          <h5>R Squared | Goodness of Fit Parameter</h5>
          <h6>R<sup>2</sup> = 1 - SS<sub>res</sub>/SS<sub>tot</sub><br />
            &nbsp; &#8627; where: <br />
            <ul>&#8627; SS<sub>tot</sub> = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>(y - y<sub>avg</sub>)<sup>2</sup></ul>
          </h6>
        </li>
        <li>
          <h5>Adjusted R Squared</h5>
          <h6>Adj R<sup>2</sup> = 1 - (1 - r<sup>2</sup>) * [(n - 1)/(n - p - 1)] <br />
            &nbsp; &#8627; where: <br />
            <ul>
              &#8627; p = number of regressors <br />
              &#8627; n = sample size
            </ul>
          </h6>
        </li>
      </ul>
      <li><a target="_blank" title="" href="https://www.mathworks.com/help/stats/understanding-support-vector-machine-regression.html" />
        <h5>Support Vector Regression | Classification</h5></a>
        <h7>Use as a regression method, maintaining all the main features that characterize the algorithm (maximal margin). The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences.
        </h7>
        <ul>
          <li>
            <h5>Epsilon-Insensitive Tube</h5>
            <h6>
              <math div="epsilon_insnstvty_tuber">
                <mfrac>
                  <mrow>
                    <mn>1</mn>
                  </mrow>
                  <mrow>
                    <mn>2</mn>
                  </mrow>
                </mfrac>
                <mo>&#8741;</mo>
                <mi>w</mi>
                <mo> &#8741;</mo>
                <mo>&nbsp; + &nbsp;</mo>
                <mn>C &nbsp;</mn>
                <span id="epsilon" style="font-size: 20px;">&Sigma;</span>(ξ<sub>i</sub> + ξ<sub>i</sub><sup>*</sup>) &#8594; min
              </math>
            </h6>
          </li>
          <li>
            <h5>The Gaussian RBF Kernel</h5>
            <h6>
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>K</mi>
                <mo stretchy="false">(</mo>
                <mi>x&#8407;, &nbsp;</mi>
                <msup>
                  <mi>l&#8407;</mi>
                  <mn>&nbsp;i</mn>
                </msup>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <mi>exp</mi>
                <mo stretchy="true">(</mo>
                <mo>-</mo>
                <mfrac>
                  <mrow>
                    <mi>&#8741; x&#8407;, &nbsp;</mi>
                    <msup>
                      <mi>l&#8407;</mi>
                      <mn>&nbsp;i</mn>
                    </msup>
                    <mo>&#8741;</mo>
                    <msup>
                      <mn></mn>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                  <mrow>
                    <mi>2</mi>
                    <msup>
                      <mi>&sigma;</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </mfrac>
                <mo stretchy="true">)</mo>
              </math><br />
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Logistic Regression | Classification</h5>
        <h7>Used to estimate discrete values, binary values (0/1, yes/no, true/false)
          based on given set of independent variables; predicts probability between
          0 & 1 as output values.
          <br /> &emsp; Logistic regression like its name is logarithmic. Its graph
          is curvilinear. If the dependent variable is binary, the graph is sigmoid.
          If not, the graph can be more pronounced, parabolic, etc.</h7>
        <ul>
          <li>
            <h5>Linear Regression | Sigmoid Function | Predicting Probability (p&#770;) </h5>
            <h6>y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub><br /><br />
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>&nbsp; &#8627;p</mi>
                <mo>=</mo>
                <mfrac>
                  <mrow>
                    <mi>1 &nbsp;</mi>
                  </mrow>
                  <mrow>
                    <mi>1 &nbsp; +</mi>
                    <msup>
                      <mi>&nbsp; e</mi>
                      <mn>-y</mn>
                    </msup>
                  </mrow>
                </mfrac>
              </math><br /><br />
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>&nbsp;&nbsp;&nbsp;&#8627;&nbsp;ln</mi>
                <mo stetchy=false>(</mo>
                <mfrac>
                  <mrow>
                    <mi>p &nbsp;</mi>
                  </mrow>
                  <mrow>
                    <mi>1 - p</mi>
                  </mrow>
                </mfrac>
                <mo stetchy=false>)</mo>
                <mo>=</mo>
                <msub>
                  <mi>b</mi>
                  <mn>0</mn>
                </msub>
                <mi>+</mi>
                <msub>
                  <mi>b</mi>
                  <mn>1</mn>
                </msub>
                <mi>x</mi>
              </math><br />
            </h6>
          </li>
        </ul>
      </li>
      <li>
        <h5>Decision Tree Regression</h5>
        <h7>Supervised learning algorithm used for classification problems; works for categorical & continuous variables</h7>
        <ul>
          <li>
            <h5>Standard Deviation Reduction</h5>
          </li>
          <h6>F(T, X) = <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>P(c)S(c)</h6>
        </ul>
      </li>
      <li>
        <h5>Support Vector Machines | Discriminative Classifier</h5>
        <h7>Discriminative classifier formally defined by a separating hyperplane</h7>
        <ul>
          <li><a target="_blank" title="" href="https://medium.com/@ankitnitjsr13/math-behind-support-vector-machine-svm-5e7376d0ee4d">
              <h5>Maximum Margin Hyperplane | Support Vectors</h5>
            </a></li>
          <h6>{x<sub><i>i</i></sub>, y<sub><i>i</i></sub>} where <i>i</i> = 1 . . . L, y<sub><i>i</i></sub> &#8712; {-1, 1}, x &#8712; &#8477;<sup>D</sup></h6>
        </ul>
      </li>
      <li><a target="_blank" title="Kernel Functions" href="https://towardsdatascience.com/kernel-function-6f1d2be6091" />
        <h5>Kernel SVM | Nonlinear</h5></a>
      </li>
      <h7>Mapping to a higher-dimensional space, applying the support vector algorithm & then projecting back to lower dimensional space resulting in a nonlinear separator</h7>
      <ul>
        <li><a target="_blank" title="The Math Behind SVM" href="https://medium.com/@ankitnitjsr13/math-behind-support-vector-machine-svm-5e7376d0ee4d">
            <h5>Linearly Separable with Hyperplane in 3D</h5>
          </a></li>
        <h6>&phi;(x<sub>1</sub>, x<sub>2</sub>) &#8658; (x<sub>1</sub>, x<sub>2</sub>, z) </h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">
            <h5>The Gaussian or Radial Basis Function (RBF) Kernel</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>K</mi>
              <mo stretchy="false">(</mo>
              <mi>x&#8407;, &nbsp;</mi>
              <msup>
                <mi>l&#8407;</mi>
                <mn>&nbsp;i</mn>
              </msup>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mi>exp</mi>
              <mo stretchy="true">(</mo>
              <mo>-</mo>
              <mfrac>
                <mrow>
                  <mi>|| x&#8407;, &nbsp;</mi>
                  <msup>
                    <mi>l&#8407;</mi>
                    <mn>&nbsp;i</mn>
                  </msup>
                  <msup>
                    <mi>||</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
                <mrow>
                  <mi>2</mi>
                  <msup>
                    <mi>&sigma;</mi>
                    <mn>2</mn>
                  </msup>
                </mrow>
              </mfrac>
              <mo stretchy="true">)</mo>
            </math><br />
          </h6>
        </div>
        <h6>&#8627; where:<br />
          <ul>
            &#8627; K = function applied to two vectors<br />
            &#8627; x = point in datasets<br />
            &#8627; <i>l</i> = landmark
          </ul>
        </h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="http://www.cs.toronto.edu/~duvenaud/cookbook/index.html">
            <h5>Sigmoid Kernel</h5>
          </a></li>
        <h6><i>K(X, Y)</i> = tanh(<i>&gamma; <b>&dot;</b> X<sup>T</sup>Y + r</i>)</h6>
        <li><a target="_blank" title="The Kernel Cookbook" href="http://www.cs.toronto.edu/~duvenaud/cookbook/index.html">
            <h5>Polynomial Kernel</h5>
          </a></li>
        <h6><i>K(X, Y)</i> = tanh(<i>&gamma; <b>&dot;</b> X<sup>T</sup>Y + r</i>)<sup><i>d</i></sup>, <i>&gamma;</i> &#62; 0</h6>
      </ul>
      <li>
        <h5>Naive Bayes Classification</h5>
        <h7>Probabilistic classifier based on Bayes Theorem with an assumption of independence between predictors (aka, features or independent variables)</h7>
        <ul>
          <li>
            <h5>Bayes Theorem &#8658; The probability of an event given prior knowledge of related events that occurred earlier</h5>
            <div style="text-align: left;">
              <math id="bayes_theorem" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>P</mi>
                <mo stretchy="false">(</mo>
                <mi>y</mi>
                <mo>&#x2223;</mo>
                <msub>
                  <mi>x</mi>
                  <mn>1</mn>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;</mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mi>n</mi>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <mfrac>
                  <mrow>
                    <mi>P</mi>
                    <mo stretchy="false">(</mo>
                    <mi>y</mi>
                    <mo stretchy="false">)</mo>
                    <mi>P</mi>
                    <mo stretchy="false">(</mo>
                    <msub>
                      <mi>x</mi>
                      <mn>1</mn>
                    </msub>
                    <mo>,</mo>
                    <mo>&#x2026;</mo>
                    <mo>,</mo>
                    <msub>
                      <mi>x</mi>
                      <mi>n</mi>
                    </msub>
                    <mo>&#x2223;</mo>
                    <mi>y</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                  <mrow>
                    <mi>P</mi>
                    <mo stretchy="false">(</mo>
                    <msub>
                      <mi>x</mi>
                      <mn>1</mn>
                    </msub>
                    <mo>,</mo>
                    <mo>&#x2026;</mo>
                    <mo>,</mo>
                    <msub>
                      <mi>x</mi>
                      <mi>n</mi>
                    </msub>
                    <mo stretchy="false">)</mo>
                  </mrow>
                </mfrac>
              </math>
            </div>
          </li>
        </ul>
      </li>
      <li>
        <h5>K-Nearest Neighbors</h5>
        <h7>Used for classification & regression; a simple algorithm that stores all available cases & classifies new cases by a "majority vote" of its K-nearest neighbors</h7>
        <ul>
          <li>
            <h5>Euclidean Distance</h5>
            <div style="text-align: left;">
              <math id="euclidean" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>Between</mi>
                <msub>
                  <mi>P</mi>
                  <mn>1</mn>
                </msub>
                <mo stretchy="false"> & </mo>
                <msub>
                  <mi>P</mi>
                  <mn>2</mn>
                </msub>
                <mo>=</mo>
                <msqrt>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mn>2</mn>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>1</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                  <msup>
                    <mi>2</mi>
                  </msup>
                  <mo stretchy="false">+</mo>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>y</mi>
                    <mn>2</mn>
                  </msub>
                  <mo>-</mo>
                  <msub>
                    <mi>y</mi>
                    <mi>1</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                  <msup>
                    <mi>2</mi>
                  </msup>
                </msqrt>
              </math>
            </div>
          </li>
        </ul>
      </li>
    </ul>

    <br />
    <a target="_blank" title="" href="https://en.wikipedia.org/wiki/Unsupervised_learning#:~:text=Unsupervised%20learning%20is%20a%20type,a%20minimum%20of%20human%20supervision" />
    <h4>Unsupervised Learning</h4></a>
    <h7><b>&nbsp; &#8627; "looks for previously undetected patterns in a data set with no pre-existing labels and with a minimum of human supervision"</b></h7>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>K-Means Clustering</h5></a>
      </li>
      <h7>Unsupervised algorithm which solves clustering problems; follows simple/easy way to classify a dataset through a certain number of clusters</h7>
      <ul>
        <li><a target="_blank" title="" href="https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce#:~:text=Within%20Cluster%20Sum%20of%20Squares&text=To%20calculate%20WCSS%2C%20you%20first,by%20the%20number%20of%20points.">
            <h5>Within Cluster Sum of Squares (WCSS)| Quantifiable metric to evaluate how certain number of clusters performs compared to different number of clusters</h5>
          </a></li>
        <h6>WCSS = <span id="wcss1" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>1</sub>)<sup>2</sup> + <span id="wcss2" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>2</sub>)<sup>2</sup>
          +<span id="wcss3" style="font-size: 20px;">&Sigma;</span> distance(P<sub>i</sub>, C<sub>3</sub>)<sup>2</sup></h6>
        <h6>&#8627; where:<br />
          <ul>
            &#8627; distance = distance between each point inside cluster<br />
            &#8627; C = centroids, respectively<br />
          </ul>
        </h6>
      </ul>
      <li><a target="_blank" title="" href="https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html" />
        <h5>Apriori Association</h5></a>
      </li>
      <h7>Analyzes the association of specific preferences in customer transactions (movies watched, items purchased in convenience store - beer & pampers urban myth) to discover relationships and how items are associated with each other</h7>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Support</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>Movie recommendation example: <br />
            &nbsp; &#8627; where M = specific <u>M</u>ovie<br />
            <br />
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Support(M)</mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi># of user watchlists containing M</mi>
                </mrow>
                <mrow>
                  <mi># of user watchlists</mi>
                </mrow>
              </mfrac>
            </math>
          </h6>
        </div>
        <li><a target="_blank" title="" href="">
            <h5>Confidence</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Confidence</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>M</mi>
                <mn>1</mn>
              </msub>
              <mo>&#x2192;</mo>
              <msub>
                <mi>M</mi>
                <mi>2</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi># of user watchlists containing</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>&#x2192;</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi># of user watchlists containing</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>1</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </div>
        <li><a target="_blank" title="" href="">
            <h5>Lift &#8594; measuring the relevance of an associated rule & the improvement prediction</h5>
          </a></li>
        <div style="text-align: left;">
          <h6>
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>Lift</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>M</mi>
                <mn>1</mn>
              </msub>
              <mo>&#x2192;</mo>
              <msub>
                <mi>M</mi>
                <mi>2</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>Confidence</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mn>1</mn>
                  </msub>
                  <mo>&#x2192;</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>Support</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>M</mi>
                    <mi>2</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </div>
      </ul>
    </ul>
    <br />
    <a target="_blank" href="https://en.wikipedia.org/wiki/Reinforcement_learning">
      <h4>Reinforcement Learning</h4>
    </a>
    <h7><b>&nbsp; &#8627; "how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward"</b></h7>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Upper Confidence Bound Algorithm | Deterministic Model</h5></a>
      </li>
      <a target="_blank" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">
        <h7>Modern application of Multi-Armed Bandit Problem (reference slot machine distributions)</h7>
      </a>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Advertising Model (requires update at every round)</h5>
          </a></li>
        <h6><u>Step 1</u>: Each round <i>n</i> considers two numbers for each ad <i>i</i>:<br />
          <ul>
            &nbsp; &#8627; <i>N<sub>i</sub></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> selected up to round <i>n</i><br />
            &nbsp; &#8627; <i>R<sub>i</sub></i>(<i>n</i>) &#x2192; &Sigma; of rewards of ad <i>i</i> up to round <i>n</i><br />
          </ul><br />
          <u>Step 2</u>: From these two numbers we compute:<br />
          <ul>
            &nbsp; &#8627; Average reward of ad <i>i</i> up to round <i>n</i> with:
        </h6>
        <div style="text-align: left;">
          <ul>
            <h6>&nbsp; &nbsp; &nbsp; &nbsp;
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <mi>r&#772;</mi>
                <mo stretchy="false">(</mo>
                <mi>n</mi>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <mfrac>
                  <mrow>
                    <msub>
                      <mi>R</mi>
                      <mn>i</mn>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                  <mrow>
                    <msub>
                      <mi>N</mi>
                      <mn>i</mn>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                </mfrac>
              </math><br />
            </h6>
          </ul>
        </div>
        <ul>
          <h6>&nbsp; &#8627; Confidence interval [<i>r&#772;<sub>i</sub></i>(<i>n</i>) - &#x25B3;<sub><i>i</i></sub>(<i>n</i>), <i>r&#772;<sub>i</sub></i>(<i>n</i>) +
            &#x25B3;<sub><i>i</i></sub>(<i>n</i>)] at round <i>n</i> with:</h6>
        </ul>
        <div>
          <ul>
            <h6>&nbsp; &nbsp; &nbsp; &nbsp;
              <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
                <msub>
                  <mi>&#x25B3;</mi>
                  <mn>i</mn>
                </msub>
                <mo stretchy="false">(</mo>
                <mi>n</mi>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <msqrt>
                  <mfrac>
                    <mrow>
                      <mi>3</mi>
                    </mrow>
                    <mrow>
                      <mi>2</mi>
                    </mrow>
                  </mfrac>
                  <mo>*</mo>
                  <mfrac>
                    <mrow>
                      <mi>log</mi>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>N</mi>
                        <mn>i</mn>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                  </mfrac>
                </msqrt>
              </math><br />
            </h6>
          </ul>
        </div>
        <h6><u>Step 3</u>: Select the ad <i>i</i> that has the maximum UCB <i>r&#772;<sub>i</sub></i>(<i>n</i>) +
          &#x25B3;<sub><i>i</i></sub>(<i>n</i>)<br />
      </ul>
    </ul>
    </ul>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Thompson Sampling Algorithm | Probabilistic Model</h5></a>
      </li>
      <a target="_blank" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">
        <h7>Constructs distributions of where we think the actual expected value might lie; an auxiliary mechanism to solve the problem</h7>
      </a>
      <ul>
        <li><a target="_blank" title="" href="">
            <h5>Advertising Model (can accomodate delayed feedback & has better empirical evidence than UCB)</h5>
          </a></li>
        <h6><u>Step 1</u>: Each round <i>n</i> considers two numbers for each ad <i>i</i>:<br />
          <ul>
            &nbsp; &#8627; <i>N<sub>i</sub><sup>1</sup></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> rewarded 1 up to round <i>n</i><br />
            &nbsp; &#8627; <i>N<sub>i</sub><sup>0</sup></i>(<i>n</i>) &#x2192; # of times the ad <i>i</i> rewarded 0 up to round <i>n</i><br />
          </ul><br />
          <u>Step 2</u>: For each ad <i>i</i>, we take a random draw from the distribution below:<br />
          <ul>
            <br />
            <i>&theta;</i><sub>i</sub>(<i>n</i>) = <i>&beta;</i>(<i>N<sub>i</i></sub><sup>1</sup>(<i>n</i>) + 1, <i>N<sub>i</sub></i><sup>0</sup>(<i>n</i> + 1))
          </ul>
          <br />
        </h6>
        <h6><u>Step 3</u>: Select the ad <i>i</i> that has highest <i>&theta;</i><sub>i</sub>(<i>n</i>)<br />
      </ul>
    </ul>
    <ul>
      <li><a target="_blank" title="" href="" />
        <h5>Random Forest Regression</h5></a>
      </li>
      <h7>Ensemble decision trees; a collection of decision trees (aka forest) to classify a new object based on attributes; each tree gives a classification & we say the tree "votes" for the class </h7>
      <!-- <ul>
        <li><a target="_blank" title="" href="">
            <h5>Type</h5>
          </a></li>
        <h6>Equation</h6>
      </ul> -->
      <li><a target="_blank" title="" href="" />
        <h5>Dimensionality Reduction</h5></a>
      </li>
      <h7>Identifies highly significant variables when you have thousands</h7>
      <!-- <ul>
        <li><a target="_blank" title="" href="">
            <h5>Type</h5>
          </a></li>
        <h6>Equation</h6>
      </ul> -->
      <li><a target="_blank" title="" href="" />
        <h5>Gradient Boosting</h5></a>
      </li>
      <h7>Ensemble of machine learning algorithms</h7>
      <!-- <ul>
        <li><a target="_blank" title="" href="">
            <h5>Type</h5>
          </a></li>
        <h6>Equation</h6>
      </ul> -->
    </ul>
  </div>

  <br /><br />
  <div id="My_NN_Projects">
    <h3>My Neural Networks Projects</h3>
    <table>
      <tr>
        <td>
          <ul>
            <li><a target="_blank" title="ANN_Regression" href="https://github.com/RyanLBuchanan/ANN_Regression" /><b>Artificial Neural Network | Regression</b></a></li>
            <li><a target="_blank" title="ANN-geodemographic-segmentation" href="https://github.com/RyanLBuchanan/ANN-geodemographic-segmentation" /><b>Artificial Neural Network | Geodemographic Segmentation of Bank Clients</b></a></li>
            <li><a target="_blank" title="CNN_boilerplate" href="https://github.com/RyanLBuchanan/CNN_boilerplate" /><b>Convolutional Neural Network | Boiler Plate</b></a></li>
            <li><a target="_blank" title="Face_Recognition_CNN" href="https://github.com/RyanLBuchanan/Face_Recognition_CNN" /><b>Convolutional Neural Network | Facial Recognition</b></a></li>

          </ul>
        </td>
        <td>
          <ul>
            <li><a target="_blank" title="CNN_Cat_r_Dog" href="https://github.com/RyanLBuchanan/CNN_Cat_r_Dog" /><b>Convolutional Neural Network | Is it a Cat or Dog?</b></a></li>
            <li><a target="_blank" title="Generative Adversarial Network | Neural Style Transfer" href="https://github.com/RyanLBuchanan/Neural_Style_Transfer" /><b>Generative Adversarial Network | Neural Style Transfer</b></a></li>
            <li><a target="_blank" title="Natural Language Processing" href="https://github.com/RyanLBuchanan/Natural_Language_Processing" /><b>Natural Language Processing</b></a></li>
            <li><a target="_blank" title="Bidirectional Encoder Representations from Transformers" href="https://github.com/RyanLBuchanan/Bidirectional_Encoder_Representations_Transformers" /><b>Bidirectional Encoder Representations from
                Transformers</b></a></li>
          </ul>
        </td>
      </tr>
    </table>
  </div>

  <br /><br />
  <div id="Deep_Learning">
    <h3>Lovely Deep Learning</h3>
    <div id="ANNs">
      <a id="definition" target="_blank" href="https://towardsdatascience.com/understanding-neural-networks-what-how-and-why-18ec703ebd31">
        <h4>Artificial Neural Networks</h4>
      </a>
      <h7><b>&nbsp; &#8627; A computing system that consist of a number of simple but highly interconnected elements or nodes, called ‘neurons’, which are organized in layers which process information using dynamic state responses to external inputs,
          an extremely useful algorithm for finding patterns too complex to be manually extracted</b></h7>
      <ul>
        <li><a target="_blank" title="Understanding neural networks 1: The concept of neurons" href="https://becominghuman.ai/understanding-neural-networks-1-the-concept-of-neurons-287be36d40f" />
          <h5>Neuron Definition</h5></a>
        </li>
        <h7>A mathematical operation that takes its input, multiplies it by its weight & then passes the sum through an activation function</h7>
        <ul>
          <li><a target="_blank" title="Understanding neural networks 2: The math of neural networks in 3 equations" href="https://becominghuman.ai/understanding-neural-networks-2-the-math-of-neural-networks-in-3-equations-6085fd3f09df">
              <h5>Neuron Formula</h5>
            </a></li>
          <h6>Y<sub>1</sub> = activation(w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub> + . . . + w<sub>m</sub>x<sub>m</sub>)</h6>
          <li><a target="_blank" title="Understanding neural networks 2: The math of neural networks in 3 equations" href="https://becominghuman.ai/understanding-neural-networks-1-the-concept-of-neurons-287be36d40f">
              <h5>Sigmoid Activation Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>1 &nbsp;</mi>
                </mrow>
                <mrow>
                  <mi>1 &nbsp; +</mi>
                  <msup>
                    <mi>&nbsp; e</mi>
                    <mn>-z</mn>
                  </msup>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Threshold Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mo stretchy="true">{</mo>
              <mrow>
                <mi>1 if x &#x2265; 0</mi>
              </mrow>
              <mrow>
                <mi>&nbsp;,&nbsp;0 if x < 0</mi>
              </mrow>
              <mo stretchy="true">}</mo>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Rectifier Function</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mo stretchy="false">(</mo>
              <mi>x, 0</mi>
              <mo stretchy="false">)</mo>
            </math><br />
          </h6>
          <li><a target="_blank" title="" href="">
              <h5>Hyperbolic Tangent Function (tanh)</h5>
            </a></li>
          <h6>
            <span id="" class="sigma_sum" style="font-size: 20px;">&Sigma;</span>w<sub><i>i</i></sub>x<sub><i>i</i></sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <math id="" xmlns="http://www.w3.org/1998/Math/MathML">
              <mi>&phi;</mi>
              <mo stretchy="false">(</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>1&nbsp; - &nbsp;</mi>
                  <msup>
                    <mi>e</mi>
                    <mn>-2x</mn>
                  </msup>
                </mrow>
                <mrow>
                  <mi>1&nbsp; + &nbsp;</mi>
                  <msup>
                    <mi>e</mi>
                    <mn>-2x</mn>
                </mrow>
              </mfrac>
            </math><br />
          </h6>
        </ul>
      </ul>
    </div>
    <br />
    <div id="CNNs">
      <a id="definition" target="_blank" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">
        <h4>Convolutional Neural Networks</h4>
      </a>
      <h7><b>&nbsp; &#8627; A class of deep neural networks, most commonly applied to analyzing visual imagery. CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each
          neuron in one layer is connected to all neurons in the next layer.</b></h7>
      <ul>
        <li><a target="_blank" title="" href="" />
          <h5>Convolution | Visual Imagery Analysis</h5></a>
        </li>
        <h7>A special kind of mathematical linear operation to give a network a degree of translation invariance; eg, a typical image convolution is a form of blurring</h7>
      </ul>
    </div>
    <br />
    <div id="NLPs">
      <a id="definition" target="_blank"
        href="https://classroom.udacity.com/nanodegrees/nd009t/parts/c4bacd6f-3766-4b62-994f-23e44e4c1f68/modules/52fce89d-5551-4d94-8bdc-48089274b27b/lessons/ab4cc389-336f-401c-937a-54f8c2aea24c/concepts/f5efb207-200c-4194-9ada-1189f4d66312">
        <h4>Natural Language Processing</h4>
      </a>
      <h7><b>&nbsp; &#8627; Starts with raw text in whatever format available, processes it, extracts relevant features and builds models to accomplish various NLP tasks</b></h7>
      <ul>
        <li><a target="_blank" title="" href="" />
          <h5>NLP Pipeline</h5></a>
        </li>
        <h6>Text Processing &nbsp; &#8658; &nbsp; Feature Extraction &nbsp; &#8658; &nbsp; Modeling</h6>
        <ul>
          <li>
            <h5>Document-Term Matrix</h5>
            <h7>Compute dot product (sum of the products of corresponding elements) to find similarities</h7>
            <h6>a * b = &Sigma; (a<sub>1</sub>b<sub>1</sub> + a<sub>2</sub>b<sub>2</sub> + a<sub>3</sub>b<sub>3</sub> + . . . + a<sub>n</sub>b<sub>n</sub>)</h6>
          </li>
          <li>
            <h5>Cosine Similarity</h5>
            <h7>Divide the product of two vectors by their magnitudes or Euclidean norms</h7>
            <h6>
              <math>
                <mi>cos(&theta;) = </mi>
                <mfrac>
                  <mrow>
                    <mi>a*b</mi>
                  </mrow>
                  <mrow>
                    <mi>||a||*||b||</mi>
                  </mrow>
                </mfrac>
                <br />&nbsp; &#8627; where:
                <br />&nbsp; &nbsp; &nbsp; Identical vectors &#x2192; cos(&theta;) = 1
                <br />&nbsp; &nbsp; &nbsp; Orthogonal vectors &#x2192; cos(&theta;) = 0
                <br />&nbsp; &nbsp; &nbsp; Exact opposite vectors &#x2192; cos(&theta;) = -1
              </math>
            </h6>
          </li>
          <li>
            <h5>TF-IDF Transform</h5>
            <h7>Term frequency-inverse document frequency</h7>
            <br />
            <h6>
              <mi>tfidf(t, d, D) = tf(t, d) * idf(t, D)</mi>
              <br />&nbsp; &#8627; where:
              <br />&nbsp; &nbsp; &nbsp;
              <mi>tf(t, d) = </mi>
              <math>
                <mi></mi>
                <mfrac>
                  <mrow>
                    <mi>count(t, d)</mi>
                  </mrow>
                  <mrow>
                    <mi>|d|</mi>
                  </mrow>
                </mfrac>
              </math>
              <br />&nbsp; &nbsp; &nbsp;
              <mi>idf(t, D) = </mi>
              <math>
                <mi>Log</mi>
                <mo stretchy=True>(</mo>
                <mfrac>
                  <mrow>
                    <mi>|D|</mi>
                  </mrow>
                  <mrow>
                    <mi>|{d &#8712; D : t &#8712; d}|</mi>
                  </mrow>
                </mfrac>
                <mo stretchy=True>)</mo>
              </math>
            </h6>
          </li>
        </ul>
        <li>
          <h5>Stemming</h5>
          <h7>Takes the root of a word removing conjugation to simplify & understand gist meaning (reducing final dimension )</h7>
        <li><a target="_blank" title="" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html#:~:text=Lemmatization%20usually%20refers%20to%20doing,is%20known%20as%20the%20lemma%20." />
        </li>
        <h5>Lemmatization</h5></a>
        </li>
        <h7>Refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.</>
      </ul>
    </div>
  </div>


  <br /><br />
  <div id="about">
    <h3>About Ryan L Buchanan</h3>
    <p class="para">
      I am re-skilling as a Data Analyst & Machine Learning Engineer.&nbsp; I
      am currently enrolled in a Masters in Data Analytics.&nbsp; I am also
      acquiring certifications as an ML Engineer & Algorithmic Trader from Udacity.
      &nbsp; I have an MBA & an MS in Instructional Design.
      <br /><br />
      I have a multi-displinary background including military intelligence,
      psychology, linguistics, economics, virtual reality & educational technology.&nbsp; I have
      worked abroad for ten years with military, universities & vocational schools.
      &nbsp; I have working knowledge of Arabic, Chinese & French.&nbsp; I am very
      mobile, able to relocate quickly, adapt easily to diverse working conditions
      & have a current passport.
      <br /><br />
      I have a passion for mathematics, statistics & artificial intelligence.&nbsp;
      I am enthusiastic, highly self-motivated & enjoy presenting informative data
      to decision makers.&nbsp; I am eager to work with dynamic teams to create
      high quality products & services.
    </p>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.3.4/lib/darkmode-js.min.js"></script>
  <script src="scripts/script.js"></script>

</body>

<footer>
  <div id="My_Links">
    <section>
      <h4 class="visuallyhidden"></h4>
      <a target="_blank" class="social-link" href="https://github.com/RyanLBuchanan">
        <img src="assets/social-github.png" alt="GitHub">
      </a>
      <a target="_blank" class="social-link" href="https://www.facebook.com/buchananryan22">
        <img src="assets/social-facebook.png" alt="Facebook">
      </a>
      <a target="_blank" class="social-link" href="https://www.linkedin.com/in/ryanlbuchanan/">
        <img src="assets/social-linkedin.png" alt="LinkedIn">
      </a>
      <a target="_blank" class="social-link" href="https://twitter.com/buchananryan22">
        <img src="assets/social-twitter.png" alt="Twitter">
      </a>
      <a target="_blank" class="social-link" href="https://stackoverflow.com/users/story/7541619?view=Timeline">
        <img src="assets/social-stack-overflow.png" alt="Stack Overflow">
      </a>
      <a target="_blank" class="social-link" href="https://www.ryangineer.com/virtual_reality.html">
        <img src="assets/social-youtube.png" alt="VR Dev Kids">
      </a>
      <a target="_blank" class="social-link" href="https://www.instagram.com/ryanlbuchanan/">
        <img src="assets/social-instagram.png" alt="Instagram">
      </a>
    </section>
  </div>
</footer>

</html>
